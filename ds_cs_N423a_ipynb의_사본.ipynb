{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ds-cs-N423a.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MINED30/AI-python-connect/blob/master/ds_cs_N423a_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBQsZEJmubLs"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 1 / Assingment 3*\n",
        "\n",
        "---\n",
        "# Neural Network Framework (Keras)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN5Wzlub62DZ"
      },
      "source": [
        "\n",
        "## 기본과제\n",
        "### 케라스 라이브러리를 사용하여 Multi-Layer Perceptron 모델을 CIFAR100 데이터에 적용해보세요.\n",
        "\n",
        "- 시드를 고정하십시오.\n",
        "- 데이터를 Noramlized 해줍니다. \n",
        "- 케라스에서 모델은 다음과 같이 고정합니다. \n",
        "- 활성함수는 ReLU를 사용합니다.\n",
        "- 단계별로 오늘 배운 규제방법을 적용해봅니다. \n",
        "\n",
        "\n",
        "### 문제에 기록된 텍스트를 꼭! 잘 읽어보고 답변을 다셔야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBPLbaggP52G"
      },
      "source": [
        "##### Base #####\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# 데이터 불러오기\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test / 255."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kAKEMcKdpsC"
      },
      "source": [
        "## 1) X_train, y_train의 Data형태를 출력해서 matrix 구조 [N, x, y, c]를 확인하고 입력해보세요.\n",
        "\n",
        "### 문항 1-1). 데이터의 구조를 출력하기 위한 코드를 입력하세요.\n",
        "\n",
        "### 문항 1-2). Flatten(input_shape=()) 에 들어갈 데이터 형태를 입력하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0r1YrzRNG1y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1135dd7-07df-4628-82b2-d23a59378cd3"
      },
      "source": [
        "##### Your Code Here #####\n",
        "[X_train.shape,y_train.shape]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(50000, 32, 32, 3), (50000, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7nHEuYmd-p6"
      },
      "source": [
        "Base model을 제작합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T_3XkVRY2xw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66eb7e80-bfec-45cc-8fb2-d8dc04fd7736"
      },
      "source": [
        "# Step 1. Basic Model\n",
        "\n",
        "# 변수 설정을 따로 하는 방법을 적용하기 위한 코드입니다. \n",
        "batch_size = 100\n",
        "epochs_max = 20\n",
        "\n",
        "# model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(32, 32, 3))) ## 문제 1의 데이터구조에서 확인한 내용을 잘 입력하세요\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성함\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "results = model.fit(X_train, y_train, epochs=epochs_max, batch_size=batch_size, verbose=1, validation_data=(X_test,y_test))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 4.3548 - accuracy: 0.0441 - val_loss: 3.8663 - val_accuracy: 0.1067\n",
            "Epoch 2/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.7917 - accuracy: 0.1173 - val_loss: 3.7211 - val_accuracy: 0.1336\n",
            "Epoch 3/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.6517 - accuracy: 0.1408 - val_loss: 3.6870 - val_accuracy: 0.1447\n",
            "Epoch 4/20\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 3.5702 - accuracy: 0.1534 - val_loss: 3.6012 - val_accuracy: 0.1572\n",
            "Epoch 5/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.5057 - accuracy: 0.1701 - val_loss: 3.5252 - val_accuracy: 0.1685\n",
            "Epoch 6/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.4211 - accuracy: 0.1817 - val_loss: 3.5043 - val_accuracy: 0.1731\n",
            "Epoch 7/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.4013 - accuracy: 0.1871 - val_loss: 3.4831 - val_accuracy: 0.1788\n",
            "Epoch 8/20\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 3.3565 - accuracy: 0.1922 - val_loss: 3.4569 - val_accuracy: 0.1882\n",
            "Epoch 9/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.3335 - accuracy: 0.1986 - val_loss: 3.4624 - val_accuracy: 0.1861\n",
            "Epoch 10/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.3087 - accuracy: 0.2014 - val_loss: 3.3963 - val_accuracy: 0.1961\n",
            "Epoch 11/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.2815 - accuracy: 0.2064 - val_loss: 3.3819 - val_accuracy: 0.1989\n",
            "Epoch 12/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.2345 - accuracy: 0.2127 - val_loss: 3.3897 - val_accuracy: 0.1970\n",
            "Epoch 13/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.2420 - accuracy: 0.2153 - val_loss: 3.3889 - val_accuracy: 0.1954\n",
            "Epoch 14/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.2088 - accuracy: 0.2194 - val_loss: 3.3779 - val_accuracy: 0.2041\n",
            "Epoch 15/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1971 - accuracy: 0.2238 - val_loss: 3.3573 - val_accuracy: 0.2086\n",
            "Epoch 16/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1707 - accuracy: 0.2255 - val_loss: 3.3789 - val_accuracy: 0.2012\n",
            "Epoch 17/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1690 - accuracy: 0.2288 - val_loss: 3.3464 - val_accuracy: 0.2086\n",
            "Epoch 18/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1626 - accuracy: 0.2282 - val_loss: 3.3346 - val_accuracy: 0.2128\n",
            "Epoch 19/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1408 - accuracy: 0.2296 - val_loss: 3.3307 - val_accuracy: 0.2131\n",
            "Epoch 20/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1216 - accuracy: 0.2323 - val_loss: 3.3584 - val_accuracy: 0.2054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdxJ5AnieUxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad29e5e0-41bc-4681-bf34-2f5b4f0f0245"
      },
      "source": [
        "model.predict(X_test[0:1])\n",
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 3.3342 - accuracy: 0.2108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbNCUtz4eHIi"
      },
      "source": [
        "## 2) 최종 모델에서 model.evaluate을 통해서 결과를 출력해보세요.  \n",
        "### 문항 2-1). verbose=0 으로 입력해서 출력되는 accuracy를 입력하세요.\n",
        "### 문항 2-2). verbose=1 으로 입력해서 출력되는 accuracy를 입력하세요. <Br>\n",
        "(차이점을 아시겠나요? 차이점을 모른다면 검색해보세요. 정답에 공백을 입력할 수 있어야 합니다.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBQks0_rZWa9"
      },
      "source": [
        "# Step 2. Basic Model + Weight Decay\n",
        "\n",
        "# 변수 설정을 따로 하는 방법을 적용하기 위한 코드입니다. \n",
        "batch_size = 100\n",
        "epochs_max = 20\n",
        "\n",
        "# model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(X_train.shape[1:])))\n",
        "model.add(Dense(128, activation='relu', \n",
        "                kernel_regularizer=regularizers.l2(0.00001),    # L2 norm regularization\n",
        "                activity_regularizer=regularizers.l1(0.00001) )) # L1 norm regularization\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성함\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "results = model.fit(X_train, y_train, epochs=epochs_max, batch_size=batch_size, verbose=0, validation_data=(X_test,y_test))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDIpV6fD3Ghy",
        "outputId": "05c84d72-4077-4a25-de29-0467237faa01"
      },
      "source": [
        "model.evaluate(X_test,  y_test, verbose=1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 3.3926 - accuracy: 0.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.392564058303833, 0.20000000298023224]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-dlVgoo3pY_",
        "outputId": "24883cc7-fe15-4a1b-a1ef-59bbe68bef08"
      },
      "source": [
        "model.evaluate(X_test,  y_test, verbose=0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.392564058303833, 0.20000000298023224]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yQeUcY8fp4x"
      },
      "source": [
        "## 3) Dropout을 사용하기 위해서는 라이브러리 추가로 불어와야 합니다. \n",
        "\n",
        "### 문항 3) Dropout의 라이브러리를 호출하기 위해서 사용한 import 문구를 적어주세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_B_mosCZ_Ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b1c71e-c459-44ca-ae86-eadb3b9933e6"
      },
      "source": [
        "# Step 3. Basic Model + Dropout\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# 변수 설정을 따로 하는 방법을 적용하기 위한 코드입니다. \n",
        "batch_size = 100\n",
        "epochs_max = 20\n",
        "\n",
        "# model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(X_train.shape[1:])))\n",
        "model.add(Dense(128*1.1, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성함\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "results = model.fit(X_train, y_train, epochs=epochs_max, batch_size=batch_size, verbose=1, validation_data=(X_test,y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 4.4480 - accuracy: 0.0311 - val_loss: 3.9934 - val_accuracy: 0.0775\n",
            "Epoch 2/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 4.0173 - accuracy: 0.0779 - val_loss: 3.8617 - val_accuracy: 0.1121\n",
            "Epoch 3/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.9137 - accuracy: 0.0949 - val_loss: 3.7819 - val_accuracy: 0.1267\n",
            "Epoch 4/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.8587 - accuracy: 0.1047 - val_loss: 3.7475 - val_accuracy: 0.1231\n",
            "Epoch 5/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.8170 - accuracy: 0.1130 - val_loss: 3.6885 - val_accuracy: 0.1361\n",
            "Epoch 6/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.7615 - accuracy: 0.1225 - val_loss: 3.6834 - val_accuracy: 0.1377\n",
            "Epoch 7/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.7366 - accuracy: 0.1243 - val_loss: 3.6403 - val_accuracy: 0.1445\n",
            "Epoch 8/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.7213 - accuracy: 0.1242 - val_loss: 3.6599 - val_accuracy: 0.1425\n",
            "Epoch 9/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.7006 - accuracy: 0.1296 - val_loss: 3.6152 - val_accuracy: 0.1519\n",
            "Epoch 10/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.6879 - accuracy: 0.1314 - val_loss: 3.6185 - val_accuracy: 0.1490\n",
            "Epoch 11/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.6687 - accuracy: 0.1337 - val_loss: 3.5918 - val_accuracy: 0.1559\n",
            "Epoch 12/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.6469 - accuracy: 0.1385 - val_loss: 3.5835 - val_accuracy: 0.1589\n",
            "Epoch 13/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.6482 - accuracy: 0.1369 - val_loss: 3.5845 - val_accuracy: 0.1595\n",
            "Epoch 14/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.6371 - accuracy: 0.1372 - val_loss: 3.5828 - val_accuracy: 0.1548\n",
            "Epoch 15/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.6248 - accuracy: 0.1454 - val_loss: 3.5555 - val_accuracy: 0.1572\n",
            "Epoch 16/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.6140 - accuracy: 0.1424 - val_loss: 3.5685 - val_accuracy: 0.1587\n",
            "Epoch 17/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.6002 - accuracy: 0.1445 - val_loss: 3.5429 - val_accuracy: 0.1661\n",
            "Epoch 18/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.6070 - accuracy: 0.1419 - val_loss: 3.5448 - val_accuracy: 0.1644\n",
            "Epoch 19/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.5873 - accuracy: 0.1477 - val_loss: 3.5327 - val_accuracy: 0.1672\n",
            "Epoch 20/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.5814 - accuracy: 0.1493 - val_loss: 3.5331 - val_accuracy: 0.1658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3RoevKkC27v"
      },
      "source": [
        "### 문항 4) Early Stopping을 사용할 수 있도록 강의자료에서 코드를 잘 발췌해서 사용하시고, 50개의 Epoch를 돌렸을 때 Stop된 epoch 숫자를 입력하세요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjj4th3oLjgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6934ab1-93a5-4060-8396-53b3b8ad9c3d"
      },
      "source": [
        "# Step 4. Basic Model + Early Stopping\n",
        "\n",
        "# 학습시킨 데이터를 저장시키기 위한 코드입니다. \n",
        "checkpoint_filepath = \"FMbest.hdf5\"\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(X_train.shape[1:])))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성함\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# early stopping\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "# Validation Set을 기준으로 가장 최적의 모델을 찾기\n",
        "save_best = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
        "    save_weights_only=True, mode='auto', save_freq='epoch', options=None)\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=50, verbose=1, \n",
        "          validation_data=(X_test,y_test), \n",
        "          callbacks=[early_stop, save_best])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 4.3196 - accuracy: 0.0454 - val_loss: 3.8364 - val_accuracy: 0.1100\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.83637, saving model to FMbest.hdf5\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.7895 - accuracy: 0.1169 - val_loss: 3.7194 - val_accuracy: 0.1331\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.83637 to 3.71943, saving model to FMbest.hdf5\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.6419 - accuracy: 0.1452 - val_loss: 3.6360 - val_accuracy: 0.1481\n",
            "\n",
            "Epoch 00003: val_loss improved from 3.71943 to 3.63604, saving model to FMbest.hdf5\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.5510 - accuracy: 0.1589 - val_loss: 3.5606 - val_accuracy: 0.1633\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.63604 to 3.56062, saving model to FMbest.hdf5\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 3.4674 - accuracy: 0.1763 - val_loss: 3.5061 - val_accuracy: 0.1758\n",
            "\n",
            "Epoch 00005: val_loss improved from 3.56062 to 3.50609, saving model to FMbest.hdf5\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.3848 - accuracy: 0.1882 - val_loss: 3.4660 - val_accuracy: 0.1849\n",
            "\n",
            "Epoch 00006: val_loss improved from 3.50609 to 3.46601, saving model to FMbest.hdf5\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 3.3514 - accuracy: 0.1952 - val_loss: 3.4567 - val_accuracy: 0.1879\n",
            "\n",
            "Epoch 00007: val_loss improved from 3.46601 to 3.45674, saving model to FMbest.hdf5\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.3064 - accuracy: 0.2035 - val_loss: 3.4169 - val_accuracy: 0.1914\n",
            "\n",
            "Epoch 00008: val_loss improved from 3.45674 to 3.41691, saving model to FMbest.hdf5\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.2762 - accuracy: 0.2106 - val_loss: 3.4406 - val_accuracy: 0.1856\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 3.41691\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.2541 - accuracy: 0.2156 - val_loss: 3.3670 - val_accuracy: 0.1998\n",
            "\n",
            "Epoch 00010: val_loss improved from 3.41691 to 3.36704, saving model to FMbest.hdf5\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.2246 - accuracy: 0.2176 - val_loss: 3.3703 - val_accuracy: 0.2034\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 3.36704\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1852 - accuracy: 0.2257 - val_loss: 3.3318 - val_accuracy: 0.2106\n",
            "\n",
            "Epoch 00012: val_loss improved from 3.36704 to 3.33183, saving model to FMbest.hdf5\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1799 - accuracy: 0.2283 - val_loss: 3.3339 - val_accuracy: 0.2107\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 3.33183\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1468 - accuracy: 0.2310 - val_loss: 3.3119 - val_accuracy: 0.2141\n",
            "\n",
            "Epoch 00014: val_loss improved from 3.33183 to 3.31189, saving model to FMbest.hdf5\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1426 - accuracy: 0.2351 - val_loss: 3.3317 - val_accuracy: 0.2124\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 3.31189\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 3.1252 - accuracy: 0.2356 - val_loss: 3.3429 - val_accuracy: 0.2097\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 3.31189\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1154 - accuracy: 0.2392 - val_loss: 3.3547 - val_accuracy: 0.2135\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 3.31189\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.1135 - accuracy: 0.2394 - val_loss: 3.3041 - val_accuracy: 0.2179\n",
            "\n",
            "Epoch 00018: val_loss improved from 3.31189 to 3.30411, saving model to FMbest.hdf5\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.0745 - accuracy: 0.2467 - val_loss: 3.3472 - val_accuracy: 0.2098\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 3.30411\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.0717 - accuracy: 0.2464 - val_loss: 3.3364 - val_accuracy: 0.2108\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 3.30411\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 3.0842 - accuracy: 0.2433 - val_loss: 3.3398 - val_accuracy: 0.2075\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 3.30411\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.0631 - accuracy: 0.2458 - val_loss: 3.3392 - val_accuracy: 0.2093\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 3.30411\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.0422 - accuracy: 0.2525 - val_loss: 3.3204 - val_accuracy: 0.2189\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 3.30411\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.0316 - accuracy: 0.2540 - val_loss: 3.3093 - val_accuracy: 0.2157\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 3.30411\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.0467 - accuracy: 0.2515 - val_loss: 3.3058 - val_accuracy: 0.2200\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 3.30411\n",
            "Epoch 26/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.0150 - accuracy: 0.2565 - val_loss: 3.3183 - val_accuracy: 0.2188\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 3.30411\n",
            "Epoch 27/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 3.0188 - accuracy: 0.2559 - val_loss: 3.3275 - val_accuracy: 0.2140\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 3.30411\n",
            "Epoch 28/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 2.9972 - accuracy: 0.2572 - val_loss: 3.3186 - val_accuracy: 0.2196\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 3.30411\n",
            "Epoch 00028: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f678ab87690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk3GSXbfUI91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40cbd1b0-fff4-4a8e-b0e6-489324f9e4f5"
      },
      "source": [
        "# 학습된 모델을 이용하여 테스트하는 코드\n",
        "\n",
        "model.predict(X_test[0:1])\n",
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 3.3186 - accuracy: 0.2196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyz7CrMIUNJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f33900bb-1dcc-4d95-d9e2-d29a32d4dca4"
      },
      "source": [
        "model.load_weights(checkpoint_filepath)\n",
        "# best model을 이용한 테스트 데이터 예측 정확도 재확인 코드\n",
        "\n",
        "model.predict(X_test[0:1])\n",
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 3.3041 - accuracy: 0.2179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv_3xNMjzdLI"
      },
      "source": [
        "## 도전과제\n",
        "\n",
        "- 하이퍼 파라미터 튜닝을 사용하여 모델의 정확도를 최대한 높여보세요.\n",
        "- 교차 검증(CV) 기법을 사용하여 모델과 조금 더 일관된 결과를 얻어보세요.\n",
        "- 아직 이론을 배우진 않았지만, Cifar100의 분류문제를 효율적으로 찾기위한 방법을 찾아보세요. \n",
        "- 대부분의 문제풀이는 CNN을 통해서 해결했을 것입니다. \n",
        "- 이제 코드를 보는 방법이 조금씩 익숙해졌기 때문에 다른 사람들이 돌려놓은 파일을 이해해서 돌아가는 샘플코드를 만들어볼 수 있을 것입니다. \n",
        "- 남들이 작성해두었고, 돌아가는 코드를 찾아서 변환하는 것이기 때문에 CNN이라고 해서 어려울 것은 없습니다. \n",
        "- 아직 원리를 모르지만, cifar100 데이터셋을 이용하여 CNN 모델을 구축하고 기본적인 신경망의 결과와 비교해 보십시오. \n",
        "- [참조링크](https://www.kaggle.com/adi160/cifar-10-keras-transfer-learning)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQUAJg5mYLBV"
      },
      "source": [
        "### 신경망"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDklWAHqYTjm"
      },
      "source": [
        "#### 데이터불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RdyQ2P_lFlX"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 100\n",
        "epochs = 50\n",
        "\n",
        "# 데이터 불러오기\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "X_train = X_train / 255.0 \n",
        "X_test = X_test / 255.0 \n",
        "\n",
        "# X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=.2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkStH7FyFgra",
        "outputId": "2b84d98e-d99f-4704-8592-f57aac61dabf"
      },
      "source": [
        "[X_train.shape, y_train.shape]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(40000, 32, 32, 3), (40000, 100)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2qZnsoYYVdi"
      },
      "source": [
        "#### 모델제작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5-JemoY1J2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd26069e-f953-49e3-f554-9baa4c5a05a4"
      },
      "source": [
        "# transfer\n",
        "from keras.applications import VGG19, ResNet50\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "base_model_1 = VGG19(include_top=False, weights='imagenet', input_shape=(32,32,3), classes=y_train.shape[1])\n",
        "\n",
        "model_1= Sequential()\n",
        "model_1.add(base_model_1) \n",
        "model_1.add(Flatten()) \n",
        "\n",
        "#Add the Dense layers along with activation and batch normalization\n",
        "model_1.add(Dense(1024,activation=('relu'),input_dim=512))\n",
        "model_1.add(Dense(512,activation=('relu'))) \n",
        "model_1.add(Dense(256,activation=('relu'))) \n",
        "model_1.add(Dropout(.3)) #Adding a dropout layer that will randomly drop /30% of the weights\n",
        "model_1.add(Dense(128,activation=('relu')))\n",
        "model_1.add(Dropout(.2))\n",
        "model_1.add(Dense(num_classes,activation=('softmax'))) #This is the classification layer\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Functional)           (None, 1, 1, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 21,251,620\n",
            "Trainable params: 21,251,620\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77K0LG6pYXjs"
      },
      "source": [
        "#### 모델 fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-8tMvFy1kko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42561aa-3ce3-40f7-e9b0-ed38a175aa55"
      },
      "source": [
        "import keras \n",
        "\n",
        "learn_rate=.001\n",
        "\n",
        "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "model_1.compile(optimizer=sgd,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1)\n",
        "\n",
        "model_1.fit(X_train, y_train, batch_size=batch_size,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[early_stop],\n",
        "                    epochs=epochs, verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "391/391 [==============================] - 19s 44ms/step - loss: 4.5589 - accuracy: 0.0205 - val_loss: 3.9165 - val_accuracy: 0.1342\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 3.9106 - accuracy: 0.1187 - val_loss: 3.0882 - val_accuracy: 0.2640\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 3.2640 - accuracy: 0.2192 - val_loss: 2.6320 - val_accuracy: 0.3389\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.8477 - accuracy: 0.2894 - val_loss: 2.3447 - val_accuracy: 0.3976\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.5585 - accuracy: 0.3457 - val_loss: 2.2349 - val_accuracy: 0.4178\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.3293 - accuracy: 0.3928 - val_loss: 2.1042 - val_accuracy: 0.4472\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 2.1646 - accuracy: 0.4278 - val_loss: 2.0453 - val_accuracy: 0.4543\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 2.0202 - accuracy: 0.4608 - val_loss: 1.9934 - val_accuracy: 0.4652\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 1.9002 - accuracy: 0.4868 - val_loss: 1.8612 - val_accuracy: 0.4965\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 1.7904 - accuracy: 0.5145 - val_loss: 1.8298 - val_accuracy: 0.5090\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.6926 - accuracy: 0.5342 - val_loss: 1.7643 - val_accuracy: 0.5234\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 1.5680 - accuracy: 0.5684 - val_loss: 1.7704 - val_accuracy: 0.5270\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.4839 - accuracy: 0.5875 - val_loss: 1.7066 - val_accuracy: 0.5404\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 1.3789 - accuracy: 0.6179 - val_loss: 1.7304 - val_accuracy: 0.5399\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.2997 - accuracy: 0.6312 - val_loss: 1.7148 - val_accuracy: 0.5512\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.2085 - accuracy: 0.6565 - val_loss: 1.6723 - val_accuracy: 0.5581\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 1.1369 - accuracy: 0.6715 - val_loss: 1.7582 - val_accuracy: 0.5491\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 1.0667 - accuracy: 0.6908 - val_loss: 1.7360 - val_accuracy: 0.5522\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 0.9774 - accuracy: 0.7183 - val_loss: 1.7966 - val_accuracy: 0.5603\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 0.9007 - accuracy: 0.7335 - val_loss: 1.8059 - val_accuracy: 0.5578\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 0.8333 - accuracy: 0.7524 - val_loss: 1.8161 - val_accuracy: 0.5672\n",
            "Epoch 00021: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f83a55eb910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYWQl2YZgy"
      },
      "source": [
        "#### Visualize history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynoPTe_u10Jg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "d257b6e1-c9e1-4480-ca0b-8b600535c662"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f,ax=plt.subplots(2,1) #Creates 2 subplots under 1 column\n",
        "\n",
        "#Assign the first subplot to graph training loss and validation loss\n",
        "ax[0].plot(model_1.history.history['loss'],color='b',label='Training Loss')\n",
        "ax[0].plot(model_1.history.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "#Next lets plot the training accuracy and validation accuracy\n",
        "ax[1].plot(model_1.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
        "ax[1].plot(model_1.history.history['val_accuracy'],color='r',label='Validation Accuracy')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f83a531f390>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDhhZdbLdA49"
      },
      "source": [
        "#### test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdl_5S9xQ4Na",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbbe365f-47f9-4dac-a8c8-e602c38a61f2"
      },
      "source": [
        "model_1.predict(X_test)\n",
        "test_loss, test_acc = model_1.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 1.9139 - accuracy: 0.5470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfHTDU-YYbXk"
      },
      "source": [
        "### CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh3tnrbLYvMN"
      },
      "source": [
        "#### 모델제작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAZ_SYLPYcjk",
        "outputId": "e9e98761-8027-44e7-de90-9f24848eccb5"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32,32,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 270,372\n",
            "Trainable params: 270,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFeb4P5HY0Wy"
      },
      "source": [
        "#### 모델훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zaZ4rWqY1-X",
        "outputId": "f68e626b-9435-415b-8eaf-23cc2a9d8be6"
      },
      "source": [
        "learn_rate=.001\n",
        "\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "model.compile(optimizer=adam,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=batch_size,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=epochs, verbose=1)\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.7298 - accuracy: 0.5133 - val_loss: 3.6956 - val_accuracy: 0.3356\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.8860 - accuracy: 0.7287 - val_loss: 4.1809 - val_accuracy: 0.3324\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6527 - accuracy: 0.7899 - val_loss: 4.8308 - val_accuracy: 0.3319\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5007 - accuracy: 0.8363 - val_loss: 5.2112 - val_accuracy: 0.3290\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3863 - accuracy: 0.8703 - val_loss: 5.6783 - val_accuracy: 0.3342\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3017 - accuracy: 0.9012 - val_loss: 6.0775 - val_accuracy: 0.3306\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2674 - accuracy: 0.9118 - val_loss: 6.5409 - val_accuracy: 0.3364\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2474 - accuracy: 0.9166 - val_loss: 6.8302 - val_accuracy: 0.3349\n",
            "Epoch 9/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2259 - accuracy: 0.9234 - val_loss: 7.1325 - val_accuracy: 0.3297\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2230 - accuracy: 0.9240 - val_loss: 7.2718 - val_accuracy: 0.3267\n",
            "Epoch 11/50\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2288 - accuracy: 0.9231 - val_loss: 7.4018 - val_accuracy: 0.3271\n",
            "Epoch 12/50\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1759 - accuracy: 0.9420 - val_loss: 7.7037 - val_accuracy: 0.3283\n",
            "Epoch 13/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1974 - accuracy: 0.9340 - val_loss: 7.8681 - val_accuracy: 0.3195\n",
            "Epoch 14/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2396 - accuracy: 0.9187 - val_loss: 8.1172 - val_accuracy: 0.3225\n",
            "Epoch 15/50\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1942 - accuracy: 0.9338 - val_loss: 8.0585 - val_accuracy: 0.3261\n",
            "Epoch 16/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1843 - accuracy: 0.9357 - val_loss: 8.3619 - val_accuracy: 0.3279\n",
            "Epoch 17/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1688 - accuracy: 0.9438 - val_loss: 8.5781 - val_accuracy: 0.3271\n",
            "Epoch 18/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1636 - accuracy: 0.9463 - val_loss: 8.7567 - val_accuracy: 0.3286\n",
            "Epoch 19/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1910 - accuracy: 0.9361 - val_loss: 8.7615 - val_accuracy: 0.3271\n",
            "Epoch 20/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2079 - accuracy: 0.9330 - val_loss: 8.8530 - val_accuracy: 0.3259\n",
            "Epoch 21/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1701 - accuracy: 0.9430 - val_loss: 9.1140 - val_accuracy: 0.3284\n",
            "Epoch 22/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1382 - accuracy: 0.9533 - val_loss: 9.3036 - val_accuracy: 0.3230\n",
            "Epoch 23/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1783 - accuracy: 0.9414 - val_loss: 9.4043 - val_accuracy: 0.3190\n",
            "Epoch 24/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1691 - accuracy: 0.9423 - val_loss: 9.5742 - val_accuracy: 0.3225\n",
            "Epoch 25/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1533 - accuracy: 0.9499 - val_loss: 9.4970 - val_accuracy: 0.3201\n",
            "Epoch 26/50\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1565 - accuracy: 0.9458 - val_loss: 9.7394 - val_accuracy: 0.3264\n",
            "Epoch 27/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1980 - accuracy: 0.9346 - val_loss: 9.8277 - val_accuracy: 0.3188\n",
            "Epoch 28/50\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1407 - accuracy: 0.9523 - val_loss: 9.7627 - val_accuracy: 0.3132\n",
            "Epoch 29/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1601 - accuracy: 0.9478 - val_loss: 9.7938 - val_accuracy: 0.3265\n",
            "Epoch 30/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1171 - accuracy: 0.9605 - val_loss: 9.8743 - val_accuracy: 0.3204\n",
            "Epoch 31/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1555 - accuracy: 0.9489 - val_loss: 10.1993 - val_accuracy: 0.3192\n",
            "Epoch 32/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1736 - accuracy: 0.9450 - val_loss: 10.1272 - val_accuracy: 0.3230\n",
            "Epoch 33/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1632 - accuracy: 0.9479 - val_loss: 10.2401 - val_accuracy: 0.3206\n",
            "Epoch 34/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1746 - accuracy: 0.9419 - val_loss: 10.3147 - val_accuracy: 0.3222\n",
            "Epoch 35/50\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1482 - accuracy: 0.9506 - val_loss: 10.3266 - val_accuracy: 0.3266\n",
            "Epoch 36/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1296 - accuracy: 0.9579 - val_loss: 10.5196 - val_accuracy: 0.3147\n",
            "Epoch 37/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1846 - accuracy: 0.9411 - val_loss: 10.4183 - val_accuracy: 0.3201\n",
            "Epoch 38/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1404 - accuracy: 0.9547 - val_loss: 10.6625 - val_accuracy: 0.3199\n",
            "Epoch 39/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1332 - accuracy: 0.9550 - val_loss: 10.7026 - val_accuracy: 0.3212\n",
            "Epoch 40/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1701 - accuracy: 0.9442 - val_loss: 10.7404 - val_accuracy: 0.3186\n",
            "Epoch 41/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1312 - accuracy: 0.9577 - val_loss: 10.8887 - val_accuracy: 0.3242\n",
            "Epoch 42/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1465 - accuracy: 0.9510 - val_loss: 10.9582 - val_accuracy: 0.3229\n",
            "Epoch 43/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1384 - accuracy: 0.9541 - val_loss: 10.9309 - val_accuracy: 0.3173\n",
            "Epoch 44/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1601 - accuracy: 0.9491 - val_loss: 11.1106 - val_accuracy: 0.3219\n",
            "Epoch 45/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1258 - accuracy: 0.9581 - val_loss: 11.3622 - val_accuracy: 0.3151\n",
            "Epoch 46/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1728 - accuracy: 0.9455 - val_loss: 11.1703 - val_accuracy: 0.3176\n",
            "Epoch 47/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1505 - accuracy: 0.9499 - val_loss: 11.1895 - val_accuracy: 0.3175\n",
            "Epoch 48/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1330 - accuracy: 0.9576 - val_loss: 11.4109 - val_accuracy: 0.3237\n",
            "Epoch 49/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1423 - accuracy: 0.9538 - val_loss: 11.6017 - val_accuracy: 0.3217\n",
            "Epoch 50/50\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1965 - accuracy: 0.9384 - val_loss: 11.3390 - val_accuracy: 0.3207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8bea78f1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7zPZ23DY0Tw"
      },
      "source": [
        "#### Visualize history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "iEVxuv1vci34",
        "outputId": "b22449ae-64ac-4d69-ba80-c82c9892c2f8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f,ax=plt.subplots(2,1) #Creates 2 subplots under 1 column\n",
        "\n",
        "#Assign the first subplot to graph training loss and validation loss\n",
        "ax[0].plot(model.history.history['loss'],color='b',label='Training Loss')\n",
        "ax[0].plot(model.history.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "#Next lets plot the training accuracy and validation accuracy\n",
        "ax[1].plot(model.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
        "ax[1].plot(model.history.history['val_accuracy'],color='r',label='Validation Accuracy')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8bceeedc10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Pz-qR3_dD4v"
      },
      "source": [
        "#### test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIDi9isdsRTl",
        "outputId": "02036fd5-188b-4f91-ab5b-3e2a7a0325d2"
      },
      "source": [
        "## ANN\n",
        "model_1.predict(X_test)\n",
        "test_loss, test_acc = model_1.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 1.9139 - accuracy: 0.5470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq2gmH48dE8F",
        "outputId": "8548705b-0259-498e-b598-5c110b0ae7d3"
      },
      "source": [
        "## CNN\n",
        "model.predict(X_test)\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 11.0041 - accuracy: 0.3158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaABveg1c3Es"
      },
      "source": [
        "#### 중간점검"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F_D29s9c2_H"
      },
      "source": [
        "기본적인 ANN모델은 테스트셋에서 정확도가 0.5470이었는데 CNN모델에서는 0.3158이었다. ANN은 캐글 작성자가 열심히 조정해놓은 것이니까, CNN을 조정해서 ANN보다 좋게 만들어 보자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMxTkOP2c24c"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBjbyIwOqOPG"
      },
      "source": [
        "#### 모델링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up1BiCQ-dr5J"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPool2D\n",
        "from keras.layers.core import Dense,Activation,Dropout,Flatten\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, optimizers\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "num_classes=100\n",
        "\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test / 255.\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# Create Model(CNN + Dropout)\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        " \n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBbEA8ILqP4u"
      },
      "source": [
        "#### 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vst7iK04vC7O",
        "outputId": "435adb3f-7230-4e9a-f039-1ed70c491448"
      },
      "source": [
        "# Training\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "\n",
        "checkpoint_filepath = \"cifar.hdf5\"\n",
        "save_best = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
        "    save_weights_only=True, mode='auto', save_freq='epoch', options=None)\n",
        "\n",
        "history = model.fit(X_train, y_train\n",
        "                    , batch_size=64\n",
        "                    , epochs=100\n",
        "                    , validation_data=(X_test, y_test)\n",
        "                    , verbose=1\n",
        "                    , callbacks=[early_stop, save_best])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "782/782 [==============================] - 37s 8ms/step - loss: 4.5217 - accuracy: 0.0312 - val_loss: 3.8341 - val_accuracy: 0.0964\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.83407, saving model to cifar.hdf5\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 3.8235 - accuracy: 0.1066 - val_loss: 3.2872 - val_accuracy: 0.1948\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.83407 to 3.28716, saving model to cifar.hdf5\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 3.3982 - accuracy: 0.1754 - val_loss: 3.2555 - val_accuracy: 0.2048\n",
            "\n",
            "Epoch 00003: val_loss improved from 3.28716 to 3.25553, saving model to cifar.hdf5\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 3.0428 - accuracy: 0.2414 - val_loss: 2.6684 - val_accuracy: 0.3184\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.25553 to 2.66837, saving model to cifar.hdf5\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.7576 - accuracy: 0.2922 - val_loss: 2.4107 - val_accuracy: 0.3646\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.66837 to 2.41069, saving model to cifar.hdf5\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.5552 - accuracy: 0.3325 - val_loss: 2.2772 - val_accuracy: 0.3984\n",
            "\n",
            "Epoch 00006: val_loss improved from 2.41069 to 2.27717, saving model to cifar.hdf5\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.3761 - accuracy: 0.3654 - val_loss: 2.2936 - val_accuracy: 0.3960\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 2.27717\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.2379 - accuracy: 0.4023 - val_loss: 2.1142 - val_accuracy: 0.4453\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.27717 to 2.11416, saving model to cifar.hdf5\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.1098 - accuracy: 0.4284 - val_loss: 1.9661 - val_accuracy: 0.4674\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.11416 to 1.96605, saving model to cifar.hdf5\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 2.0273 - accuracy: 0.4455 - val_loss: 1.9424 - val_accuracy: 0.4783\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.96605 to 1.94235, saving model to cifar.hdf5\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.9159 - accuracy: 0.4689 - val_loss: 1.8872 - val_accuracy: 0.4862\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.94235 to 1.88721, saving model to cifar.hdf5\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.8409 - accuracy: 0.4865 - val_loss: 1.8480 - val_accuracy: 0.4956\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.88721 to 1.84801, saving model to cifar.hdf5\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.7692 - accuracy: 0.5052 - val_loss: 1.9330 - val_accuracy: 0.4838\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.84801\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.6961 - accuracy: 0.5216 - val_loss: 1.7822 - val_accuracy: 0.5158\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.84801 to 1.78221, saving model to cifar.hdf5\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.6407 - accuracy: 0.5341 - val_loss: 1.7848 - val_accuracy: 0.5148\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.78221\n",
            "Epoch 16/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.6043 - accuracy: 0.5415 - val_loss: 1.8178 - val_accuracy: 0.5153\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.78221\n",
            "Epoch 17/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.5361 - accuracy: 0.5642 - val_loss: 1.8530 - val_accuracy: 0.5080\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.78221\n",
            "Epoch 18/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4968 - accuracy: 0.5696 - val_loss: 1.7842 - val_accuracy: 0.5206\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.78221\n",
            "Epoch 19/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4505 - accuracy: 0.5822 - val_loss: 1.7187 - val_accuracy: 0.5327\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.78221 to 1.71866, saving model to cifar.hdf5\n",
            "Epoch 20/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4283 - accuracy: 0.5856 - val_loss: 1.7124 - val_accuracy: 0.5408\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.71866 to 1.71239, saving model to cifar.hdf5\n",
            "Epoch 21/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3942 - accuracy: 0.5949 - val_loss: 1.6986 - val_accuracy: 0.5382\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.71239 to 1.69861, saving model to cifar.hdf5\n",
            "Epoch 22/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3414 - accuracy: 0.6063 - val_loss: 1.7266 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.69861\n",
            "Epoch 23/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3233 - accuracy: 0.6141 - val_loss: 1.6852 - val_accuracy: 0.5477\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.69861 to 1.68517, saving model to cifar.hdf5\n",
            "Epoch 24/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3108 - accuracy: 0.6146 - val_loss: 1.6879 - val_accuracy: 0.5490\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.68517\n",
            "Epoch 25/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2693 - accuracy: 0.6205 - val_loss: 1.6467 - val_accuracy: 0.5557\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.68517 to 1.64667, saving model to cifar.hdf5\n",
            "Epoch 26/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2426 - accuracy: 0.6321 - val_loss: 1.7291 - val_accuracy: 0.5359\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.64667\n",
            "Epoch 27/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2323 - accuracy: 0.6358 - val_loss: 1.6476 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.64667\n",
            "Epoch 28/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2112 - accuracy: 0.6412 - val_loss: 1.6967 - val_accuracy: 0.5495\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.64667\n",
            "Epoch 29/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1853 - accuracy: 0.6448 - val_loss: 1.6985 - val_accuracy: 0.5503\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.64667\n",
            "Epoch 30/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1784 - accuracy: 0.6482 - val_loss: 1.7497 - val_accuracy: 0.5477\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.64667\n",
            "Epoch 31/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1485 - accuracy: 0.6558 - val_loss: 1.6894 - val_accuracy: 0.5517\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.64667\n",
            "Epoch 32/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1350 - accuracy: 0.6618 - val_loss: 1.7199 - val_accuracy: 0.5417\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.64667\n",
            "Epoch 33/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1159 - accuracy: 0.6634 - val_loss: 1.6822 - val_accuracy: 0.5582\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.64667\n",
            "Epoch 34/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0978 - accuracy: 0.6688 - val_loss: 1.6832 - val_accuracy: 0.5632\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.64667\n",
            "Epoch 35/100\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0892 - accuracy: 0.6713 - val_loss: 1.7015 - val_accuracy: 0.5565\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.64667\n",
            "Epoch 00035: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oChXabIKqBKd"
      },
      "source": [
        "#### Visualize history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "bnRMYSh1Cp6F",
        "outputId": "79be2d29-42c9-4f71-b2d4-df2dc279ad84"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f,ax=plt.subplots(2,1) #Creates 2 subplots under 1 column\n",
        "\n",
        "#Assign the first subplot to graph training loss and validation loss\n",
        "ax[0].plot(model.history.history['loss'],color='b',label='Training Loss')\n",
        "ax[0].plot(model.history.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "#Next lets plot the training accuracy and validation accuracy\n",
        "ax[1].plot(model.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
        "ax[1].plot(model.history.history['val_accuracy'],color='r',label='Validation Accuracy')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f833eef19d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92DCaiusC30W"
      },
      "source": [
        "### 중간점검2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEaUKRkwqGph"
      },
      "source": [
        "#### 비교"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWj9-ZbGCxN0",
        "outputId": "f4d9ae60-e91f-4e1e-dedb-05d65aed263b"
      },
      "source": [
        "## ANN\n",
        "model_1.predict(X_test)\n",
        "test_loss, test_acc = model_1.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 1.8161 - accuracy: 0.5672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN9xVf73C6LY",
        "outputId": "c8a6a260-57f1-483e-9549-188f376300cc"
      },
      "source": [
        "## CNN\n",
        "model.predict(X_test)\n",
        "model.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 1.7015 - accuracy: 0.5565\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7014621496200562, 0.5565000176429749]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV7l5XVxDXM8"
      },
      "source": [
        "수많은 변경 끝에 ANN보다 살짝 나은 정도의 성능을 내는 CNN모델을 만들었다. 클래스가 100개인 데이터를 분류하기는 정말 힘들다.\n",
        "\n",
        "ANN이 저렇게 좋을 수 있는 이유가\n",
        "VGG19라는 구조때문이다. 빼고 돌려보자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIXcCiMVqINV"
      },
      "source": [
        "#### without vgg19\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0ejcmePFart",
        "outputId": "636e2fd7-25f9-4b56-c0ac-033146172993"
      },
      "source": [
        "## without VGG19\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 100\n",
        "epochs = 50\n",
        "\n",
        "# 데이터 불러오기\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "X_train = X_train / 255.0 \n",
        "X_test = X_test / 255.0 \n",
        "\n",
        "# transfer\n",
        "from keras.applications import VGG19, ResNet50\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "\n",
        "model_1= Sequential()\n",
        "model_1.add(Flatten(input_shape=(32, 32, 3))) \n",
        "\n",
        "model_1.add(Dense(1024,activation=('relu')))\n",
        "model_1.add(Dense(512,activation=('relu'))) \n",
        "model_1.add(Dense(256,activation=('relu'))) \n",
        "model_1.add(Dropout(.3)) #Adding a dropout layer that will randomly drop /30% of the weights\n",
        "model_1.add(Dense(128,activation=('relu')))\n",
        "model_1.add(Dropout(.2))\n",
        "model_1.add(Dense(num_classes,activation=('softmax'))) #This is the classification layer\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_10 (Flatten)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 1024)              3146752   \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 3,848,676\n",
            "Trainable params: 3,848,676\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNurjJUkFg4r",
        "outputId": "7c8fa939-f768-41c4-d916-97f6be7418ba"
      },
      "source": [
        "import keras \n",
        "\n",
        "learn_rate=.001\n",
        "\n",
        "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "model_1.compile(optimizer=sgd,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1)\n",
        "\n",
        "model_1.fit(X_train, y_train, batch_size=batch_size,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[early_stop],\n",
        "                    epochs=epochs, verbose=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 4.6063 - accuracy: 0.0140 - val_loss: 4.5274 - val_accuracy: 0.0428\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 4.5193 - accuracy: 0.0326 - val_loss: 4.3945 - val_accuracy: 0.0497\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 4.4042 - accuracy: 0.0451 - val_loss: 4.2527 - val_accuracy: 0.0639\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 4.2920 - accuracy: 0.0524 - val_loss: 4.1427 - val_accuracy: 0.0792\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 4.2081 - accuracy: 0.0621 - val_loss: 4.0598 - val_accuracy: 0.0945\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 4.1309 - accuracy: 0.0696 - val_loss: 3.9836 - val_accuracy: 0.1084\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 4.0717 - accuracy: 0.0778 - val_loss: 3.9291 - val_accuracy: 0.1172\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 4.0168 - accuracy: 0.0855 - val_loss: 3.8757 - val_accuracy: 0.1216\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.9636 - accuracy: 0.0925 - val_loss: 3.8410 - val_accuracy: 0.1291\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.9316 - accuracy: 0.0969 - val_loss: 3.7960 - val_accuracy: 0.1298\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.8980 - accuracy: 0.1039 - val_loss: 3.7649 - val_accuracy: 0.1403\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.8592 - accuracy: 0.1096 - val_loss: 3.7386 - val_accuracy: 0.1446\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.8410 - accuracy: 0.1147 - val_loss: 3.7159 - val_accuracy: 0.1489\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.8052 - accuracy: 0.1160 - val_loss: 3.6877 - val_accuracy: 0.1516\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.7812 - accuracy: 0.1273 - val_loss: 3.6700 - val_accuracy: 0.1561\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.7503 - accuracy: 0.1321 - val_loss: 3.6446 - val_accuracy: 0.1584\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.7361 - accuracy: 0.1321 - val_loss: 3.6237 - val_accuracy: 0.1589\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.7128 - accuracy: 0.1328 - val_loss: 3.6004 - val_accuracy: 0.1670\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.6839 - accuracy: 0.1394 - val_loss: 3.5881 - val_accuracy: 0.1675\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.6733 - accuracy: 0.1426 - val_loss: 3.5640 - val_accuracy: 0.1751\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.6507 - accuracy: 0.1437 - val_loss: 3.5517 - val_accuracy: 0.1753\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.6291 - accuracy: 0.1501 - val_loss: 3.5332 - val_accuracy: 0.1792\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.6112 - accuracy: 0.1526 - val_loss: 3.5292 - val_accuracy: 0.1763\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.5884 - accuracy: 0.1581 - val_loss: 3.4971 - val_accuracy: 0.1846\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.5913 - accuracy: 0.1569 - val_loss: 3.4816 - val_accuracy: 0.1854\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.5509 - accuracy: 0.1637 - val_loss: 3.4659 - val_accuracy: 0.1882\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.5380 - accuracy: 0.1667 - val_loss: 3.4663 - val_accuracy: 0.1868\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.5065 - accuracy: 0.1678 - val_loss: 3.4441 - val_accuracy: 0.1921\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.4970 - accuracy: 0.1709 - val_loss: 3.4229 - val_accuracy: 0.1941\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.4821 - accuracy: 0.1747 - val_loss: 3.4254 - val_accuracy: 0.1927\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.4774 - accuracy: 0.1752 - val_loss: 3.4084 - val_accuracy: 0.1985\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.4521 - accuracy: 0.1787 - val_loss: 3.3933 - val_accuracy: 0.2000\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 3.4319 - accuracy: 0.1819 - val_loss: 3.3777 - val_accuracy: 0.2063\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.4218 - accuracy: 0.1840 - val_loss: 3.3814 - val_accuracy: 0.1983\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.4096 - accuracy: 0.1860 - val_loss: 3.3542 - val_accuracy: 0.2067\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.3907 - accuracy: 0.1906 - val_loss: 3.3678 - val_accuracy: 0.2074\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.3820 - accuracy: 0.1931 - val_loss: 3.3349 - val_accuracy: 0.2108\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.3579 - accuracy: 0.1950 - val_loss: 3.3189 - val_accuracy: 0.2165\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.3368 - accuracy: 0.1964 - val_loss: 3.3069 - val_accuracy: 0.2158\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.3335 - accuracy: 0.2024 - val_loss: 3.2989 - val_accuracy: 0.2174\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.3199 - accuracy: 0.2010 - val_loss: 3.3049 - val_accuracy: 0.2176\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.3150 - accuracy: 0.2001 - val_loss: 3.2867 - val_accuracy: 0.2211\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.2942 - accuracy: 0.2093 - val_loss: 3.2755 - val_accuracy: 0.2236\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.2787 - accuracy: 0.2077 - val_loss: 3.2640 - val_accuracy: 0.2250\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.2664 - accuracy: 0.2086 - val_loss: 3.2724 - val_accuracy: 0.2221\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.2496 - accuracy: 0.2138 - val_loss: 3.2840 - val_accuracy: 0.2165\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.2520 - accuracy: 0.2148 - val_loss: 3.2672 - val_accuracy: 0.2235\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.2404 - accuracy: 0.2137 - val_loss: 3.2499 - val_accuracy: 0.2251\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.2208 - accuracy: 0.2188 - val_loss: 3.2253 - val_accuracy: 0.2292\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 3.2094 - accuracy: 0.2192 - val_loss: 3.2221 - val_accuracy: 0.2316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f83a5d73c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KuEOPxwG0zO",
        "outputId": "0baf1a56-72cd-4d2e-c9b0-b7b9dfe7fa8e"
      },
      "source": [
        "## ANN\n",
        "model_1.predict(X_test)\n",
        "test_loss, test_acc = model_1.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 3.2221 - accuracy: 0.2316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atWhPh1-Ggld"
      },
      "source": [
        "### VGG19\n",
        "\n",
        "새로만든 CNN의 성능이 문제가 아니었고, VGG19라는 아키텍쳐가 성능이 좋은 것이었다. VGG19구조를 빼고 단순한 인공신경망으로 진행하니 정확도가 반이 떨어졌다. 그렇다면 VGG가 무엇인가? \n",
        "\n",
        "VGG19는 이미지에서 성능이 매우 좋은 pre trained 모델 중에 하나이다. 이미 VGG19라는 architecture에는 convolution을 포함하는 여러개의 블록이 있다. 아래는 VGG19를 CNN으로 직접 구현한 코드이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqoQmNmwIFR1"
      },
      "source": [
        "#### CNN : VGG19 Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DeViQLzIQQj",
        "outputId": "f8768acc-311e-4c29-f240-bd266aea4c92"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.datasets import cifar100\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from keras.initializers import he_normal\n",
        "from keras import optimizers\n",
        "from keras.callbacks import LearningRateScheduler, TensorBoard\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils.data_utils import get_file\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_classes = 100\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "iterations = 391\n",
        "dropout = 0.5\n",
        "weight_decay = 0.0001\n",
        "log_filepath = r'./vgg19_retrain_logs/'\n",
        "\n",
        "\n",
        "def scheduler(epoch):\n",
        "    if epoch < 80:\n",
        "        return 0.1\n",
        "    if epoch < 160:\n",
        "        return 0.01\n",
        "    return 0.001\n",
        "\n",
        "\n",
        "# data loading\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# data preprocessing\n",
        "x_train[:, :, :, 0] = (x_train[:, :, :, 0]-123.680)\n",
        "x_train[:, :, :, 1] = (x_train[:, :, :, 1]-116.779)\n",
        "x_train[:, :, :, 2] = (x_train[:, :, :, 2]-103.939)\n",
        "x_test[:, :, :, 0] = (x_test[:, :, :, 0]-123.680)\n",
        "x_test[:, :, :, 1] = (x_test[:, :, :, 1]-116.779)\n",
        "x_test[:, :, :, 2] = (x_test[:, :, :, 2]-103.939)\n",
        "\n",
        "# build model\n",
        "model = Sequential()\n",
        "\n",
        "# Block 1\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block1_conv1', input_shape=x_train.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block1_conv2'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
        "\n",
        "# Block 2\n",
        "model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block2_conv1'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block2_conv2'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
        "\n",
        "# Block 3\n",
        "model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block3_conv1'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block3_conv2'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block3_conv3'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block3_conv4'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
        "\n",
        "# Block 4\n",
        "model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block4_conv1'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block4_conv2'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block4_conv3'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block4_conv4'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
        "\n",
        "# Block 5\n",
        "model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block5_conv1'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block5_conv2'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block5_conv3'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                 kernel_initializer=he_normal(), name='block5_conv4'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
        "\n",
        "# model modification for cifar-10\n",
        "model.add(Flatten(name='flatten'))\n",
        "model.add(Dense(4096, use_bias=True, kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                kernel_initializer=he_normal(), name='fc_cifa10'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(4096, kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                kernel_initializer=he_normal(), name='fc2'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(100, kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
        "                kernel_initializer=he_normal(), name='predictions_cifa10'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# load pretrained weight from VGG19 by name\n",
        "# model.load_weights(filepath, by_name=True)\n",
        "\n",
        "# optimizer\n",
        "sgd = optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "tb_cb = TensorBoard(log_dir=log_filepath, histogram_freq=0)\n",
        "change_lr = LearningRateScheduler(scheduler)\n",
        "cbks = [change_lr, tb_cb]\n",
        "\n",
        "print('Using real-time data augmentation.')\n",
        "datagen = ImageDataGenerator(horizontal_flip=True,\n",
        "                             width_shift_range=0.125, height_shift_range=0.125, fill_mode='constant', cval=0.)\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1amK6GJgIfE-",
        "outputId": "daa1b30b-6c8a-448d-ac7f-19024b440240"
      },
      "source": [
        "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                              steps_per_epoch=iterations,\n",
        "                              epochs=epochs,\n",
        "                              callbacks=cbks,\n",
        "                              validation_data=(x_test, y_test))\n",
        "model.save('retrain.h5')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "391/391 [==============================] - 32s 81ms/step - loss: 7.3109 - accuracy: 0.0165 - val_loss: 7.1567 - val_accuracy: 0.0102\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 6.7764 - accuracy: 0.0269 - val_loss: 6.8625 - val_accuracy: 0.0116\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 6.1555 - accuracy: 0.0499 - val_loss: 6.1232 - val_accuracy: 0.0467\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 5.6922 - accuracy: 0.0732 - val_loss: 5.7532 - val_accuracy: 0.0666\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 5.3356 - accuracy: 0.0913 - val_loss: 5.6037 - val_accuracy: 0.0611\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 4.9273 - accuracy: 0.1186 - val_loss: 5.1712 - val_accuracy: 0.0853\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 4.6097 - accuracy: 0.1451 - val_loss: 4.7377 - val_accuracy: 0.1255\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 4.3691 - accuracy: 0.1647 - val_loss: 4.5299 - val_accuracy: 0.1402\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 4.1534 - accuracy: 0.1848 - val_loss: 4.6710 - val_accuracy: 0.1198\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 3.9815 - accuracy: 0.2026 - val_loss: 4.3792 - val_accuracy: 0.1524\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 3.8270 - accuracy: 0.2193 - val_loss: 4.0404 - val_accuracy: 0.1749\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 3.7026 - accuracy: 0.2363 - val_loss: 4.3911 - val_accuracy: 0.1475\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 3.6011 - accuracy: 0.2508 - val_loss: 4.1332 - val_accuracy: 0.1862\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 3.5127 - accuracy: 0.2603 - val_loss: 4.1203 - val_accuracy: 0.1724\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 3.4554 - accuracy: 0.2722 - val_loss: 4.3858 - val_accuracy: 0.1787\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 3.3632 - accuracy: 0.2872 - val_loss: 3.8423 - val_accuracy: 0.2236\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 3.1308 - accuracy: 0.3261 - val_loss: 3.7276 - val_accuracy: 0.2435\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 3.0182 - accuracy: 0.3527 - val_loss: 3.7676 - val_accuracy: 0.2470\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.9466 - accuracy: 0.3695 - val_loss: 3.3528 - val_accuracy: 0.2939\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.9016 - accuracy: 0.3861 - val_loss: 3.4693 - val_accuracy: 0.3195\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.8497 - accuracy: 0.4010 - val_loss: 3.2411 - val_accuracy: 0.3496\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.8095 - accuracy: 0.4161 - val_loss: 3.2159 - val_accuracy: 0.3454\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.7808 - accuracy: 0.4249 - val_loss: 3.1874 - val_accuracy: 0.3675\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 2.7518 - accuracy: 0.4399 - val_loss: 3.7714 - val_accuracy: 0.2925\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 2.7426 - accuracy: 0.4470 - val_loss: 3.1391 - val_accuracy: 0.3715\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.7129 - accuracy: 0.4582 - val_loss: 3.2925 - val_accuracy: 0.3735\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6956 - accuracy: 0.4672 - val_loss: 3.1887 - val_accuracy: 0.3942\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6825 - accuracy: 0.4771 - val_loss: 3.3062 - val_accuracy: 0.3634\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6748 - accuracy: 0.4865 - val_loss: 3.3142 - val_accuracy: 0.3843\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6721 - accuracy: 0.4922 - val_loss: 3.3063 - val_accuracy: 0.3877\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6603 - accuracy: 0.4988 - val_loss: 3.3107 - val_accuracy: 0.3925\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6724 - accuracy: 0.5050 - val_loss: 3.2190 - val_accuracy: 0.4189\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6631 - accuracy: 0.5134 - val_loss: 3.3537 - val_accuracy: 0.3832\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 2.6513 - accuracy: 0.5192 - val_loss: 3.7894 - val_accuracy: 0.3499\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6569 - accuracy: 0.5261 - val_loss: 3.3670 - val_accuracy: 0.3926\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6482 - accuracy: 0.5306 - val_loss: 3.5680 - val_accuracy: 0.3654\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6614 - accuracy: 0.5322 - val_loss: 3.1382 - val_accuracy: 0.4521\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6295 - accuracy: 0.5425 - val_loss: 3.6199 - val_accuracy: 0.3821\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6532 - accuracy: 0.5432 - val_loss: 3.6716 - val_accuracy: 0.3532\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6603 - accuracy: 0.5464 - val_loss: 3.2486 - val_accuracy: 0.4527\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6392 - accuracy: 0.5560 - val_loss: 3.4614 - val_accuracy: 0.4195\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6418 - accuracy: 0.5585 - val_loss: 3.5181 - val_accuracy: 0.3993\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6559 - accuracy: 0.5599 - val_loss: 3.1851 - val_accuracy: 0.4638\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6636 - accuracy: 0.5631 - val_loss: 3.2684 - val_accuracy: 0.4505\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 2.6530 - accuracy: 0.5703 - val_loss: 3.7179 - val_accuracy: 0.3680\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6592 - accuracy: 0.5706 - val_loss: 4.0990 - val_accuracy: 0.3406\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6632 - accuracy: 0.5769 - val_loss: 3.3018 - val_accuracy: 0.4589\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6713 - accuracy: 0.5767 - val_loss: 3.3331 - val_accuracy: 0.4551\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 2.6850 - accuracy: 0.5764 - val_loss: 4.0678 - val_accuracy: 0.3448\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 30s 77ms/step - loss: 2.6652 - accuracy: 0.5838 - val_loss: 3.7086 - val_accuracy: 0.4099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "KnMhnrxXI3XP",
        "outputId": "08902b77-c765-4624-a102-16310bbfa152"
      },
      "source": [
        "loss = history.history.get('loss')\n",
        "acc = history.history.get('accuracy')\n",
        "val_loss = history.history.get('val_loss')\n",
        "val_acc = history.history.get('val_accuracy')\n",
        "\n",
        "plt.figure(0)\n",
        "plt.subplot(121)\n",
        "plt.plot(range(len(loss)), loss, label=\"Training\")\n",
        "plt.plot(range(len(val_loss)), val_loss, label='Validation')\n",
        "plt.title('Loss')\n",
        "plt.legend(loc='upper left')\n",
        "plt.subplot(122)\n",
        "plt.plot(range(len(acc)), acc, label='Training')\n",
        "plt.plot(range(len(val_acc)), val_acc, label='Validation')\n",
        "plt.title('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLpYuq1iYKEs"
      },
      "source": [
        "#### VGG19 구조파악하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v39zDLh2WjJh",
        "outputId": "7c0d07b2-dbb8-4a5e-f25e-5b4d469da08d"
      },
      "source": [
        "from keras.applications.vgg19 import VGG19\n",
        "get_inside = VGG19()\n",
        "print(get_inside.summary())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574717952/574710816 [==============================] - 5s 0us/step\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 143,667,240\n",
            "Trainable params: 143,667,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o4l9s_SkFhc"
      },
      "source": [
        "VGG19를 import하면 구조자체를바꾸는 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG8v924wtO6T"
      },
      "source": [
        "### CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu-PiXqotQUo",
        "outputId": "634a2a14-d621-444e-9c4c-70d2386e395c"
      },
      "source": [
        "import keras \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.applications import VGG19, ResNet50\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "## init\n",
        "batch_size = 128\n",
        "num_classes = 100\n",
        "epochs = 50\n",
        "learn_rate=.001\n",
        "n_fold=5\n",
        "\n",
        "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
        "\n",
        "accuracy=[]\n",
        "\n",
        "## load data\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "X_train = X_train / 255.0 \n",
        "X_test = X_test / 255.0 \n",
        "\n",
        "\n",
        "# transfer\n",
        "for train, val in skf.split(X_train,y_train):\n",
        "  base_model_1 = VGG19(include_top=False, weights='imagenet', input_shape=(32,32,3), classes=y_train.shape[1])\n",
        "\n",
        "  model_1= Sequential()\n",
        "  model_1.add(base_model_1) \n",
        "  model_1.add(Flatten()) \n",
        "\n",
        "  model_1.add(Dense(1024,activation=('relu'),input_dim=512))\n",
        "  model_1.add(Dense(512,activation=('relu'))) \n",
        "  model_1.add(Dense(256,activation=('relu'))) \n",
        "  model_1.add(Dropout(.3)) #Adding a dropout layer that will randomly drop /30% of the weights\n",
        "  model_1.add(Dense(128,activation=('relu')))\n",
        "  model_1.add(Dropout(.2))\n",
        "  model_1.add(Dense(num_classes,activation=('softmax'))) #This is the classification layer\n",
        "\n",
        "  model_1.compile(optimizer=sgd\n",
        "                  ,loss='sparse_categorical_crossentropy'\n",
        "                  ,metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  history = model_1.fit(X_train, y_train\n",
        "                        , batch_size=batch_size\n",
        "                        , validation_data=(X_test, y_test)\n",
        "                        , callbacks=[early_stop]\n",
        "                        , epochs=epochs\n",
        "                        , verbose=1)\n",
        "\n",
        "  accuracy_history = history.history['accuracy']\n",
        "  val_accuracy_history = history.history['val_accuracy']\n",
        "  \n",
        "  k_accuracy = f\"{model.evaluate(X_train[val],y_train[val])[1]:.4f}\"\n",
        "  accuracy.append([k_accuracy,accuracy_history,val_accuracy_history])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "391/391 [==============================] - 25s 45ms/step - loss: 4.5609 - accuracy: 0.0206 - val_loss: 3.9638 - val_accuracy: 0.1343\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 3.9222 - accuracy: 0.1168 - val_loss: 3.0913 - val_accuracy: 0.2645\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 3.2820 - accuracy: 0.2205 - val_loss: 2.6855 - val_accuracy: 0.3293\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.8552 - accuracy: 0.2864 - val_loss: 2.3965 - val_accuracy: 0.3838\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.5707 - accuracy: 0.3422 - val_loss: 2.2818 - val_accuracy: 0.4144\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.3501 - accuracy: 0.3879 - val_loss: 2.1162 - val_accuracy: 0.4428\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.1755 - accuracy: 0.4280 - val_loss: 2.0255 - val_accuracy: 0.4632\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.0271 - accuracy: 0.4629 - val_loss: 1.9276 - val_accuracy: 0.4780\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 1.9026 - accuracy: 0.4915 - val_loss: 1.8661 - val_accuracy: 0.4988\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 1.8023 - accuracy: 0.5132 - val_loss: 1.8611 - val_accuracy: 0.5060\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.7002 - accuracy: 0.5370 - val_loss: 1.7721 - val_accuracy: 0.5234\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.5679 - accuracy: 0.5684 - val_loss: 1.7698 - val_accuracy: 0.5347\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.4895 - accuracy: 0.5859 - val_loss: 1.6929 - val_accuracy: 0.5405\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.3833 - accuracy: 0.6146 - val_loss: 1.7149 - val_accuracy: 0.5434\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.2945 - accuracy: 0.6325 - val_loss: 1.7166 - val_accuracy: 0.5494\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 16s 42ms/step - loss: 1.2146 - accuracy: 0.6543 - val_loss: 1.7006 - val_accuracy: 0.5543\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.1392 - accuracy: 0.6716 - val_loss: 1.7112 - val_accuracy: 0.5542\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.0553 - accuracy: 0.6966 - val_loss: 1.7525 - val_accuracy: 0.5514\n",
            "Epoch 00018: early stopping\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 3.0567 - accuracy: 0.2559\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 18s 43ms/step - loss: 4.5678 - accuracy: 0.0183 - val_loss: 3.9999 - val_accuracy: 0.1254\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 3.9703 - accuracy: 0.1110 - val_loss: 3.2110 - val_accuracy: 0.2387\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 3.3475 - accuracy: 0.2012 - val_loss: 2.7307 - val_accuracy: 0.3174\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.9195 - accuracy: 0.2806 - val_loss: 2.4478 - val_accuracy: 0.3745\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.6402 - accuracy: 0.3322 - val_loss: 2.3616 - val_accuracy: 0.3912\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.3826 - accuracy: 0.3824 - val_loss: 2.2094 - val_accuracy: 0.4322\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.2368 - accuracy: 0.4172 - val_loss: 2.0135 - val_accuracy: 0.4689\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.0538 - accuracy: 0.4558 - val_loss: 1.9862 - val_accuracy: 0.4704\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.9149 - accuracy: 0.4853 - val_loss: 1.8973 - val_accuracy: 0.4923\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.8188 - accuracy: 0.5133 - val_loss: 1.8324 - val_accuracy: 0.5039\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.7201 - accuracy: 0.5283 - val_loss: 1.7575 - val_accuracy: 0.5265\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.6045 - accuracy: 0.5628 - val_loss: 1.7541 - val_accuracy: 0.5317\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.4953 - accuracy: 0.5824 - val_loss: 1.6996 - val_accuracy: 0.5420\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.4119 - accuracy: 0.6093 - val_loss: 1.7528 - val_accuracy: 0.5415\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.3334 - accuracy: 0.6247 - val_loss: 1.6987 - val_accuracy: 0.5539\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.2128 - accuracy: 0.6525 - val_loss: 1.7274 - val_accuracy: 0.5536\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.1524 - accuracy: 0.6670 - val_loss: 1.6743 - val_accuracy: 0.5573\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.0899 - accuracy: 0.6841 - val_loss: 1.7541 - val_accuracy: 0.5503\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.0040 - accuracy: 0.7092 - val_loss: 1.7858 - val_accuracy: 0.5539\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 0.9096 - accuracy: 0.7296 - val_loss: 1.7517 - val_accuracy: 0.5611\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 0.8427 - accuracy: 0.7499 - val_loss: 1.7593 - val_accuracy: 0.5687\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 0.7943 - accuracy: 0.7619 - val_loss: 1.8565 - val_accuracy: 0.5600\n",
            "Epoch 00022: early stopping\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 3.0725 - accuracy: 0.2459\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 18s 43ms/step - loss: 4.5715 - accuracy: 0.0184 - val_loss: 3.9728 - val_accuracy: 0.1100\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 3.9489 - accuracy: 0.1104 - val_loss: 3.2192 - val_accuracy: 0.2482\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 3.3309 - accuracy: 0.2063 - val_loss: 2.6299 - val_accuracy: 0.3362\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.8910 - accuracy: 0.2814 - val_loss: 2.4005 - val_accuracy: 0.3837\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.6002 - accuracy: 0.3385 - val_loss: 2.2784 - val_accuracy: 0.4133\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.3709 - accuracy: 0.3839 - val_loss: 2.1342 - val_accuracy: 0.4395\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.2175 - accuracy: 0.4214 - val_loss: 2.0552 - val_accuracy: 0.4607\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.0758 - accuracy: 0.4537 - val_loss: 1.9575 - val_accuracy: 0.4778\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.9350 - accuracy: 0.4800 - val_loss: 1.9080 - val_accuracy: 0.4912\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.8199 - accuracy: 0.5084 - val_loss: 1.8845 - val_accuracy: 0.4937\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.7115 - accuracy: 0.5342 - val_loss: 1.7710 - val_accuracy: 0.5206\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.6048 - accuracy: 0.5624 - val_loss: 1.8036 - val_accuracy: 0.5192\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.4930 - accuracy: 0.5859 - val_loss: 1.7410 - val_accuracy: 0.5321\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.4177 - accuracy: 0.6021 - val_loss: 1.7223 - val_accuracy: 0.5437\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.3229 - accuracy: 0.6236 - val_loss: 1.7264 - val_accuracy: 0.5489\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.2325 - accuracy: 0.6462 - val_loss: 1.7110 - val_accuracy: 0.5577\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.1553 - accuracy: 0.6668 - val_loss: 1.7180 - val_accuracy: 0.5598\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.0946 - accuracy: 0.6856 - val_loss: 1.6903 - val_accuracy: 0.5709\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.0180 - accuracy: 0.7038 - val_loss: 1.8219 - val_accuracy: 0.5545\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 0.9314 - accuracy: 0.7231 - val_loss: 1.7924 - val_accuracy: 0.5655\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 0.8637 - accuracy: 0.7452 - val_loss: 1.7420 - val_accuracy: 0.5744\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 0.8013 - accuracy: 0.7594 - val_loss: 1.8317 - val_accuracy: 0.5742\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 0.7299 - accuracy: 0.7798 - val_loss: 1.9445 - val_accuracy: 0.5654\n",
            "Epoch 00023: early stopping\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 3.0318 - accuracy: 0.2549\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 18s 43ms/step - loss: 4.5467 - accuracy: 0.0232 - val_loss: 3.9592 - val_accuracy: 0.1320\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 3.9339 - accuracy: 0.1169 - val_loss: 3.1786 - val_accuracy: 0.2564\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 3.2921 - accuracy: 0.2148 - val_loss: 2.6992 - val_accuracy: 0.3306\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.8523 - accuracy: 0.2908 - val_loss: 2.3550 - val_accuracy: 0.3889\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.5588 - accuracy: 0.3491 - val_loss: 2.1941 - val_accuracy: 0.4249\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.3188 - accuracy: 0.3931 - val_loss: 2.1044 - val_accuracy: 0.4413\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 2.1589 - accuracy: 0.4337 - val_loss: 1.9852 - val_accuracy: 0.4689\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.0091 - accuracy: 0.4665 - val_loss: 1.8929 - val_accuracy: 0.4949\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.8688 - accuracy: 0.4965 - val_loss: 1.9498 - val_accuracy: 0.4824\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.7785 - accuracy: 0.5163 - val_loss: 1.8935 - val_accuracy: 0.5035\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.6756 - accuracy: 0.5411 - val_loss: 1.8026 - val_accuracy: 0.5192\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.5720 - accuracy: 0.5670 - val_loss: 1.7969 - val_accuracy: 0.5206\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.4560 - accuracy: 0.5915 - val_loss: 1.7160 - val_accuracy: 0.5385\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.3800 - accuracy: 0.6111 - val_loss: 1.7214 - val_accuracy: 0.5459\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.2955 - accuracy: 0.6317 - val_loss: 1.6922 - val_accuracy: 0.5635\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.2064 - accuracy: 0.6531 - val_loss: 1.6535 - val_accuracy: 0.5635\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.1198 - accuracy: 0.6713 - val_loss: 1.7038 - val_accuracy: 0.5668\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 1.0583 - accuracy: 0.6907 - val_loss: 1.7797 - val_accuracy: 0.5573\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 0.9811 - accuracy: 0.7133 - val_loss: 1.7713 - val_accuracy: 0.5605\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 0.9177 - accuracy: 0.7286 - val_loss: 1.7134 - val_accuracy: 0.5708\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 17s 42ms/step - loss: 0.8245 - accuracy: 0.7557 - val_loss: 1.7667 - val_accuracy: 0.5725\n",
            "Epoch 00021: early stopping\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 3.0478 - accuracy: 0.2600\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 18s 43ms/step - loss: 4.5685 - accuracy: 0.0184 - val_loss: 4.0195 - val_accuracy: 0.1222\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 3.9467 - accuracy: 0.1099 - val_loss: 3.1922 - val_accuracy: 0.2532\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 3.3320 - accuracy: 0.2070 - val_loss: 2.6950 - val_accuracy: 0.3269\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.9026 - accuracy: 0.2805 - val_loss: 2.3569 - val_accuracy: 0.3990\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.5953 - accuracy: 0.3401 - val_loss: 2.2557 - val_accuracy: 0.4074\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.3605 - accuracy: 0.3860 - val_loss: 2.1049 - val_accuracy: 0.4481\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.2192 - accuracy: 0.4167 - val_loss: 2.0859 - val_accuracy: 0.4555\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 2.0621 - accuracy: 0.4520 - val_loss: 2.0025 - val_accuracy: 0.4652\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.9260 - accuracy: 0.4833 - val_loss: 1.9530 - val_accuracy: 0.4803\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.8147 - accuracy: 0.5107 - val_loss: 1.8753 - val_accuracy: 0.4969\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.7117 - accuracy: 0.5328 - val_loss: 1.7828 - val_accuracy: 0.5209\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.6169 - accuracy: 0.5588 - val_loss: 1.7317 - val_accuracy: 0.5338\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.5025 - accuracy: 0.5808 - val_loss: 1.6899 - val_accuracy: 0.5473\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.4052 - accuracy: 0.6050 - val_loss: 1.7799 - val_accuracy: 0.5240\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.3230 - accuracy: 0.6226 - val_loss: 1.6996 - val_accuracy: 0.5501\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.2419 - accuracy: 0.6471 - val_loss: 1.7136 - val_accuracy: 0.5432\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.1608 - accuracy: 0.6641 - val_loss: 1.7679 - val_accuracy: 0.5420\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 1.0882 - accuracy: 0.6885 - val_loss: 1.8114 - val_accuracy: 0.5477\n",
            "Epoch 00018: early stopping\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 3.0390 - accuracy: 0.2543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "clBPWU-7tobK",
        "outputId": "6886d895-c57a-4539-a263-7516c8280ee2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,5))\n",
        "colours = 'krgby'\n",
        "for i in range(5):\n",
        "  plt.plot(accuracy[i][1],marker='.',c=colours[i],label=str(i+1)+\"-fold\")\n",
        "  plt.plot(accuracy[i][2],marker='.',c=colours[i])\n",
        "plt.ylim(0,1.0)\n",
        "plt.grid()\n",
        "plt.legend();"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXYWk_m35r-Z"
      },
      "source": [
        "5fold CV를 진행한 결과, 5fold 모두 비슷하게 진행되었고모두 안정적으로 0.6이 안되는 accuracy에 수렴하였습니다."
      ]
    }
  ]
}