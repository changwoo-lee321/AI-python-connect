{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ds-cs-N424a.ipynb의 사본의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MINED30/AI-python-connect/blob/master/ds_cs_N424a_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzaaHL75OF2K"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 1 / Assignment 4*\n",
        "\n",
        "---\n",
        "# N414. 신경망과 학습에 관련된 파라미터 튜닝 (HyperTune)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ryp-TVm4njD"
      },
      "source": [
        "\n",
        "\n",
        "## 실전 연습과제\n",
        "\n",
        "다음 통신사 고객 이탈(Churn) 데이터셋에서 정확도를 조정해보는 파라미터 학습을 진행해보겠습니다 : [다운로드](https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/telecom/TelcomCustomer.csv)\n",
        "\n",
        "## 진행방식\n",
        "\n",
        "- 데이터를 다운로드 받고 읽어옴(load)\n",
        "- 데이터 클리닝을 진행 (필수는 아니지만 추천)\n",
        "- Keras MLP model을 만들고, 학습 진행\n",
        "- Hyperparameter 튜닝 진행:\n",
        " - batch_size\n",
        " - training epochs\n",
        " - optimizer\n",
        " - learning rate (optimizer에 따라서 해당되면)\n",
        " - momentum (optimizer에 따라서 해당되면)\n",
        " - activation functions\n",
        " - network weight initialization\n",
        " - dropout regularization\n",
        " - number of neurons in the hidden layer\n",
        " \n",
        "하이퍼 파라미터의 초기 패스를 위해 그리드 검색 및 교차 검증을 사용할 수 있어야 합니다. \n",
        "\n",
        "실제 큰 통신회사의 데이터이기 때문에 최대한 정확하게 파악해 보십시오! \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j68yxJGopANf"
      },
      "source": [
        "# 데이터 전처리 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB91n40ySJxC"
      },
      "source": [
        "### 문항 1) 내 로컬 파일을 colab에 업로드하기\n",
        "\n",
        "충분한 GPU를 가지고 있다면, 쉽게 문제를 해결할 수 있겠지만, 제한된 자원에서 충분한 GPU를 제공받지 못할 지 모릅니다. 이럴 때에는 딥러닝 커뮤니티에 물어볼 수도 있겠지만, 가성비 좋은 Colab의 GPU를 이용해서 실제 GPU사용량을 예측할 수 있다면 좋겠습니다. 모델 파라미터의 개수와 batch size 등이 GPU메모리에 큰 영향을 미치니 여러가지로 활용해보시기 바랍니다.\n",
        "\n",
        "Colab의 GPU를 이용하기 위해서, 로컬로 진행하시던 분들도 이번에는 colab을 사용해봅시다. \n",
        "\n",
        "- 구글에서 colab의 라이브러리를 찾아서 업로드하세요. \n",
        "이후에 Pandas를 이용하여 데이터프레임으로 저장합니다.\n",
        "\n",
        "colab을 사용하기위해서는 colab 라이브러리들을 잘 활용할 수 있으면 좋습니다. colab 기본형의 GPU의 사용제한 때문에 하지 못하는 일이 있다면, colab pro를 사용할 수 있습니다. 코드스테이츠에서 제공하는 colab pro 설치 가이드가 있지만, 스스로 문제를 해결해보시면 좋습니다. 그러나 도움이 필요하시면 HelpDesk에 문의해주시기 바랍니다.\n",
        "\n",
        "### 로컬 파일을 업로드하는 코드를 입력하세요. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLJylhd0JeYO",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "65cd81b9-671b-4c9d-c1a1-66d47460248b"
      },
      "source": [
        "##### Your Code Here #####\n",
        "# 로컬 파일 업로드\n",
        "from google.colab import files\n",
        "file_uploaded = files.upload()\n",
        "\n",
        "# 데이터 불러오기\n",
        "import pandas as pd\n",
        "df = pd.read_csv('TelcomCustomer.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2c700472-9471-4654-817b-15f7ec79b3f9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2c700472-9471-4654-817b-15f7ec79b3f9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving TelcomCustomer.csv to TelcomCustomer.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "MOSklFLyJ__j",
        "outputId": "0495f72e-1e59-42cd-9cf9-388523688505"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customerID</th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>OnlineBackup</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7590-VHVEG</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5575-GNVDE</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7795-CFOCW</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9237-HQITU</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   customerID  gender  SeniorCitizen  ... MonthlyCharges TotalCharges  Churn\n",
              "0  7590-VHVEG  Female              0  ...          29.85        29.85     No\n",
              "1  5575-GNVDE    Male              0  ...          56.95       1889.5     No\n",
              "2  3668-QPYBK    Male              0  ...          53.85       108.15    Yes\n",
              "3  7795-CFOCW    Male              0  ...          42.30      1840.75     No\n",
              "4  9237-HQITU  Female              0  ...          70.70       151.65    Yes\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3q777ZqUvcb"
      },
      "source": [
        "### 문항 2) 결측치가 있는지 isnull()함수를 이용하여 확인하고 결과값을 입력하시오. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRSyDmSzKJrr",
        "outputId": "ac6e191f-a2f4-45bc-a382-9208760588f5"
      },
      "source": [
        "##### Your Code Here #####\n",
        "# 결측치 확인\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customerID          0\n",
              "gender              0\n",
              "SeniorCitizen       0\n",
              "Partner             0\n",
              "Dependents          0\n",
              "tenure              0\n",
              "PhoneService        0\n",
              "MultipleLines       0\n",
              "InternetService     0\n",
              "OnlineSecurity      0\n",
              "OnlineBackup        0\n",
              "DeviceProtection    0\n",
              "TechSupport         0\n",
              "StreamingTV         0\n",
              "StreamingMovies     0\n",
              "Contract            0\n",
              "PaperlessBilling    0\n",
              "PaymentMethod       0\n",
              "MonthlyCharges      0\n",
              "TotalCharges        0\n",
              "Churn               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL9P54f2U8Is"
      },
      "source": [
        "### 문항 3) dtypes를 이용해서 데이터 타입을 확인하고 아래 문제에 답하시오.\n",
        "\n",
        "TotalCharges와 같이 중요한 타켓값이 숫자로 되어있어야 하는데, object로 되어있는 것을 확인하고 숫자형으로 바꿔주세요. <br>\n",
        "숫자형이 아닌 결측치의 개수는 몇개인가요? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVSyCJ6ICmqy",
        "outputId": "015c976f-10ad-4083-a744-64f3b5ca0559"
      },
      "source": [
        "import numpy as np\n",
        "df.TotalCharges.replace(' ',np.nan).isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMo04PeBLUO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bdc1825-3c4e-455d-cfde-109f8127c135"
      },
      "source": [
        "##### Your Code Here #####\n",
        "# 데이터 타입 확인\n",
        "df.dtypes\n",
        "# TotalCharges 숫자형으로 변환\n",
        "df.TotalCharges = pd.to_numeric(df.TotalCharges.replace(' ',np.nan))\n",
        "# 결측치 확인\n",
        "df.isnull().sum()\n",
        "# 결측치 드랍\n",
        "df = df.dropna()\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customerID          0\n",
              "gender              0\n",
              "SeniorCitizen       0\n",
              "Partner             0\n",
              "Dependents          0\n",
              "tenure              0\n",
              "PhoneService        0\n",
              "MultipleLines       0\n",
              "InternetService     0\n",
              "OnlineSecurity      0\n",
              "OnlineBackup        0\n",
              "DeviceProtection    0\n",
              "TechSupport         0\n",
              "StreamingTV         0\n",
              "StreamingMovies     0\n",
              "Contract            0\n",
              "PaperlessBilling    0\n",
              "PaymentMethod       0\n",
              "MonthlyCharges      0\n",
              "TotalCharges        0\n",
              "Churn               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWdECRBDKWsj"
      },
      "source": [
        "# customerID 드랍\n",
        "df = df.drop(columns='customerID')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT-P_VEV4s67"
      },
      "source": [
        "# Attributing No internet service to No\n",
        "no_internet_feats = [ 'TechSupport','OnlineBackup', 'DeviceProtection','StreamingTV',\n",
        "                 'OnlineSecurity','StreamingMovies']\n",
        "\n",
        "for i in no_internet_feats:\n",
        "    df[i] = df[i].replace({'No internet service':'No'})\n",
        "\n",
        "# Attributing No phone service to No\n",
        "df['MultipleLines']=df['MultipleLines'].replace({'No phone service':'No'})\n",
        "\n",
        "# Attributing No phone service to No\n",
        "df['SeniorCitizen']=df['SeniorCitizen'].replace({0:'No',\n",
        "                                                 1:'Yes'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlGG-AoeM0WY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19202818-0a9d-4873-de5c-3d6110ed3d22"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 20.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "oTiY-aTKTrbY",
        "outputId": "2361af1a-2a84-4d94-ca9d-df90ba646883"
      },
      "source": [
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>OnlineBackup</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.50</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender SeniorCitizen Partner  ... MonthlyCharges  TotalCharges Churn\n",
              "0  Female            No     Yes  ...          29.85         29.85    No\n",
              "1    Male            No      No  ...          56.95       1889.50    No\n",
              "2    Male            No      No  ...          53.85        108.15   Yes\n",
              "\n",
              "[3 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8C8PGvoKW1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc32fd2-877d-4d09-e90d-4318a90729a9"
      },
      "source": [
        "# 원핫 인코딩\n",
        "from category_encoders import OrdinalEncoder\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "df_encoded = encoder.fit_transform(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "3BG1KYmSNCqr",
        "outputId": "1f74da8c-f015-4205-d812-685b5aea630b"
      },
      "source": [
        "df_encoded.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>OnlineBackup</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender  SeniorCitizen  Partner  ...  MonthlyCharges  TotalCharges  Churn\n",
              "0       1              1        1  ...           29.85         29.85      1\n",
              "1       2              1        2  ...           56.95       1889.50      1\n",
              "2       2              1        2  ...           53.85        108.15      2\n",
              "3       2              1        2  ...           42.30       1840.75      1\n",
              "4       1              1        2  ...           70.70        151.65      2\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7bZ586RWMhm",
        "outputId": "14f8a422-f0da-442f-c2b2-34d8270c0592"
      },
      "source": [
        "# 타겟을 0과 1로 바꿔주기\n",
        "df_encoded['Churn'] = df_encoded['Churn'].replace({1: 0, 2: 1})\n",
        "df_encoded['Churn'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5163\n",
              "1    1869\n",
              "Name: Churn, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cQShFbLW8zO",
        "outputId": "52e37a60-df5b-45f6-9fbc-41f0ddf8d9c9"
      },
      "source": [
        "df_encoded.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7032, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO6qtHPGlUtk"
      },
      "source": [
        "### 문항 4) 훈련집합과 테스트 집합을 나누는 코드를 만들고, 해당 코드를 입력하시오.\n",
        "\n",
        "- random_state=1\n",
        "- test_size=0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfcv-kpAWJz8",
        "outputId": "1f93ad0a-35d1-4b96-d88c-cdf3761c006a"
      },
      "source": [
        "##### Your Code Here #####\n",
        "# 훈련, 테스트 셋을 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df_encoded, test_size=0.25, stratify=df_encoded['Churn'], random_state=1)\n",
        "train.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5274, 20), (1758, 20))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrSGVTe_VOkF"
      },
      "source": [
        "# features 와 target 을 분리\n",
        "\n",
        "target = 'Churn'\n",
        "features = df_encoded.drop(columns=[target]).columns\n",
        "\n",
        "X_train = train[features]\n",
        "X_test = test[features]\n",
        "\n",
        "y_train = train[target]\n",
        "y_test = test[target]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI7H5xZLmJYB"
      },
      "source": [
        "### 문항 5) sklearn.preprocessing.StandardScaler를 이용하여 정규화를 진행하시고, 문제를 보고 빈칸에 알맞은 단어를 넣으시오.\n",
        "\n",
        "`X_train_scaled = scaler.##### Your Code Here #####`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKngHITnNumF"
      },
      "source": [
        "##### Your Code Here #####\n",
        "# 정규화\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMdVvfM3NuuI",
        "outputId": "c9ba5650-4dbd-4088-c94f-4c5865eb62bd"
      },
      "source": [
        "# 19x1 형태 => 입력층의 노드수가 19개! \n",
        "X_train_scaled[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.99508225, -0.43925252,  0.96350214, -0.65400354, -0.09779796,\n",
              "        0.32541085,  1.16743446, -1.19019364,  1.59286639,  0.72650531,\n",
              "       -0.72042294, -0.64249881, -0.79264136,  1.25707392, -0.83276144,\n",
              "       -0.83448511, -0.27868378, -0.00881575, -0.17257846])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfztkd7Xdw5M"
      },
      "source": [
        "# 모델링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMyQPCy5pV21"
      },
      "source": [
        "## 기본 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW-ny1Fud4ML"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import IPython\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjzyQbLZwS4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1780c36-a656-469e-bc6f-5b176eba3180"
      },
      "source": [
        "!pip install -U keras-tuner\n",
        "import kerastuner as kt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=aa3764217e4ee8f4f9b51c8a8201dddac02ce54131d8451b1d6c7beb469b750b\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=9a3a99f28944009700fcd772605150f084d1348d10b10a45c8382b2f3b406225\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xblH5R2pnsG8"
      },
      "source": [
        "### 문제 6. np.unique를 이용해서 y_train의 Class 의 개수를 확인하고 입력하시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR709Nz8eCQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b9ff0e9-5146-4ce0-da68-b758dfbb3049"
      },
      "source": [
        "##### Your Code Here #####\n",
        "np.unique(y_train)\n",
        "# 이진분류의 경우 class는 2개이지만, 출력층의 노드수 = 1 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe3baua8j9aZ",
        "outputId": "53a09c32-9c22-4242-db1d-ae3aca4170f9"
      },
      "source": [
        "# 간단한 모델 만들어서 성능을 보기 !\n",
        "tf.random.set_seed(7)\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(64, activation='relu'))\n",
        "model2.add(Dense(64, activation='relu'))\n",
        "model2.add(Dense(1, activation='sigmoid')) # 00분류니까 노드수 1, 활성함수로는 시그모이드\n",
        "\n",
        "model2.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "results = model2.fit(X_train_scaled, y_train, epochs=10, validation_data=(X_test_scaled,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "165/165 [==============================] - 2s 5ms/step - loss: 0.5154 - accuracy: 0.7276 - val_loss: 0.4491 - val_accuracy: 0.7912\n",
            "Epoch 2/10\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8054 - val_loss: 0.4461 - val_accuracy: 0.7986\n",
            "Epoch 3/10\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8073 - val_loss: 0.4482 - val_accuracy: 0.7918\n",
            "Epoch 4/10\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8095 - val_loss: 0.4452 - val_accuracy: 0.8020\n",
            "Epoch 5/10\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8119 - val_loss: 0.4512 - val_accuracy: 0.7947\n",
            "Epoch 6/10\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8207 - val_loss: 0.4527 - val_accuracy: 0.7901\n",
            "Epoch 7/10\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8156 - val_loss: 0.4520 - val_accuracy: 0.7958\n",
            "Epoch 8/10\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8236 - val_loss: 0.4533 - val_accuracy: 0.7929\n",
            "Epoch 9/10\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8293 - val_loss: 0.4551 - val_accuracy: 0.7856\n",
            "Epoch 10/10\n",
            "165/165 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8212 - val_loss: 0.4638 - val_accuracy: 0.7810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKSycr4vKdcg",
        "outputId": "2f94944c-2c31-4698-e8d5-02de747cfab2"
      },
      "source": [
        "# 테스트셋 사용해서 결과 보기\n",
        "model2.evaluate(X_test_scaled,  y_test, verbose=2) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 - 0s - loss: 0.4638 - accuracy: 0.7810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.46377870440483093, 0.7810011506080627]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOIeK9vgk7aS"
      },
      "source": [
        "파라미터 튜닝을 하기전에 간단히 임의로 넣어본 결과도 꽤 좋다. 이젠 GridSearchCV 를 사용해서 튜닝을 해보겠음!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH3zjICDpOpZ"
      },
      "source": [
        "## GridSearchCV 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K60WHG6gWYyG",
        "outputId": "6a6b4d2c-2104-4cc8-fbbc-7af7444293ef"
      },
      "source": [
        "# 모델 만들기\n",
        "tf.random.set_seed(7)\n",
        "\n",
        "def model_builder(nodes=16, activation='relu'):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(1, activation='sigmoid')) # 이진분류니까 노드수 1, 활성함수로는 시그모이드\n",
        "\n",
        "  model.compile(optimizer='adam', \n",
        "                loss='binary_crossentropy', \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# keras.wrapper를 활용하여 분류기를 만듭니다\n",
        "model = KerasClassifier(build_fn=model_builder, verbose=0)\n",
        "\n",
        "# GridSearch\n",
        "batch_size = [50, 100, 300]\n",
        "epochs = [10, 20, 30]\n",
        "nodes = [64, 128, 256]\n",
        "activation = ['relu', 'sigmoid']\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs, nodes=nodes, activation=activation)\n",
        "\n",
        "\n",
        "# GridSearch CV를 만들기\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=2)\n",
        "grid_result = grid.fit(X_train_scaled, y_train, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "[CV] activation=relu, batch_size=50, epochs=10, nodes=64 .............\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "71/71 - 1s - loss: 0.4941 - accuracy: 0.7491\n",
            "Epoch 2/10\n",
            "71/71 - 0s - loss: 0.4235 - accuracy: 0.7929\n",
            "Epoch 3/10\n",
            "71/71 - 0s - loss: 0.4118 - accuracy: 0.7986\n",
            "Epoch 4/10\n",
            "71/71 - 0s - loss: 0.4067 - accuracy: 0.8035\n",
            "Epoch 5/10\n",
            "71/71 - 0s - loss: 0.3993 - accuracy: 0.8066\n",
            "Epoch 6/10\n",
            "71/71 - 0s - loss: 0.3976 - accuracy: 0.8057\n",
            "Epoch 7/10\n",
            "71/71 - 0s - loss: 0.3927 - accuracy: 0.8097\n",
            "Epoch 8/10\n",
            "71/71 - 0s - loss: 0.3883 - accuracy: 0.8129\n",
            "Epoch 9/10\n",
            "71/71 - 0s - loss: 0.3844 - accuracy: 0.8137\n",
            "Epoch 10/10\n",
            "71/71 - 0s - loss: 0.3827 - accuracy: 0.8214\n",
            "[CV]  activation=relu, batch_size=50, epochs=10, nodes=64, total=   1.8s\n",
            "[CV] activation=relu, batch_size=50, epochs=10, nodes=64 .............\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.3759 - accuracy: 0.8259\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.3737 - accuracy: 0.8279\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.3721 - accuracy: 0.8254\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.3689 - accuracy: 0.8265\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.3672 - accuracy: 0.8305\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.3641 - accuracy: 0.8305\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.3621 - accuracy: 0.8348\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.3603 - accuracy: 0.8325\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.3578 - accuracy: 0.8359\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.3549 - accuracy: 0.8330\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.3547 - accuracy: 0.8348\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.3528 - accuracy: 0.8379\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.3477 - accuracy: 0.8416\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.3464 - accuracy: 0.8385\n",
            "[CV]  activation=relu, batch_size=100, epochs=30, nodes=64, total=   2.4s\n",
            "[CV] activation=relu, batch_size=100, epochs=30, nodes=64 ............\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.5637 - accuracy: 0.6863\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.4407 - accuracy: 0.7858\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.4194 - accuracy: 0.7975\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.4102 - accuracy: 0.8003\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.4033 - accuracy: 0.8060\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.3969 - accuracy: 0.8094\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.3939 - accuracy: 0.8140\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.3903 - accuracy: 0.8146\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.3870 - accuracy: 0.8151\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.3846 - accuracy: 0.8185\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.3827 - accuracy: 0.8205\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.3789 - accuracy: 0.8211\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.3761 - accuracy: 0.8197\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.3753 - accuracy: 0.8237\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.3735 - accuracy: 0.8222\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.3691 - accuracy: 0.8271\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.3670 - accuracy: 0.8279\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.3660 - accuracy: 0.8254\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.3645 - accuracy: 0.8294\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.3618 - accuracy: 0.8296\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.3594 - accuracy: 0.8336\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.3560 - accuracy: 0.8336\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.3537 - accuracy: 0.8345\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.3520 - accuracy: 0.8376\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.3490 - accuracy: 0.8376\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.3482 - accuracy: 0.8365\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.3466 - accuracy: 0.8385\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.3433 - accuracy: 0.8393\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.3400 - accuracy: 0.8399\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.3414 - accuracy: 0.8385\n",
            "[CV]  activation=relu, batch_size=100, epochs=30, nodes=64, total=   2.3s\n",
            "[CV] activation=relu, batch_size=100, epochs=30, nodes=128 ...........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.5213 - accuracy: 0.7130\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.4239 - accuracy: 0.7907\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.4081 - accuracy: 0.8012\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.4017 - accuracy: 0.8103\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.3951 - accuracy: 0.8114\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.3940 - accuracy: 0.8109\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.3885 - accuracy: 0.8177\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.3819 - accuracy: 0.8208\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.3773 - accuracy: 0.8203\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.3764 - accuracy: 0.8234\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.3752 - accuracy: 0.8228\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.3675 - accuracy: 0.8262\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.3640 - accuracy: 0.8316\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.3637 - accuracy: 0.8328\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.3547 - accuracy: 0.8376\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.3555 - accuracy: 0.8342\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.3508 - accuracy: 0.8382\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.3477 - accuracy: 0.8376\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.3393 - accuracy: 0.8456\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.3390 - accuracy: 0.8478\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.3346 - accuracy: 0.8458\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.3287 - accuracy: 0.8535\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.3242 - accuracy: 0.8524\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.3203 - accuracy: 0.8541\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.3175 - accuracy: 0.8615\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.3109 - accuracy: 0.8592\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.3063 - accuracy: 0.8655\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.3045 - accuracy: 0.8666\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.2983 - accuracy: 0.8689\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.2925 - accuracy: 0.8754\n",
            "[CV]  activation=relu, batch_size=100, epochs=30, nodes=128, total=   2.6s\n",
            "[CV] activation=relu, batch_size=100, epochs=30, nodes=128 ...........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.4700 - accuracy: 0.7645\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.4182 - accuracy: 0.7952\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.4095 - accuracy: 0.8055\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.4027 - accuracy: 0.8109\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.3957 - accuracy: 0.8140\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.3956 - accuracy: 0.8103\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.3867 - accuracy: 0.8205\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.3825 - accuracy: 0.8208\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.3807 - accuracy: 0.8228\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.3794 - accuracy: 0.8183\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.3761 - accuracy: 0.8231\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.3700 - accuracy: 0.8259\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.3655 - accuracy: 0.8291\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.3624 - accuracy: 0.8294\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.3576 - accuracy: 0.8313\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.3567 - accuracy: 0.8373\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.3514 - accuracy: 0.8376\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.3478 - accuracy: 0.8376\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.3432 - accuracy: 0.8385\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.3365 - accuracy: 0.8458\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.3312 - accuracy: 0.8470\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.3299 - accuracy: 0.8467\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.3249 - accuracy: 0.8510\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.3190 - accuracy: 0.8555\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.3185 - accuracy: 0.8584\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.3110 - accuracy: 0.8598\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.3085 - accuracy: 0.8575\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.3118 - accuracy: 0.8626\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.3005 - accuracy: 0.8612\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.2935 - accuracy: 0.8660\n",
            "[CV]  activation=relu, batch_size=100, epochs=30, nodes=128, total=   3.0s\n",
            "[CV] activation=relu, batch_size=100, epochs=30, nodes=128 ...........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.4708 - accuracy: 0.7651\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.4165 - accuracy: 0.7964\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.4015 - accuracy: 0.8097\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.3954 - accuracy: 0.8157\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.3895 - accuracy: 0.8171\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.3833 - accuracy: 0.8217\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.3777 - accuracy: 0.8205\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.3743 - accuracy: 0.8276\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.3705 - accuracy: 0.8262\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.3662 - accuracy: 0.8316\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.3644 - accuracy: 0.8319\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.3573 - accuracy: 0.8353\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.3521 - accuracy: 0.8350\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.3503 - accuracy: 0.8413\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.3450 - accuracy: 0.8430\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.3437 - accuracy: 0.8436\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.3366 - accuracy: 0.8470\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.3370 - accuracy: 0.8478\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.3307 - accuracy: 0.8458\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.3243 - accuracy: 0.8513\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.3202 - accuracy: 0.8567\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.3213 - accuracy: 0.8504\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.3116 - accuracy: 0.8612\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.3083 - accuracy: 0.8635\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.3047 - accuracy: 0.8663\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.3008 - accuracy: 0.8655\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.3003 - accuracy: 0.8618\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.2904 - accuracy: 0.8714\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.2880 - accuracy: 0.8709\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.2818 - accuracy: 0.8749\n",
            "[CV]  activation=relu, batch_size=100, epochs=30, nodes=128, total=   2.6s\n",
            "[CV] activation=relu, batch_size=100, epochs=30, nodes=256 ...........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.4590 - accuracy: 0.7696\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.4122 - accuracy: 0.7995\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.3979 - accuracy: 0.8092\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.3962 - accuracy: 0.8094\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.3845 - accuracy: 0.8200\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.3816 - accuracy: 0.8203\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.3764 - accuracy: 0.8276\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.3695 - accuracy: 0.8271\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.3610 - accuracy: 0.8311\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.3575 - accuracy: 0.8336\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.3561 - accuracy: 0.8379\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.3438 - accuracy: 0.8481\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.3386 - accuracy: 0.8441\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.3362 - accuracy: 0.8495\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.3206 - accuracy: 0.8572\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.3216 - accuracy: 0.8487\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.3124 - accuracy: 0.8567\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.3059 - accuracy: 0.8638\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.2916 - accuracy: 0.8717\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.2861 - accuracy: 0.8729\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.2791 - accuracy: 0.8754\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.2744 - accuracy: 0.8771\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.2678 - accuracy: 0.8811\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.2609 - accuracy: 0.8874\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.2510 - accuracy: 0.8973\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.2403 - accuracy: 0.8993\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.2362 - accuracy: 0.8999\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.2353 - accuracy: 0.9005\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.2217 - accuracy: 0.9133\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.2173 - accuracy: 0.9104\n",
            "[CV]  activation=relu, batch_size=100, epochs=30, nodes=256, total=   4.2s\n",
            "[CV] activation=relu, batch_size=100, epochs=30, nodes=256 ...........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.4639 - accuracy: 0.7762\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.4102 - accuracy: 0.8057\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.4034 - accuracy: 0.8089\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.3983 - accuracy: 0.8183\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.3908 - accuracy: 0.8191\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.3895 - accuracy: 0.8137\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.3786 - accuracy: 0.8296\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.3738 - accuracy: 0.8288\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.3716 - accuracy: 0.8291\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.3662 - accuracy: 0.8248\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.3670 - accuracy: 0.8313\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.3559 - accuracy: 0.8399\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.3500 - accuracy: 0.8385\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.3476 - accuracy: 0.8441\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.3377 - accuracy: 0.8450\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.3339 - accuracy: 0.8484\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.3270 - accuracy: 0.8527\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.3234 - accuracy: 0.8558\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.3140 - accuracy: 0.8578\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.3033 - accuracy: 0.8595\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.2936 - accuracy: 0.8689\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.2874 - accuracy: 0.8712\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.2879 - accuracy: 0.8766\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.2728 - accuracy: 0.8797\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.2765 - accuracy: 0.8754\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.2641 - accuracy: 0.8842\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.2614 - accuracy: 0.8854\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.2585 - accuracy: 0.8882\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.2443 - accuracy: 0.8968\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.2349 - accuracy: 0.9022\n",
            "[CV]  activation=relu, batch_size=100, epochs=30, nodes=256, total=   4.3s\n",
            "[CV] activation=relu, batch_size=100, epochs=30, nodes=256 ...........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.4708 - accuracy: 0.7546\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.4084 - accuracy: 0.8052\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.3964 - accuracy: 0.8111\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.3905 - accuracy: 0.8123\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.3831 - accuracy: 0.8220\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.3772 - accuracy: 0.8211\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.3699 - accuracy: 0.8299\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.3648 - accuracy: 0.8356\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.3613 - accuracy: 0.8316\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.3544 - accuracy: 0.8404\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.3555 - accuracy: 0.8387\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.3425 - accuracy: 0.8447\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.3354 - accuracy: 0.8484\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.3328 - accuracy: 0.8473\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.3247 - accuracy: 0.8518\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.3207 - accuracy: 0.8535\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.3094 - accuracy: 0.8612\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.3056 - accuracy: 0.8598\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.2990 - accuracy: 0.8660\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.2895 - accuracy: 0.8746\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.2817 - accuracy: 0.8737\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.2790 - accuracy: 0.8774\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.2711 - accuracy: 0.8805\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.2621 - accuracy: 0.8882\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.2622 - accuracy: 0.8857\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.2540 - accuracy: 0.8936\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.2489 - accuracy: 0.8919\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.2378 - accuracy: 0.9050\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.2282 - accuracy: 0.9064\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.2267 - accuracy: 0.9087\n",
            "[CV]  activation=relu, batch_size=100, epochs=30, nodes=256, total=   4.3s\n",
            "[CV] activation=relu, batch_size=300, epochs=10, nodes=64 ............\n",
            "Epoch 1/10\n",
            "12/12 - 0s - loss: 0.5705 - accuracy: 0.7051\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.4771 - accuracy: 0.7435\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.4406 - accuracy: 0.7765\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.4262 - accuracy: 0.7878\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.4195 - accuracy: 0.7907\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.4136 - accuracy: 0.8018\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.4094 - accuracy: 0.8035\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.4060 - accuracy: 0.8020\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.4032 - accuracy: 0.8055\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.4003 - accuracy: 0.8066\n",
            "[CV]  activation=relu, batch_size=300, epochs=10, nodes=64, total=   1.0s\n",
            "[CV] activation=relu, batch_size=300, epochs=10, nodes=64 ............\n",
            "Epoch 1/10\n",
            "12/12 - 0s - loss: 0.5346 - accuracy: 0.7395\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.4610 - accuracy: 0.7756\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.4376 - accuracy: 0.7890\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.4282 - accuracy: 0.7941\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.4218 - accuracy: 0.7989\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.4155 - accuracy: 0.8075\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.4113 - accuracy: 0.8069\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.4082 - accuracy: 0.8094\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.4049 - accuracy: 0.8097\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.4023 - accuracy: 0.8143\n",
            "[CV]  activation=relu, batch_size=300, epochs=10, nodes=64, total=   1.0s\n",
            "[CV] activation=relu, batch_size=300, epochs=10, nodes=64 ............\n",
            "Epoch 1/10\n",
            "12/12 - 1s - loss: 0.5457 - accuracy: 0.7412\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.4624 - accuracy: 0.7810\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.4332 - accuracy: 0.7952\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.4208 - accuracy: 0.7989\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.4132 - accuracy: 0.8038\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.4072 - accuracy: 0.8046\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.4023 - accuracy: 0.8092\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.3983 - accuracy: 0.8111\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.3947 - accuracy: 0.8160\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.3918 - accuracy: 0.8188\n",
            "[CV]  activation=relu, batch_size=300, epochs=10, nodes=64, total=   1.0s\n",
            "[CV] activation=relu, batch_size=300, epochs=10, nodes=128 ...........\n",
            "Epoch 1/10\n",
            "12/12 - 1s - loss: 0.5451 - accuracy: 0.7099\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.4472 - accuracy: 0.7716\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.4209 - accuracy: 0.7966\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.4128 - accuracy: 0.8020\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.4070 - accuracy: 0.8057\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.4023 - accuracy: 0.8063\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.3983 - accuracy: 0.8083\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.3952 - accuracy: 0.8151\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.3924 - accuracy: 0.8151\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.3897 - accuracy: 0.8163\n",
            "[CV]  activation=relu, batch_size=300, epochs=10, nodes=128, total=   1.1s\n",
            "[CV] activation=relu, batch_size=300, epochs=10, nodes=128 ...........\n",
            "Epoch 1/10\n",
            "12/12 - 1s - loss: 0.5373 - accuracy: 0.7358\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.4406 - accuracy: 0.7901\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.4247 - accuracy: 0.7998\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.4134 - accuracy: 0.8077\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.4086 - accuracy: 0.8089\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.4028 - accuracy: 0.8197\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.3987 - accuracy: 0.8183\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.3958 - accuracy: 0.8134\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.3946 - accuracy: 0.8163\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.3900 - accuracy: 0.8248\n",
            "[CV]  activation=relu, batch_size=300, epochs=10, nodes=128, total=   1.5s\n",
            "[CV] activation=relu, batch_size=300, epochs=10, nodes=128 ...........\n",
            "Epoch 1/10\n",
            "12/12 - 1s - loss: 0.5222 - accuracy: 0.7415\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.4325 - accuracy: 0.7901\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.4167 - accuracy: 0.8003\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.4068 - accuracy: 0.8063\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.4006 - accuracy: 0.8066\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.3950 - accuracy: 0.8100\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.3903 - accuracy: 0.8166\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.3869 - accuracy: 0.8148\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.3838 - accuracy: 0.8185\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.3807 - accuracy: 0.8205\n",
            "[CV]  activation=relu, batch_size=300, epochs=10, nodes=128, total=   1.1s\n",
            "[CV] activation=relu, batch_size=300, epochs=10, nodes=256 ...........\n",
            "Epoch 1/10\n",
            "12/12 - 1s - loss: 0.5407 - accuracy: 0.7028\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.4337 - accuracy: 0.7884\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.4181 - accuracy: 0.7958\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.4064 - accuracy: 0.8060\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.4004 - accuracy: 0.8086\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.3959 - accuracy: 0.8143\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.3906 - accuracy: 0.8197\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.3861 - accuracy: 0.8237\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.3821 - accuracy: 0.8259\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.3785 - accuracy: 0.8254\n",
            "[CV]  activation=relu, batch_size=300, epochs=10, nodes=256, total=   1.4s\n",
            "[CV] activation=relu, batch_size=300, epochs=10, nodes=256 ...........\n",
            "Epoch 1/10\n",
            "12/12 - 1s - loss: 0.5409 - accuracy: 0.7085\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.4331 - accuracy: 0.7944\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.4194 - accuracy: 0.8018\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.4065 - accuracy: 0.8114\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.4010 - accuracy: 0.8148\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.3962 - accuracy: 0.8157\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.3913 - accuracy: 0.8168\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.3874 - accuracy: 0.8177\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.3872 - accuracy: 0.8205\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.3808 - accuracy: 0.8222\n",
            "[CV]  activation=relu, batch_size=300, epochs=10, nodes=256, total=   1.5s\n",
            "[CV] activation=relu, batch_size=300, epochs=10, nodes=256 ...........\n",
            "Epoch 1/10\n",
            "12/12 - 1s - loss: 0.5688 - accuracy: 0.6792\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.4367 - accuracy: 0.7873\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.4155 - accuracy: 0.8012\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.4063 - accuracy: 0.8083\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.3988 - accuracy: 0.8106\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.3927 - accuracy: 0.8114\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.3872 - accuracy: 0.8180\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.3833 - accuracy: 0.8217\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.3794 - accuracy: 0.8245\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.3753 - accuracy: 0.8265\n",
            "[CV]  activation=relu, batch_size=300, epochs=10, nodes=256, total=   1.5s\n",
            "[CV] activation=relu, batch_size=300, epochs=20, nodes=64 ............\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.5770 - accuracy: 0.7318\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.4834 - accuracy: 0.7534\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.4384 - accuracy: 0.7875\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.4224 - accuracy: 0.7975\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.4157 - accuracy: 0.7995\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.4093 - accuracy: 0.8052\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.4051 - accuracy: 0.8083\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.4018 - accuracy: 0.8120\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.3991 - accuracy: 0.8157\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.3964 - accuracy: 0.8160\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.3946 - accuracy: 0.8160\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.3922 - accuracy: 0.8168\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.3904 - accuracy: 0.8214\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.3886 - accuracy: 0.8214\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.3876 - accuracy: 0.8183\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.3851 - accuracy: 0.8211\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.3833 - accuracy: 0.8228\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.3819 - accuracy: 0.8237\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.3798 - accuracy: 0.8245\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.3780 - accuracy: 0.8231\n",
            "[CV]  activation=relu, batch_size=300, epochs=20, nodes=64, total=   1.3s\n",
            "[CV] activation=relu, batch_size=300, epochs=20, nodes=64 ............\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.6049 - accuracy: 0.6761\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.4819 - accuracy: 0.7617\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.4468 - accuracy: 0.7864\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.4336 - accuracy: 0.7947\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.4270 - accuracy: 0.7981\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.4201 - accuracy: 0.8026\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.4158 - accuracy: 0.8077\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.4123 - accuracy: 0.8089\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.4091 - accuracy: 0.8123\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.4063 - accuracy: 0.8134\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.4043 - accuracy: 0.8166\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.4018 - accuracy: 0.8168\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.3995 - accuracy: 0.8197\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.3977 - accuracy: 0.8163\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.3965 - accuracy: 0.8168\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.3936 - accuracy: 0.8211\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.3923 - accuracy: 0.8205\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.3909 - accuracy: 0.8194\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.3885 - accuracy: 0.8222\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.3877 - accuracy: 0.8205\n",
            "[CV]  activation=relu, batch_size=300, epochs=20, nodes=64, total=   1.4s\n",
            "[CV] activation=relu, batch_size=300, epochs=20, nodes=64 ............\n",
            "Epoch 1/20\n",
            "12/12 - 0s - loss: 0.7202 - accuracy: 0.5063\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.5381 - accuracy: 0.7344\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.4824 - accuracy: 0.7548\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.4478 - accuracy: 0.7801\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.4319 - accuracy: 0.7867\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.4218 - accuracy: 0.7918\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.4149 - accuracy: 0.7966\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.4092 - accuracy: 0.8026\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.4044 - accuracy: 0.8069\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.4008 - accuracy: 0.8103\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.3978 - accuracy: 0.8131\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.3947 - accuracy: 0.8166\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.3923 - accuracy: 0.8168\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.3905 - accuracy: 0.8188\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.3881 - accuracy: 0.8203\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.3859 - accuracy: 0.8217\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.3849 - accuracy: 0.8222\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.3832 - accuracy: 0.8222\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.3815 - accuracy: 0.8220\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.3808 - accuracy: 0.8239\n",
            "[CV]  activation=relu, batch_size=300, epochs=20, nodes=64, total=   1.3s\n",
            "[CV] activation=relu, batch_size=300, epochs=20, nodes=128 ...........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.5510 - accuracy: 0.7127\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.4475 - accuracy: 0.7722\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.4240 - accuracy: 0.7938\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.4150 - accuracy: 0.7964\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.4089 - accuracy: 0.8066\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.4028 - accuracy: 0.8092\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.3977 - accuracy: 0.8154\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.3938 - accuracy: 0.8148\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.3907 - accuracy: 0.8191\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.3873 - accuracy: 0.8203\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.3847 - accuracy: 0.8203\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.3816 - accuracy: 0.8211\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.3791 - accuracy: 0.8231\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.3763 - accuracy: 0.8205\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.3745 - accuracy: 0.8234\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.3735 - accuracy: 0.8225\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.3695 - accuracy: 0.8259\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.3684 - accuracy: 0.8225\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.3653 - accuracy: 0.8262\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.3619 - accuracy: 0.8285\n",
            "[CV]  activation=relu, batch_size=300, epochs=20, nodes=128, total=   1.6s\n",
            "[CV] activation=relu, batch_size=300, epochs=20, nodes=128 ...........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.5598 - accuracy: 0.6997\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.4550 - accuracy: 0.7602\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.4252 - accuracy: 0.8006\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.4157 - accuracy: 0.8026\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.4084 - accuracy: 0.8100\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.4027 - accuracy: 0.8166\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.3983 - accuracy: 0.8166\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.3954 - accuracy: 0.8166\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.3926 - accuracy: 0.8220\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.3889 - accuracy: 0.8225\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.3870 - accuracy: 0.8214\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.3838 - accuracy: 0.8265\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.3816 - accuracy: 0.8268\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.3784 - accuracy: 0.8311\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.3762 - accuracy: 0.8311\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.3748 - accuracy: 0.8299\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.3714 - accuracy: 0.8339\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.3696 - accuracy: 0.8328\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.3659 - accuracy: 0.8359\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.3643 - accuracy: 0.8330\n",
            "[CV]  activation=relu, batch_size=300, epochs=20, nodes=128, total=   1.6s\n",
            "[CV] activation=relu, batch_size=300, epochs=20, nodes=128 ...........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.5689 - accuracy: 0.6999\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.4532 - accuracy: 0.7733\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.4237 - accuracy: 0.7952\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.4120 - accuracy: 0.8020\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.4027 - accuracy: 0.8094\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.3964 - accuracy: 0.8131\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.3915 - accuracy: 0.8151\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.3877 - accuracy: 0.8174\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.3843 - accuracy: 0.8185\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.3815 - accuracy: 0.8231\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.3791 - accuracy: 0.8251\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.3764 - accuracy: 0.8276\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.3739 - accuracy: 0.8279\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.3733 - accuracy: 0.8239\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.3689 - accuracy: 0.8305\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.3665 - accuracy: 0.8316\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.3645 - accuracy: 0.8330\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.3633 - accuracy: 0.8316\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.3594 - accuracy: 0.8359\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.3585 - accuracy: 0.8325\n",
            "[CV]  activation=relu, batch_size=300, epochs=20, nodes=128, total=   2.0s\n",
            "[CV] activation=relu, batch_size=300, epochs=20, nodes=256 ...........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.5108 - accuracy: 0.7304\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.4232 - accuracy: 0.7958\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.4125 - accuracy: 0.8086\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.4036 - accuracy: 0.8092\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.3964 - accuracy: 0.8111\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.3925 - accuracy: 0.8168\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.3866 - accuracy: 0.8183\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.3826 - accuracy: 0.8231\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.3785 - accuracy: 0.8257\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.3744 - accuracy: 0.8274\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.3703 - accuracy: 0.8291\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.3663 - accuracy: 0.8339\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.3620 - accuracy: 0.8348\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.3577 - accuracy: 0.8362\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.3556 - accuracy: 0.8382\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.3532 - accuracy: 0.8376\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.3453 - accuracy: 0.8444\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.3408 - accuracy: 0.8441\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.3375 - accuracy: 0.8458\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.3321 - accuracy: 0.8490\n",
            "[CV]  activation=relu, batch_size=300, epochs=20, nodes=256, total=   2.3s\n",
            "[CV] activation=relu, batch_size=300, epochs=20, nodes=256 ...........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.5309 - accuracy: 0.7181\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.4283 - accuracy: 0.7929\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.4180 - accuracy: 0.8012\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.4058 - accuracy: 0.8097\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.4001 - accuracy: 0.8140\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.3948 - accuracy: 0.8203\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.3895 - accuracy: 0.8211\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.3857 - accuracy: 0.8237\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.3855 - accuracy: 0.8203\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.3788 - accuracy: 0.8222\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.3754 - accuracy: 0.8265\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.3712 - accuracy: 0.8288\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.3673 - accuracy: 0.8311\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.3655 - accuracy: 0.8308\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.3615 - accuracy: 0.8333\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.3609 - accuracy: 0.8365\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.3562 - accuracy: 0.8379\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.3525 - accuracy: 0.8393\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.3483 - accuracy: 0.8399\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.3446 - accuracy: 0.8444\n",
            "[CV]  activation=relu, batch_size=300, epochs=20, nodes=256, total=   2.3s\n",
            "[CV] activation=relu, batch_size=300, epochs=20, nodes=256 ...........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.5633 - accuracy: 0.6886\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.4317 - accuracy: 0.7878\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.4121 - accuracy: 0.8006\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.4011 - accuracy: 0.8126\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.3950 - accuracy: 0.8151\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.3884 - accuracy: 0.8174\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.3837 - accuracy: 0.8208\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.3791 - accuracy: 0.8211\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.3756 - accuracy: 0.8248\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.3713 - accuracy: 0.8308\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.3681 - accuracy: 0.8305\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.3642 - accuracy: 0.8305\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.3598 - accuracy: 0.8305\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.3620 - accuracy: 0.8268\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.3548 - accuracy: 0.8365\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.3502 - accuracy: 0.8379\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.3473 - accuracy: 0.8404\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.3465 - accuracy: 0.8385\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.3406 - accuracy: 0.8422\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.3376 - accuracy: 0.8427\n",
            "[CV]  activation=relu, batch_size=300, epochs=20, nodes=256, total=   2.2s\n",
            "[CV] activation=relu, batch_size=300, epochs=30, nodes=64 ............\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.5930 - accuracy: 0.6891\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.4910 - accuracy: 0.7383\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.4472 - accuracy: 0.7745\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.4275 - accuracy: 0.7867\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4199 - accuracy: 0.7918\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.4142 - accuracy: 0.7949\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.4098 - accuracy: 0.7966\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.4060 - accuracy: 0.8029\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.4030 - accuracy: 0.8029\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.3999 - accuracy: 0.8072\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.3977 - accuracy: 0.8075\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.3952 - accuracy: 0.8137\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.3931 - accuracy: 0.8148\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.3913 - accuracy: 0.8146\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.3901 - accuracy: 0.8154\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.3880 - accuracy: 0.8188\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.3864 - accuracy: 0.8197\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.3850 - accuracy: 0.8185\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.3829 - accuracy: 0.8225\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.3814 - accuracy: 0.8205\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.3795 - accuracy: 0.8214\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.3787 - accuracy: 0.8217\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.3771 - accuracy: 0.8217\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.3756 - accuracy: 0.8237\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.3740 - accuracy: 0.8234\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.3725 - accuracy: 0.8259\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.3710 - accuracy: 0.8257\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.3693 - accuracy: 0.8265\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.3680 - accuracy: 0.8268\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.3669 - accuracy: 0.8265\n",
            "[CV]  activation=relu, batch_size=300, epochs=30, nodes=64, total=   1.7s\n",
            "[CV] activation=relu, batch_size=300, epochs=30, nodes=64 ............\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.5589 - accuracy: 0.7383\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.4838 - accuracy: 0.7514\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.4487 - accuracy: 0.7847\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.4336 - accuracy: 0.7884\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4255 - accuracy: 0.7941\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.4184 - accuracy: 0.7992\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.4131 - accuracy: 0.8052\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.4089 - accuracy: 0.8097\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.4053 - accuracy: 0.8103\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.4022 - accuracy: 0.8129\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.3998 - accuracy: 0.8154\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.3971 - accuracy: 0.8143\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.3946 - accuracy: 0.8160\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.3928 - accuracy: 0.8177\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.3914 - accuracy: 0.8205\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.3884 - accuracy: 0.8217\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.3869 - accuracy: 0.8214\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.3855 - accuracy: 0.8231\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.3832 - accuracy: 0.8214\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.3823 - accuracy: 0.8239\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.3804 - accuracy: 0.8245\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.3796 - accuracy: 0.8222\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.3778 - accuracy: 0.8285\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.3765 - accuracy: 0.8265\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.3744 - accuracy: 0.8265\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.3729 - accuracy: 0.8279\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.3719 - accuracy: 0.8262\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.3702 - accuracy: 0.8305\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.3682 - accuracy: 0.8325\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.3671 - accuracy: 0.8322\n",
            "[CV]  activation=relu, batch_size=300, epochs=30, nodes=64, total=   1.7s\n",
            "[CV] activation=relu, batch_size=300, epochs=30, nodes=64 ............\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.5759 - accuracy: 0.7028\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.4881 - accuracy: 0.7361\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.4531 - accuracy: 0.7693\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.4311 - accuracy: 0.7864\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4193 - accuracy: 0.7998\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.4119 - accuracy: 0.8040\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.4061 - accuracy: 0.8100\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.4015 - accuracy: 0.8114\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.3976 - accuracy: 0.8131\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.3946 - accuracy: 0.8140\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.3921 - accuracy: 0.8134\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.3894 - accuracy: 0.8205\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.3873 - accuracy: 0.8203\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.3856 - accuracy: 0.8194\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.3838 - accuracy: 0.8191\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.3812 - accuracy: 0.8234\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.3802 - accuracy: 0.8234\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.3786 - accuracy: 0.8208\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.3767 - accuracy: 0.8222\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.3762 - accuracy: 0.8231\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.3742 - accuracy: 0.8279\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.3729 - accuracy: 0.8265\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.3711 - accuracy: 0.8282\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.3695 - accuracy: 0.8291\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.3682 - accuracy: 0.8285\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.3670 - accuracy: 0.8305\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.3654 - accuracy: 0.8313\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.3643 - accuracy: 0.8285\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.3625 - accuracy: 0.8359\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.3610 - accuracy: 0.8319\n",
            "[CV]  activation=relu, batch_size=300, epochs=30, nodes=64, total=   1.7s\n",
            "[CV] activation=relu, batch_size=300, epochs=30, nodes=128 ...........\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.6279 - accuracy: 0.6175\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.4759 - accuracy: 0.7520\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.4292 - accuracy: 0.7927\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.4191 - accuracy: 0.8003\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4126 - accuracy: 0.8035\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.4065 - accuracy: 0.8080\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.4020 - accuracy: 0.8111\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.3986 - accuracy: 0.8134\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.3954 - accuracy: 0.8160\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.3924 - accuracy: 0.8205\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.3898 - accuracy: 0.8200\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.3870 - accuracy: 0.8214\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.3845 - accuracy: 0.8239\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.3821 - accuracy: 0.8234\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.3808 - accuracy: 0.8234\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.3789 - accuracy: 0.8276\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.3760 - accuracy: 0.8259\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.3739 - accuracy: 0.8282\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.3706 - accuracy: 0.8271\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.3680 - accuracy: 0.8311\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.3651 - accuracy: 0.8305\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.3639 - accuracy: 0.8333\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.3615 - accuracy: 0.8342\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.3586 - accuracy: 0.8333\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.3567 - accuracy: 0.8385\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.3529 - accuracy: 0.8402\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.3508 - accuracy: 0.8382\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.3482 - accuracy: 0.8410\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.3455 - accuracy: 0.8424\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.3442 - accuracy: 0.8436\n",
            "[CV]  activation=relu, batch_size=300, epochs=30, nodes=128, total=   2.0s\n",
            "[CV] activation=relu, batch_size=300, epochs=30, nodes=128 ...........\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.5546 - accuracy: 0.7224\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.4525 - accuracy: 0.7713\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.4260 - accuracy: 0.7972\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.4174 - accuracy: 0.8040\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4106 - accuracy: 0.8086\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.4047 - accuracy: 0.8143\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.4006 - accuracy: 0.8126\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.3982 - accuracy: 0.8148\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.3960 - accuracy: 0.8157\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.3919 - accuracy: 0.8188\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.3902 - accuracy: 0.8168\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.3870 - accuracy: 0.8208\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.3851 - accuracy: 0.8211\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.3818 - accuracy: 0.8245\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.3793 - accuracy: 0.8257\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.3779 - accuracy: 0.8251\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.3750 - accuracy: 0.8302\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.3733 - accuracy: 0.8296\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.3694 - accuracy: 0.8305\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.3680 - accuracy: 0.8294\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.3659 - accuracy: 0.8311\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.3651 - accuracy: 0.8291\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.3623 - accuracy: 0.8356\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.3605 - accuracy: 0.8345\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.3574 - accuracy: 0.8348\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.3543 - accuracy: 0.8390\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.3527 - accuracy: 0.8367\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.3500 - accuracy: 0.8419\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.3460 - accuracy: 0.8427\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.3446 - accuracy: 0.8413\n",
            "[CV]  activation=relu, batch_size=300, epochs=30, nodes=128, total=   2.1s\n",
            "[CV] activation=relu, batch_size=300, epochs=30, nodes=128 ...........\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.5705 - accuracy: 0.7062\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.4535 - accuracy: 0.7756\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.4259 - accuracy: 0.7924\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.4138 - accuracy: 0.7995\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4043 - accuracy: 0.8060\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.3980 - accuracy: 0.8057\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.3933 - accuracy: 0.8134\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.3896 - accuracy: 0.8151\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.3860 - accuracy: 0.8183\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.3831 - accuracy: 0.8208\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.3803 - accuracy: 0.8214\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.3773 - accuracy: 0.8276\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.3749 - accuracy: 0.8279\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.3729 - accuracy: 0.8285\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.3686 - accuracy: 0.8313\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.3661 - accuracy: 0.8316\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.3634 - accuracy: 0.8339\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.3619 - accuracy: 0.8365\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.3581 - accuracy: 0.8379\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.3569 - accuracy: 0.8373\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.3538 - accuracy: 0.8404\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.3528 - accuracy: 0.8365\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.3493 - accuracy: 0.8413\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.3466 - accuracy: 0.8439\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.3441 - accuracy: 0.8407\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.3413 - accuracy: 0.8447\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.3396 - accuracy: 0.8450\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.3382 - accuracy: 0.8458\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.3352 - accuracy: 0.8515\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.3331 - accuracy: 0.8544\n",
            "[CV]  activation=relu, batch_size=300, epochs=30, nodes=128, total=   2.1s\n",
            "[CV] activation=relu, batch_size=300, epochs=30, nodes=256 ...........\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.5519 - accuracy: 0.6934\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.4406 - accuracy: 0.7875\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.4214 - accuracy: 0.7949\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.4089 - accuracy: 0.8052\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4030 - accuracy: 0.8086\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.3968 - accuracy: 0.8126\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.3910 - accuracy: 0.8168\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.3865 - accuracy: 0.8203\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.3823 - accuracy: 0.8242\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.3787 - accuracy: 0.8205\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.3745 - accuracy: 0.8265\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.3710 - accuracy: 0.8282\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.3667 - accuracy: 0.8299\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.3628 - accuracy: 0.8322\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.3608 - accuracy: 0.8330\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.3592 - accuracy: 0.8345\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.3525 - accuracy: 0.8393\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.3474 - accuracy: 0.8393\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.3452 - accuracy: 0.8427\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.3406 - accuracy: 0.8419\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.3360 - accuracy: 0.8467\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.3328 - accuracy: 0.8458\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.3274 - accuracy: 0.8532\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.3232 - accuracy: 0.8518\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.3181 - accuracy: 0.8552\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.3134 - accuracy: 0.8609\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.3090 - accuracy: 0.8626\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.3057 - accuracy: 0.8615\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.2986 - accuracy: 0.8695\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.2956 - accuracy: 0.8686\n",
            "[CV]  activation=relu, batch_size=300, epochs=30, nodes=256, total=   3.4s\n",
            "[CV] activation=relu, batch_size=300, epochs=30, nodes=256 ...........\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.5300 - accuracy: 0.7199\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.4286 - accuracy: 0.7924\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.4176 - accuracy: 0.8040\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.4058 - accuracy: 0.8140\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4005 - accuracy: 0.8120\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.3953 - accuracy: 0.8160\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.3902 - accuracy: 0.8151\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.3866 - accuracy: 0.8188\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.3862 - accuracy: 0.8200\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.3795 - accuracy: 0.8220\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.3763 - accuracy: 0.8239\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.3721 - accuracy: 0.8294\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.3685 - accuracy: 0.8276\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.3663 - accuracy: 0.8257\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.3627 - accuracy: 0.8342\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.3613 - accuracy: 0.8311\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.3559 - accuracy: 0.8370\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.3530 - accuracy: 0.8387\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.3485 - accuracy: 0.8433\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.3453 - accuracy: 0.8430\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.3436 - accuracy: 0.8461\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.3395 - accuracy: 0.8473\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.3353 - accuracy: 0.8461\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.3314 - accuracy: 0.8507\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.3250 - accuracy: 0.8544\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.3241 - accuracy: 0.8518\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.3202 - accuracy: 0.8547\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.3157 - accuracy: 0.8552\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.3083 - accuracy: 0.8638\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.3045 - accuracy: 0.8626\n",
            "[CV]  activation=relu, batch_size=300, epochs=30, nodes=256, total=   3.0s\n",
            "[CV] activation=relu, batch_size=300, epochs=30, nodes=256 ...........\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.5409 - accuracy: 0.6985\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.4278 - accuracy: 0.7887\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.4106 - accuracy: 0.8023\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.3993 - accuracy: 0.8094\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.3936 - accuracy: 0.8117\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.3872 - accuracy: 0.8168\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.3828 - accuracy: 0.8214\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.3780 - accuracy: 0.8242\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.3743 - accuracy: 0.8262\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.3699 - accuracy: 0.8319\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.3665 - accuracy: 0.8285\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.3627 - accuracy: 0.8333\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.3574 - accuracy: 0.8362\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.3599 - accuracy: 0.8285\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.3525 - accuracy: 0.8390\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.3479 - accuracy: 0.8382\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.3443 - accuracy: 0.8430\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.3427 - accuracy: 0.8393\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.3369 - accuracy: 0.8467\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.3342 - accuracy: 0.8416\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.3302 - accuracy: 0.8504\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.3273 - accuracy: 0.8518\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.3227 - accuracy: 0.8481\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.3174 - accuracy: 0.8572\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.3111 - accuracy: 0.8589\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.3108 - accuracy: 0.8604\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.3086 - accuracy: 0.8584\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.3025 - accuracy: 0.8641\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.2991 - accuracy: 0.8675\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.2965 - accuracy: 0.8743\n",
            "[CV]  activation=relu, batch_size=300, epochs=30, nodes=256, total=   3.0s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=10, nodes=64 ..........\n",
            "Epoch 1/10\n",
            "71/71 - 1s - loss: 0.5814 - accuracy: 0.6951\n",
            "Epoch 2/10\n",
            "71/71 - 0s - loss: 0.4971 - accuracy: 0.7415\n",
            "Epoch 3/10\n",
            "71/71 - 0s - loss: 0.4472 - accuracy: 0.7813\n",
            "Epoch 4/10\n",
            "71/71 - 0s - loss: 0.4315 - accuracy: 0.7892\n",
            "Epoch 5/10\n",
            "71/71 - 0s - loss: 0.4245 - accuracy: 0.7978\n",
            "Epoch 6/10\n",
            "71/71 - 0s - loss: 0.4227 - accuracy: 0.7986\n",
            "Epoch 7/10\n",
            "71/71 - 0s - loss: 0.4201 - accuracy: 0.7955\n",
            "Epoch 8/10\n",
            "71/71 - 0s - loss: 0.4188 - accuracy: 0.7981\n",
            "Epoch 9/10\n",
            "71/71 - 0s - loss: 0.4174 - accuracy: 0.7995\n",
            "Epoch 10/10\n",
            "71/71 - 0s - loss: 0.4189 - accuracy: 0.7998\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=10, nodes=64, total=   1.7s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=10, nodes=64 ..........\n",
            "Epoch 1/10\n",
            "71/71 - 1s - loss: 0.5451 - accuracy: 0.7381\n",
            "Epoch 2/10\n",
            "71/71 - 0s - loss: 0.4744 - accuracy: 0.7591\n",
            "Epoch 3/10\n",
            "71/71 - 0s - loss: 0.4367 - accuracy: 0.7929\n",
            "Epoch 4/10\n",
            "71/71 - 0s - loss: 0.4290 - accuracy: 0.7966\n",
            "Epoch 5/10\n",
            "71/71 - 0s - loss: 0.4240 - accuracy: 0.7944\n",
            "Epoch 6/10\n",
            "71/71 - 0s - loss: 0.4233 - accuracy: 0.7986\n",
            "Epoch 7/10\n",
            "71/71 - 0s - loss: 0.4193 - accuracy: 0.7986\n",
            "Epoch 8/10\n",
            "71/71 - 0s - loss: 0.4179 - accuracy: 0.8032\n",
            "Epoch 9/10\n",
            "71/71 - 0s - loss: 0.4184 - accuracy: 0.8009\n",
            "Epoch 10/10\n",
            "71/71 - 0s - loss: 0.4169 - accuracy: 0.8023\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=10, nodes=64, total=   1.7s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=10, nodes=64 ..........\n",
            "Epoch 1/10\n",
            "71/71 - 1s - loss: 0.5871 - accuracy: 0.6854\n",
            "Epoch 2/10\n",
            "71/71 - 0s - loss: 0.4960 - accuracy: 0.7423\n",
            "Epoch 3/10\n",
            "71/71 - 0s - loss: 0.4442 - accuracy: 0.7864\n",
            "Epoch 4/10\n",
            "71/71 - 0s - loss: 0.4276 - accuracy: 0.7961\n",
            "Epoch 5/10\n",
            "71/71 - 0s - loss: 0.4209 - accuracy: 0.7986\n",
            "Epoch 6/10\n",
            "71/71 - 0s - loss: 0.4166 - accuracy: 0.8035\n",
            "Epoch 7/10\n",
            "71/71 - 0s - loss: 0.4143 - accuracy: 0.8035\n",
            "Epoch 8/10\n",
            "71/71 - 0s - loss: 0.4124 - accuracy: 0.8018\n",
            "Epoch 9/10\n",
            "71/71 - 0s - loss: 0.4123 - accuracy: 0.8015\n",
            "Epoch 10/10\n",
            "71/71 - 0s - loss: 0.4103 - accuracy: 0.8026\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=10, nodes=64, total=   1.7s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=10, nodes=128 .........\n",
            "Epoch 1/10\n",
            "71/71 - 1s - loss: 0.5404 - accuracy: 0.7287\n",
            "Epoch 2/10\n",
            "71/71 - 0s - loss: 0.4479 - accuracy: 0.7733\n",
            "Epoch 3/10\n",
            "71/71 - 0s - loss: 0.4254 - accuracy: 0.7944\n",
            "Epoch 4/10\n",
            "71/71 - 0s - loss: 0.4259 - accuracy: 0.7941\n",
            "Epoch 5/10\n",
            "71/71 - 0s - loss: 0.4204 - accuracy: 0.7938\n",
            "Epoch 6/10\n",
            "71/71 - 0s - loss: 0.4197 - accuracy: 0.8018\n",
            "Epoch 7/10\n",
            "71/71 - 0s - loss: 0.4183 - accuracy: 0.8003\n",
            "Epoch 8/10\n",
            "71/71 - 0s - loss: 0.4181 - accuracy: 0.8015\n",
            "Epoch 9/10\n",
            "71/71 - 0s - loss: 0.4174 - accuracy: 0.8035\n",
            "Epoch 10/10\n",
            "71/71 - 0s - loss: 0.4218 - accuracy: 0.7955\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=10, nodes=128, total=   1.7s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=10, nodes=128 .........\n",
            "Epoch 1/10\n",
            "71/71 - 1s - loss: 0.5403 - accuracy: 0.7409\n",
            "Epoch 2/10\n",
            "71/71 - 0s - loss: 0.4528 - accuracy: 0.7784\n",
            "Epoch 3/10\n",
            "71/71 - 0s - loss: 0.4311 - accuracy: 0.7904\n",
            "Epoch 4/10\n",
            "71/71 - 0s - loss: 0.4263 - accuracy: 0.7944\n",
            "Epoch 5/10\n",
            "71/71 - 0s - loss: 0.4240 - accuracy: 0.7924\n",
            "Epoch 6/10\n",
            "71/71 - 0s - loss: 0.4212 - accuracy: 0.7952\n",
            "Epoch 7/10\n",
            "71/71 - 0s - loss: 0.4181 - accuracy: 0.8032\n",
            "Epoch 8/10\n",
            "71/71 - 0s - loss: 0.4167 - accuracy: 0.8006\n",
            "Epoch 9/10\n",
            "71/71 - 0s - loss: 0.4156 - accuracy: 0.8040\n",
            "Epoch 10/10\n",
            "71/71 - 0s - loss: 0.4169 - accuracy: 0.7989\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=10, nodes=128, total=   1.7s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=10, nodes=128 .........\n",
            "Epoch 1/10\n",
            "71/71 - 1s - loss: 0.5159 - accuracy: 0.7480\n",
            "Epoch 2/10\n",
            "71/71 - 0s - loss: 0.4345 - accuracy: 0.7870\n",
            "Epoch 3/10\n",
            "71/71 - 0s - loss: 0.4213 - accuracy: 0.7966\n",
            "Epoch 4/10\n",
            "71/71 - 0s - loss: 0.4204 - accuracy: 0.7978\n",
            "Epoch 5/10\n",
            "71/71 - 0s - loss: 0.4177 - accuracy: 0.7961\n",
            "Epoch 6/10\n",
            "71/71 - 0s - loss: 0.4121 - accuracy: 0.8018\n",
            "Epoch 7/10\n",
            "71/71 - 0s - loss: 0.4110 - accuracy: 0.8077\n",
            "Epoch 8/10\n",
            "71/71 - 0s - loss: 0.4101 - accuracy: 0.8020\n",
            "Epoch 9/10\n",
            "71/71 - 0s - loss: 0.4093 - accuracy: 0.8040\n",
            "Epoch 10/10\n",
            "71/71 - 0s - loss: 0.4104 - accuracy: 0.7995\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=10, nodes=128, total=   1.7s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=10, nodes=256 .........\n",
            "Epoch 1/10\n",
            "71/71 - 1s - loss: 0.5346 - accuracy: 0.7378\n",
            "Epoch 2/10\n",
            "71/71 - 0s - loss: 0.4375 - accuracy: 0.7850\n",
            "Epoch 3/10\n",
            "71/71 - 0s - loss: 0.4263 - accuracy: 0.7932\n",
            "Epoch 4/10\n",
            "71/71 - 0s - loss: 0.4244 - accuracy: 0.7935\n",
            "Epoch 5/10\n",
            "71/71 - 0s - loss: 0.4231 - accuracy: 0.7895\n",
            "Epoch 6/10\n",
            "71/71 - 0s - loss: 0.4209 - accuracy: 0.8003\n",
            "Epoch 7/10\n",
            "71/71 - 0s - loss: 0.4201 - accuracy: 0.7975\n",
            "Epoch 8/10\n",
            "71/71 - 0s - loss: 0.4218 - accuracy: 0.7981\n",
            "Epoch 9/10\n",
            "71/71 - 0s - loss: 0.4198 - accuracy: 0.8032\n",
            "Epoch 10/10\n",
            "71/71 - 0s - loss: 0.4186 - accuracy: 0.7966\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=10, nodes=256, total=   2.9s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=10, nodes=256 .........\n",
            "Epoch 1/10\n",
            "71/71 - 1s - loss: 0.5472 - accuracy: 0.7403\n",
            "Epoch 2/10\n",
            "71/71 - 0s - loss: 0.4412 - accuracy: 0.7850\n",
            "Epoch 3/10\n",
            "71/71 - 0s - loss: 0.4310 - accuracy: 0.7921\n",
            "Epoch 4/10\n",
            "71/71 - 0s - loss: 0.4249 - accuracy: 0.7984\n",
            "Epoch 5/10\n",
            "71/71 - 0s - loss: 0.4206 - accuracy: 0.7998\n",
            "Epoch 6/10\n",
            "71/71 - 0s - loss: 0.4214 - accuracy: 0.7952\n",
            "Epoch 7/10\n",
            "71/71 - 0s - loss: 0.4223 - accuracy: 0.7915\n",
            "Epoch 8/10\n",
            "71/71 - 0s - loss: 0.4213 - accuracy: 0.7989\n",
            "Epoch 9/10\n",
            "71/71 - 0s - loss: 0.4158 - accuracy: 0.8057\n",
            "Epoch 10/10\n",
            "71/71 - 0s - loss: 0.4181 - accuracy: 0.7995\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=10, nodes=256, total=   2.7s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=10, nodes=256 .........\n",
            "Epoch 1/10\n",
            "71/71 - 1s - loss: 0.5482 - accuracy: 0.7295\n",
            "Epoch 2/10\n",
            "71/71 - 0s - loss: 0.4399 - accuracy: 0.7895\n",
            "Epoch 3/10\n",
            "71/71 - 0s - loss: 0.4266 - accuracy: 0.7929\n",
            "Epoch 4/10\n",
            "71/71 - 0s - loss: 0.4270 - accuracy: 0.7921\n",
            "Epoch 5/10\n",
            "71/71 - 0s - loss: 0.4175 - accuracy: 0.7961\n",
            "Epoch 6/10\n",
            "71/71 - 0s - loss: 0.4169 - accuracy: 0.7992\n",
            "Epoch 7/10\n",
            "71/71 - 0s - loss: 0.4115 - accuracy: 0.8023\n",
            "Epoch 8/10\n",
            "71/71 - 0s - loss: 0.4130 - accuracy: 0.8012\n",
            "Epoch 9/10\n",
            "71/71 - 0s - loss: 0.4097 - accuracy: 0.8029\n",
            "Epoch 10/10\n",
            "71/71 - 0s - loss: 0.4144 - accuracy: 0.8006\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=10, nodes=256, total=   2.7s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=20, nodes=64 ..........\n",
            "Epoch 1/20\n",
            "71/71 - 1s - loss: 0.5616 - accuracy: 0.7338\n",
            "Epoch 2/20\n",
            "71/71 - 0s - loss: 0.4823 - accuracy: 0.7546\n",
            "Epoch 3/20\n",
            "71/71 - 0s - loss: 0.4349 - accuracy: 0.7915\n",
            "Epoch 4/20\n",
            "71/71 - 0s - loss: 0.4270 - accuracy: 0.7958\n",
            "Epoch 5/20\n",
            "71/71 - 0s - loss: 0.4215 - accuracy: 0.7969\n",
            "Epoch 6/20\n",
            "71/71 - 0s - loss: 0.4205 - accuracy: 0.8003\n",
            "Epoch 7/20\n",
            "71/71 - 0s - loss: 0.4185 - accuracy: 0.7981\n",
            "Epoch 8/20\n",
            "71/71 - 0s - loss: 0.4177 - accuracy: 0.8015\n",
            "Epoch 9/20\n",
            "71/71 - 0s - loss: 0.4164 - accuracy: 0.8020\n",
            "Epoch 10/20\n",
            "71/71 - 0s - loss: 0.4184 - accuracy: 0.7969\n",
            "Epoch 11/20\n",
            "71/71 - 0s - loss: 0.4160 - accuracy: 0.8001\n",
            "Epoch 12/20\n",
            "71/71 - 0s - loss: 0.4150 - accuracy: 0.8043\n",
            "Epoch 13/20\n",
            "71/71 - 0s - loss: 0.4152 - accuracy: 0.8038\n",
            "Epoch 14/20\n",
            "71/71 - 0s - loss: 0.4154 - accuracy: 0.7992\n",
            "Epoch 15/20\n",
            "71/71 - 0s - loss: 0.4146 - accuracy: 0.8020\n",
            "Epoch 16/20\n",
            "71/71 - 0s - loss: 0.4146 - accuracy: 0.8032\n",
            "Epoch 17/20\n",
            "71/71 - 0s - loss: 0.4147 - accuracy: 0.8038\n",
            "Epoch 18/20\n",
            "71/71 - 0s - loss: 0.4146 - accuracy: 0.7998\n",
            "Epoch 19/20\n",
            "71/71 - 0s - loss: 0.4126 - accuracy: 0.8040\n",
            "Epoch 20/20\n",
            "71/71 - 0s - loss: 0.4131 - accuracy: 0.7998\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=20, nodes=64, total=   2.6s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=20, nodes=64 ..........\n",
            "Epoch 1/20\n",
            "71/71 - 1s - loss: 0.5786 - accuracy: 0.6977\n",
            "Epoch 2/20\n",
            "71/71 - 0s - loss: 0.4951 - accuracy: 0.7423\n",
            "Epoch 3/20\n",
            "71/71 - 0s - loss: 0.4486 - accuracy: 0.7816\n",
            "Epoch 4/20\n",
            "71/71 - 0s - loss: 0.4329 - accuracy: 0.7944\n",
            "Epoch 5/20\n",
            "71/71 - 0s - loss: 0.4261 - accuracy: 0.7949\n",
            "Epoch 6/20\n",
            "71/71 - 0s - loss: 0.4245 - accuracy: 0.8006\n",
            "Epoch 7/20\n",
            "71/71 - 0s - loss: 0.4203 - accuracy: 0.8012\n",
            "Epoch 8/20\n",
            "71/71 - 0s - loss: 0.4185 - accuracy: 0.8057\n",
            "Epoch 9/20\n",
            "71/71 - 0s - loss: 0.4187 - accuracy: 0.8032\n",
            "Epoch 10/20\n",
            "71/71 - 0s - loss: 0.4173 - accuracy: 0.8038\n",
            "Epoch 11/20\n",
            "71/71 - 0s - loss: 0.4185 - accuracy: 0.8043\n",
            "Epoch 12/20\n",
            "71/71 - 0s - loss: 0.4152 - accuracy: 0.8032\n",
            "Epoch 13/20\n",
            "71/71 - 0s - loss: 0.4162 - accuracy: 0.8012\n",
            "Epoch 14/20\n",
            "71/71 - 0s - loss: 0.4151 - accuracy: 0.8069\n",
            "Epoch 15/20\n",
            "71/71 - 0s - loss: 0.4146 - accuracy: 0.8020\n",
            "Epoch 16/20\n",
            "71/71 - 0s - loss: 0.4147 - accuracy: 0.8043\n",
            "Epoch 17/20\n",
            "71/71 - 0s - loss: 0.4150 - accuracy: 0.8043\n",
            "Epoch 18/20\n",
            "71/71 - 0s - loss: 0.4137 - accuracy: 0.8015\n",
            "Epoch 19/20\n",
            "71/71 - 0s - loss: 0.4128 - accuracy: 0.8055\n",
            "Epoch 20/20\n",
            "71/71 - 0s - loss: 0.4127 - accuracy: 0.8040\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=20, nodes=64, total=   2.6s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=20, nodes=64 ..........\n",
            "Epoch 1/20\n",
            "71/71 - 1s - loss: 0.6035 - accuracy: 0.6704\n",
            "Epoch 2/20\n",
            "71/71 - 0s - loss: 0.5086 - accuracy: 0.7332\n",
            "Epoch 3/20\n",
            "71/71 - 0s - loss: 0.4567 - accuracy: 0.7753\n",
            "Epoch 4/20\n",
            "71/71 - 0s - loss: 0.4337 - accuracy: 0.7910\n",
            "Epoch 5/20\n",
            "71/71 - 0s - loss: 0.4249 - accuracy: 0.7992\n",
            "Epoch 6/20\n",
            "71/71 - 0s - loss: 0.4198 - accuracy: 0.8032\n",
            "Epoch 7/20\n",
            "71/71 - 0s - loss: 0.4172 - accuracy: 0.8032\n",
            "Epoch 8/20\n",
            "71/71 - 0s - loss: 0.4149 - accuracy: 0.8018\n",
            "Epoch 9/20\n",
            "71/71 - 0s - loss: 0.4144 - accuracy: 0.8003\n",
            "Epoch 10/20\n",
            "71/71 - 0s - loss: 0.4121 - accuracy: 0.8003\n",
            "Epoch 11/20\n",
            "71/71 - 0s - loss: 0.4129 - accuracy: 0.7989\n",
            "Epoch 12/20\n",
            "71/71 - 0s - loss: 0.4091 - accuracy: 0.8046\n",
            "Epoch 13/20\n",
            "71/71 - 0s - loss: 0.4082 - accuracy: 0.8066\n",
            "Epoch 14/20\n",
            "71/71 - 0s - loss: 0.4084 - accuracy: 0.8092\n",
            "Epoch 15/20\n",
            "71/71 - 0s - loss: 0.4079 - accuracy: 0.8060\n",
            "Epoch 16/20\n",
            "71/71 - 0s - loss: 0.4077 - accuracy: 0.8038\n",
            "Epoch 17/20\n",
            "71/71 - 0s - loss: 0.4070 - accuracy: 0.8057\n",
            "Epoch 18/20\n",
            "71/71 - 0s - loss: 0.4079 - accuracy: 0.8049\n",
            "Epoch 19/20\n",
            "71/71 - 0s - loss: 0.4062 - accuracy: 0.8060\n",
            "Epoch 20/20\n",
            "71/71 - 0s - loss: 0.4064 - accuracy: 0.8020\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=20, nodes=64, total=   2.7s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=20, nodes=128 .........\n",
            "Epoch 1/20\n",
            "71/71 - 1s - loss: 0.5588 - accuracy: 0.7136\n",
            "Epoch 2/20\n",
            "71/71 - 0s - loss: 0.4609 - accuracy: 0.7722\n",
            "Epoch 3/20\n",
            "71/71 - 0s - loss: 0.4279 - accuracy: 0.7927\n",
            "Epoch 4/20\n",
            "71/71 - 0s - loss: 0.4266 - accuracy: 0.7929\n",
            "Epoch 5/20\n",
            "71/71 - 0s - loss: 0.4207 - accuracy: 0.7949\n",
            "Epoch 6/20\n",
            "71/71 - 0s - loss: 0.4196 - accuracy: 0.8012\n",
            "Epoch 7/20\n",
            "71/71 - 0s - loss: 0.4183 - accuracy: 0.8003\n",
            "Epoch 8/20\n",
            "71/71 - 0s - loss: 0.4179 - accuracy: 0.8040\n",
            "Epoch 9/20\n",
            "71/71 - 0s - loss: 0.4171 - accuracy: 0.8023\n",
            "Epoch 10/20\n",
            "71/71 - 0s - loss: 0.4215 - accuracy: 0.7955\n",
            "Epoch 11/20\n",
            "71/71 - 0s - loss: 0.4193 - accuracy: 0.7935\n",
            "Epoch 12/20\n",
            "71/71 - 0s - loss: 0.4168 - accuracy: 0.7992\n",
            "Epoch 13/20\n",
            "71/71 - 0s - loss: 0.4161 - accuracy: 0.8006\n",
            "Epoch 14/20\n",
            "71/71 - 0s - loss: 0.4178 - accuracy: 0.7972\n",
            "Epoch 15/20\n",
            "71/71 - 0s - loss: 0.4163 - accuracy: 0.8009\n",
            "Epoch 16/20\n",
            "71/71 - 0s - loss: 0.4164 - accuracy: 0.7952\n",
            "Epoch 17/20\n",
            "71/71 - 0s - loss: 0.4153 - accuracy: 0.7998\n",
            "Epoch 18/20\n",
            "71/71 - 0s - loss: 0.4159 - accuracy: 0.7989\n",
            "Epoch 19/20\n",
            "71/71 - 0s - loss: 0.4130 - accuracy: 0.8046\n",
            "Epoch 20/20\n",
            "71/71 - 0s - loss: 0.4137 - accuracy: 0.7961\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=20, nodes=128, total=   2.9s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=20, nodes=128 .........\n",
            "Epoch 1/20\n",
            "71/71 - 1s - loss: 0.5496 - accuracy: 0.7241\n",
            "Epoch 2/20\n",
            "71/71 - 0s - loss: 0.4562 - accuracy: 0.7733\n",
            "Epoch 3/20\n",
            "71/71 - 0s - loss: 0.4302 - accuracy: 0.7929\n",
            "Epoch 4/20\n",
            "71/71 - 0s - loss: 0.4253 - accuracy: 0.7966\n",
            "Epoch 5/20\n",
            "71/71 - 0s - loss: 0.4236 - accuracy: 0.7941\n",
            "Epoch 6/20\n",
            "71/71 - 0s - loss: 0.4204 - accuracy: 0.7972\n",
            "Epoch 7/20\n",
            "71/71 - 0s - loss: 0.4172 - accuracy: 0.8038\n",
            "Epoch 8/20\n",
            "71/71 - 0s - loss: 0.4158 - accuracy: 0.8052\n",
            "Epoch 9/20\n",
            "71/71 - 0s - loss: 0.4149 - accuracy: 0.8038\n",
            "Epoch 10/20\n",
            "71/71 - 0s - loss: 0.4164 - accuracy: 0.8018\n",
            "Epoch 11/20\n",
            "71/71 - 0s - loss: 0.4225 - accuracy: 0.7932\n",
            "Epoch 12/20\n",
            "71/71 - 0s - loss: 0.4165 - accuracy: 0.8006\n",
            "Epoch 13/20\n",
            "71/71 - 0s - loss: 0.4168 - accuracy: 0.8012\n",
            "Epoch 14/20\n",
            "71/71 - 0s - loss: 0.4171 - accuracy: 0.7989\n",
            "Epoch 15/20\n",
            "71/71 - 0s - loss: 0.4143 - accuracy: 0.8029\n",
            "Epoch 16/20\n",
            "71/71 - 0s - loss: 0.4158 - accuracy: 0.8055\n",
            "Epoch 17/20\n",
            "71/71 - 0s - loss: 0.4168 - accuracy: 0.8006\n",
            "Epoch 18/20\n",
            "71/71 - 0s - loss: 0.4144 - accuracy: 0.8057\n",
            "Epoch 19/20\n",
            "71/71 - 0s - loss: 0.4136 - accuracy: 0.8029\n",
            "Epoch 20/20\n",
            "71/71 - 0s - loss: 0.4135 - accuracy: 0.7998\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=20, nodes=128, total=   2.7s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=20, nodes=128 .........\n",
            "Epoch 1/20\n",
            "71/71 - 1s - loss: 0.5266 - accuracy: 0.7423\n",
            "Epoch 2/20\n",
            "71/71 - 0s - loss: 0.4385 - accuracy: 0.7912\n",
            "Epoch 3/20\n",
            "71/71 - 0s - loss: 0.4233 - accuracy: 0.7932\n",
            "Epoch 4/20\n",
            "71/71 - 0s - loss: 0.4220 - accuracy: 0.7969\n",
            "Epoch 5/20\n",
            "71/71 - 0s - loss: 0.4189 - accuracy: 0.7952\n",
            "Epoch 6/20\n",
            "71/71 - 0s - loss: 0.4131 - accuracy: 0.8012\n",
            "Epoch 7/20\n",
            "71/71 - 0s - loss: 0.4119 - accuracy: 0.8063\n",
            "Epoch 8/20\n",
            "71/71 - 0s - loss: 0.4107 - accuracy: 0.8020\n",
            "Epoch 9/20\n",
            "71/71 - 0s - loss: 0.4098 - accuracy: 0.8043\n",
            "Epoch 10/20\n",
            "71/71 - 0s - loss: 0.4106 - accuracy: 0.7992\n",
            "Epoch 11/20\n",
            "71/71 - 0s - loss: 0.4119 - accuracy: 0.7952\n",
            "Epoch 12/20\n",
            "71/71 - 0s - loss: 0.4084 - accuracy: 0.8032\n",
            "Epoch 13/20\n",
            "71/71 - 0s - loss: 0.4069 - accuracy: 0.8077\n",
            "Epoch 14/20\n",
            "71/71 - 0s - loss: 0.4097 - accuracy: 0.7998\n",
            "Epoch 15/20\n",
            "71/71 - 0s - loss: 0.4072 - accuracy: 0.8040\n",
            "Epoch 16/20\n",
            "71/71 - 0s - loss: 0.4084 - accuracy: 0.8020\n",
            "Epoch 17/20\n",
            "71/71 - 0s - loss: 0.4080 - accuracy: 0.8029\n",
            "Epoch 18/20\n",
            "71/71 - 0s - loss: 0.4082 - accuracy: 0.8057\n",
            "Epoch 19/20\n",
            "71/71 - 0s - loss: 0.4072 - accuracy: 0.8032\n",
            "Epoch 20/20\n",
            "71/71 - 0s - loss: 0.4068 - accuracy: 0.7992\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=20, nodes=128, total=   2.8s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=20, nodes=256 .........\n",
            "Epoch 1/20\n",
            "71/71 - 1s - loss: 0.5203 - accuracy: 0.7432\n",
            "Epoch 2/20\n",
            "71/71 - 0s - loss: 0.4347 - accuracy: 0.7875\n",
            "Epoch 3/20\n",
            "71/71 - 0s - loss: 0.4275 - accuracy: 0.7952\n",
            "Epoch 4/20\n",
            "71/71 - 0s - loss: 0.4244 - accuracy: 0.7935\n",
            "Epoch 5/20\n",
            "71/71 - 0s - loss: 0.4246 - accuracy: 0.7895\n",
            "Epoch 6/20\n",
            "71/71 - 0s - loss: 0.4204 - accuracy: 0.8001\n",
            "Epoch 7/20\n",
            "71/71 - 0s - loss: 0.4200 - accuracy: 0.8003\n",
            "Epoch 8/20\n",
            "71/71 - 0s - loss: 0.4227 - accuracy: 0.7966\n",
            "Epoch 9/20\n",
            "71/71 - 0s - loss: 0.4207 - accuracy: 0.8055\n",
            "Epoch 10/20\n",
            "71/71 - 0s - loss: 0.4176 - accuracy: 0.7978\n",
            "Epoch 11/20\n",
            "71/71 - 0s - loss: 0.4316 - accuracy: 0.7799\n",
            "Epoch 12/20\n",
            "71/71 - 0s - loss: 0.4165 - accuracy: 0.7995\n",
            "Epoch 13/20\n",
            "71/71 - 0s - loss: 0.4158 - accuracy: 0.8003\n",
            "Epoch 14/20\n",
            "71/71 - 0s - loss: 0.4219 - accuracy: 0.7938\n",
            "Epoch 15/20\n",
            "71/71 - 0s - loss: 0.4207 - accuracy: 0.7981\n",
            "Epoch 16/20\n",
            "71/71 - 0s - loss: 0.4164 - accuracy: 0.7966\n",
            "Epoch 17/20\n",
            "71/71 - 0s - loss: 0.4180 - accuracy: 0.7961\n",
            "Epoch 18/20\n",
            "71/71 - 0s - loss: 0.4198 - accuracy: 0.7961\n",
            "Epoch 19/20\n",
            "71/71 - 0s - loss: 0.4136 - accuracy: 0.8020\n",
            "Epoch 20/20\n",
            "71/71 - 0s - loss: 0.4151 - accuracy: 0.7947\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=20, nodes=256, total=   4.5s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=20, nodes=256 .........\n",
            "Epoch 1/20\n",
            "71/71 - 1s - loss: 0.5102 - accuracy: 0.7497\n",
            "Epoch 2/20\n",
            "71/71 - 0s - loss: 0.4329 - accuracy: 0.7918\n",
            "Epoch 3/20\n",
            "71/71 - 0s - loss: 0.4327 - accuracy: 0.7873\n",
            "Epoch 4/20\n",
            "71/71 - 0s - loss: 0.4227 - accuracy: 0.7975\n",
            "Epoch 5/20\n",
            "71/71 - 0s - loss: 0.4196 - accuracy: 0.8009\n",
            "Epoch 6/20\n",
            "71/71 - 0s - loss: 0.4214 - accuracy: 0.7981\n",
            "Epoch 7/20\n",
            "71/71 - 0s - loss: 0.4225 - accuracy: 0.7944\n",
            "Epoch 8/20\n",
            "71/71 - 0s - loss: 0.4215 - accuracy: 0.7998\n",
            "Epoch 9/20\n",
            "71/71 - 0s - loss: 0.4161 - accuracy: 0.8046\n",
            "Epoch 10/20\n",
            "71/71 - 0s - loss: 0.4180 - accuracy: 0.7998\n",
            "Epoch 11/20\n",
            "71/71 - 0s - loss: 0.4405 - accuracy: 0.7807\n",
            "Epoch 12/20\n",
            "71/71 - 0s - loss: 0.4178 - accuracy: 0.7972\n",
            "Epoch 13/20\n",
            "71/71 - 0s - loss: 0.4164 - accuracy: 0.8009\n",
            "Epoch 14/20\n",
            "71/71 - 0s - loss: 0.4172 - accuracy: 0.8015\n",
            "Epoch 15/20\n",
            "71/71 - 0s - loss: 0.4158 - accuracy: 0.8026\n",
            "Epoch 16/20\n",
            "71/71 - 0s - loss: 0.4165 - accuracy: 0.8023\n",
            "Epoch 17/20\n",
            "71/71 - 0s - loss: 0.4156 - accuracy: 0.8006\n",
            "Epoch 18/20\n",
            "71/71 - 0s - loss: 0.4181 - accuracy: 0.8018\n",
            "Epoch 19/20\n",
            "71/71 - 0s - loss: 0.4152 - accuracy: 0.8032\n",
            "Epoch 20/20\n",
            "71/71 - 0s - loss: 0.4145 - accuracy: 0.8003\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=20, nodes=256, total=   4.9s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=20, nodes=256 .........\n",
            "Epoch 1/20\n",
            "71/71 - 1s - loss: 0.5335 - accuracy: 0.7426\n",
            "Epoch 2/20\n",
            "71/71 - 0s - loss: 0.4398 - accuracy: 0.7867\n",
            "Epoch 3/20\n",
            "71/71 - 0s - loss: 0.4274 - accuracy: 0.7904\n",
            "Epoch 4/20\n",
            "71/71 - 0s - loss: 0.4269 - accuracy: 0.7895\n",
            "Epoch 5/20\n",
            "71/71 - 0s - loss: 0.4172 - accuracy: 0.7955\n",
            "Epoch 6/20\n",
            "71/71 - 0s - loss: 0.4165 - accuracy: 0.8006\n",
            "Epoch 7/20\n",
            "71/71 - 0s - loss: 0.4112 - accuracy: 0.8023\n",
            "Epoch 8/20\n",
            "71/71 - 0s - loss: 0.4124 - accuracy: 0.8038\n",
            "Epoch 9/20\n",
            "71/71 - 0s - loss: 0.4095 - accuracy: 0.8032\n",
            "Epoch 10/20\n",
            "71/71 - 0s - loss: 0.4144 - accuracy: 0.8001\n",
            "Epoch 11/20\n",
            "71/71 - 0s - loss: 0.4196 - accuracy: 0.7961\n",
            "Epoch 12/20\n",
            "71/71 - 0s - loss: 0.4117 - accuracy: 0.8023\n",
            "Epoch 13/20\n",
            "71/71 - 0s - loss: 0.4078 - accuracy: 0.8046\n",
            "Epoch 14/20\n",
            "71/71 - 0s - loss: 0.4094 - accuracy: 0.8040\n",
            "Epoch 15/20\n",
            "71/71 - 0s - loss: 0.4096 - accuracy: 0.8023\n",
            "Epoch 16/20\n",
            "71/71 - 0s - loss: 0.4104 - accuracy: 0.8006\n",
            "Epoch 17/20\n",
            "71/71 - 0s - loss: 0.4082 - accuracy: 0.8023\n",
            "Epoch 18/20\n",
            "71/71 - 0s - loss: 0.4074 - accuracy: 0.8080\n",
            "Epoch 19/20\n",
            "71/71 - 0s - loss: 0.4087 - accuracy: 0.8038\n",
            "Epoch 20/20\n",
            "71/71 - 0s - loss: 0.4059 - accuracy: 0.8001\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=20, nodes=256, total=   4.5s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=30, nodes=64 ..........\n",
            "Epoch 1/30\n",
            "71/71 - 1s - loss: 0.6026 - accuracy: 0.6815\n",
            "Epoch 2/30\n",
            "71/71 - 0s - loss: 0.5162 - accuracy: 0.7338\n",
            "Epoch 3/30\n",
            "71/71 - 0s - loss: 0.4617 - accuracy: 0.7722\n",
            "Epoch 4/30\n",
            "71/71 - 0s - loss: 0.4377 - accuracy: 0.7875\n",
            "Epoch 5/30\n",
            "71/71 - 0s - loss: 0.4276 - accuracy: 0.7941\n",
            "Epoch 6/30\n",
            "71/71 - 0s - loss: 0.4245 - accuracy: 0.7966\n",
            "Epoch 7/30\n",
            "71/71 - 0s - loss: 0.4213 - accuracy: 0.7972\n",
            "Epoch 8/30\n",
            "71/71 - 0s - loss: 0.4196 - accuracy: 0.7984\n",
            "Epoch 9/30\n",
            "71/71 - 0s - loss: 0.4179 - accuracy: 0.7998\n",
            "Epoch 10/30\n",
            "71/71 - 0s - loss: 0.4192 - accuracy: 0.7986\n",
            "Epoch 11/30\n",
            "71/71 - 0s - loss: 0.4167 - accuracy: 0.8003\n",
            "Epoch 12/30\n",
            "71/71 - 0s - loss: 0.4155 - accuracy: 0.8040\n",
            "Epoch 13/30\n",
            "71/71 - 0s - loss: 0.4156 - accuracy: 0.8040\n",
            "Epoch 14/30\n",
            "71/71 - 0s - loss: 0.4155 - accuracy: 0.8001\n",
            "Epoch 15/30\n",
            "71/71 - 0s - loss: 0.4147 - accuracy: 0.8032\n",
            "Epoch 16/30\n",
            "71/71 - 0s - loss: 0.4147 - accuracy: 0.8046\n",
            "Epoch 17/30\n",
            "71/71 - 0s - loss: 0.4149 - accuracy: 0.8046\n",
            "Epoch 18/30\n",
            "71/71 - 0s - loss: 0.4146 - accuracy: 0.8009\n",
            "Epoch 19/30\n",
            "71/71 - 0s - loss: 0.4128 - accuracy: 0.8049\n",
            "Epoch 20/30\n",
            "71/71 - 0s - loss: 0.4131 - accuracy: 0.8001\n",
            "Epoch 21/30\n",
            "71/71 - 0s - loss: 0.4129 - accuracy: 0.8043\n",
            "Epoch 22/30\n",
            "71/71 - 0s - loss: 0.4128 - accuracy: 0.8018\n",
            "Epoch 23/30\n",
            "71/71 - 0s - loss: 0.4128 - accuracy: 0.8023\n",
            "Epoch 24/30\n",
            "71/71 - 0s - loss: 0.4118 - accuracy: 0.8012\n",
            "Epoch 25/30\n",
            "71/71 - 0s - loss: 0.4122 - accuracy: 0.8035\n",
            "Epoch 26/30\n",
            "71/71 - 0s - loss: 0.4121 - accuracy: 0.8035\n",
            "Epoch 27/30\n",
            "71/71 - 0s - loss: 0.4119 - accuracy: 0.8012\n",
            "Epoch 28/30\n",
            "71/71 - 0s - loss: 0.4114 - accuracy: 0.8029\n",
            "Epoch 29/30\n",
            "71/71 - 0s - loss: 0.4110 - accuracy: 0.8057\n",
            "Epoch 30/30\n",
            "71/71 - 0s - loss: 0.4101 - accuracy: 0.8032\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=30, nodes=64, total=   3.6s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=30, nodes=64 ..........\n",
            "Epoch 1/30\n",
            "71/71 - 1s - loss: 0.5756 - accuracy: 0.7090\n",
            "Epoch 2/30\n",
            "71/71 - 0s - loss: 0.5008 - accuracy: 0.7412\n",
            "Epoch 3/30\n",
            "71/71 - 0s - loss: 0.4531 - accuracy: 0.7790\n",
            "Epoch 4/30\n",
            "71/71 - 0s - loss: 0.4360 - accuracy: 0.7924\n",
            "Epoch 5/30\n",
            "71/71 - 0s - loss: 0.4284 - accuracy: 0.7949\n",
            "Epoch 6/30\n",
            "71/71 - 0s - loss: 0.4264 - accuracy: 0.7975\n",
            "Epoch 7/30\n",
            "71/71 - 0s - loss: 0.4218 - accuracy: 0.8001\n",
            "Epoch 8/30\n",
            "71/71 - 0s - loss: 0.4198 - accuracy: 0.8040\n",
            "Epoch 9/30\n",
            "71/71 - 0s - loss: 0.4198 - accuracy: 0.8029\n",
            "Epoch 10/30\n",
            "71/71 - 0s - loss: 0.4182 - accuracy: 0.8029\n",
            "Epoch 11/30\n",
            "71/71 - 0s - loss: 0.4196 - accuracy: 0.8029\n",
            "Epoch 12/30\n",
            "71/71 - 0s - loss: 0.4160 - accuracy: 0.8026\n",
            "Epoch 13/30\n",
            "71/71 - 0s - loss: 0.4170 - accuracy: 0.7998\n",
            "Epoch 14/30\n",
            "71/71 - 0s - loss: 0.4159 - accuracy: 0.8052\n",
            "Epoch 15/30\n",
            "71/71 - 0s - loss: 0.4153 - accuracy: 0.8026\n",
            "Epoch 16/30\n",
            "71/71 - 0s - loss: 0.4154 - accuracy: 0.8040\n",
            "Epoch 17/30\n",
            "71/71 - 0s - loss: 0.4157 - accuracy: 0.8063\n",
            "Epoch 18/30\n",
            "71/71 - 0s - loss: 0.4144 - accuracy: 0.8018\n",
            "Epoch 19/30\n",
            "71/71 - 0s - loss: 0.4134 - accuracy: 0.8066\n",
            "Epoch 20/30\n",
            "71/71 - 0s - loss: 0.4133 - accuracy: 0.8055\n",
            "Epoch 21/30\n",
            "71/71 - 0s - loss: 0.4132 - accuracy: 0.8009\n",
            "Epoch 22/30\n",
            "71/71 - 0s - loss: 0.4131 - accuracy: 0.8009\n",
            "Epoch 23/30\n",
            "71/71 - 0s - loss: 0.4140 - accuracy: 0.8052\n",
            "Epoch 24/30\n",
            "71/71 - 0s - loss: 0.4127 - accuracy: 0.8060\n",
            "Epoch 25/30\n",
            "71/71 - 0s - loss: 0.4139 - accuracy: 0.8049\n",
            "Epoch 26/30\n",
            "71/71 - 0s - loss: 0.4120 - accuracy: 0.8026\n",
            "Epoch 27/30\n",
            "71/71 - 0s - loss: 0.4126 - accuracy: 0.8046\n",
            "Epoch 28/30\n",
            "71/71 - 0s - loss: 0.4137 - accuracy: 0.8040\n",
            "Epoch 29/30\n",
            "71/71 - 0s - loss: 0.4113 - accuracy: 0.8038\n",
            "Epoch 30/30\n",
            "71/71 - 0s - loss: 0.4111 - accuracy: 0.8057\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=30, nodes=64, total=   3.6s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=30, nodes=64 ..........\n",
            "Epoch 1/30\n",
            "71/71 - 1s - loss: 0.5491 - accuracy: 0.7307\n",
            "Epoch 2/30\n",
            "71/71 - 0s - loss: 0.4662 - accuracy: 0.7631\n",
            "Epoch 3/30\n",
            "71/71 - 0s - loss: 0.4305 - accuracy: 0.7932\n",
            "Epoch 4/30\n",
            "71/71 - 0s - loss: 0.4235 - accuracy: 0.7995\n",
            "Epoch 5/30\n",
            "71/71 - 0s - loss: 0.4189 - accuracy: 0.7995\n",
            "Epoch 6/30\n",
            "71/71 - 0s - loss: 0.4149 - accuracy: 0.8015\n",
            "Epoch 7/30\n",
            "71/71 - 0s - loss: 0.4131 - accuracy: 0.8029\n",
            "Epoch 8/30\n",
            "71/71 - 0s - loss: 0.4115 - accuracy: 0.8001\n",
            "Epoch 9/30\n",
            "71/71 - 0s - loss: 0.4120 - accuracy: 0.8038\n",
            "Epoch 10/30\n",
            "71/71 - 0s - loss: 0.4100 - accuracy: 0.8018\n",
            "Epoch 11/30\n",
            "71/71 - 0s - loss: 0.4112 - accuracy: 0.7966\n",
            "Epoch 12/30\n",
            "71/71 - 0s - loss: 0.4070 - accuracy: 0.8046\n",
            "Epoch 13/30\n",
            "71/71 - 0s - loss: 0.4062 - accuracy: 0.8072\n",
            "Epoch 14/30\n",
            "71/71 - 0s - loss: 0.4068 - accuracy: 0.8063\n",
            "Epoch 15/30\n",
            "71/71 - 0s - loss: 0.4062 - accuracy: 0.8049\n",
            "Epoch 16/30\n",
            "71/71 - 0s - loss: 0.4065 - accuracy: 0.8023\n",
            "Epoch 17/30\n",
            "71/71 - 0s - loss: 0.4058 - accuracy: 0.8043\n",
            "Epoch 18/30\n",
            "71/71 - 0s - loss: 0.4071 - accuracy: 0.8057\n",
            "Epoch 19/30\n",
            "71/71 - 0s - loss: 0.4053 - accuracy: 0.8046\n",
            "Epoch 20/30\n",
            "71/71 - 0s - loss: 0.4054 - accuracy: 0.8009\n",
            "Epoch 21/30\n",
            "71/71 - 0s - loss: 0.4060 - accuracy: 0.8046\n",
            "Epoch 22/30\n",
            "71/71 - 0s - loss: 0.4043 - accuracy: 0.8049\n",
            "Epoch 23/30\n",
            "71/71 - 0s - loss: 0.4049 - accuracy: 0.8057\n",
            "Epoch 24/30\n",
            "71/71 - 0s - loss: 0.4044 - accuracy: 0.8049\n",
            "Epoch 25/30\n",
            "71/71 - 0s - loss: 0.4051 - accuracy: 0.8020\n",
            "Epoch 26/30\n",
            "71/71 - 0s - loss: 0.4042 - accuracy: 0.8035\n",
            "Epoch 27/30\n",
            "71/71 - 0s - loss: 0.4040 - accuracy: 0.8038\n",
            "Epoch 28/30\n",
            "71/71 - 0s - loss: 0.4054 - accuracy: 0.8083\n",
            "Epoch 29/30\n",
            "71/71 - 0s - loss: 0.4036 - accuracy: 0.8046\n",
            "Epoch 30/30\n",
            "71/71 - 0s - loss: 0.4036 - accuracy: 0.8029\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=30, nodes=64, total=   3.6s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=30, nodes=128 .........\n",
            "Epoch 1/30\n",
            "71/71 - 1s - loss: 0.5351 - accuracy: 0.7372\n",
            "Epoch 2/30\n",
            "71/71 - 0s - loss: 0.4457 - accuracy: 0.7742\n",
            "Epoch 3/30\n",
            "71/71 - 0s - loss: 0.4246 - accuracy: 0.7955\n",
            "Epoch 4/30\n",
            "71/71 - 0s - loss: 0.4252 - accuracy: 0.7958\n",
            "Epoch 5/30\n",
            "71/71 - 0s - loss: 0.4200 - accuracy: 0.7952\n",
            "Epoch 6/30\n",
            "71/71 - 0s - loss: 0.4195 - accuracy: 0.8012\n",
            "Epoch 7/30\n",
            "71/71 - 0s - loss: 0.4180 - accuracy: 0.8001\n",
            "Epoch 8/30\n",
            "71/71 - 0s - loss: 0.4180 - accuracy: 0.8015\n",
            "Epoch 9/30\n",
            "71/71 - 0s - loss: 0.4173 - accuracy: 0.8035\n",
            "Epoch 10/30\n",
            "71/71 - 0s - loss: 0.4219 - accuracy: 0.7949\n",
            "Epoch 11/30\n",
            "71/71 - 0s - loss: 0.4203 - accuracy: 0.7910\n",
            "Epoch 12/30\n",
            "71/71 - 0s - loss: 0.4168 - accuracy: 0.7986\n",
            "Epoch 13/30\n",
            "71/71 - 0s - loss: 0.4159 - accuracy: 0.8001\n",
            "Epoch 14/30\n",
            "71/71 - 0s - loss: 0.4180 - accuracy: 0.7978\n",
            "Epoch 15/30\n",
            "71/71 - 0s - loss: 0.4165 - accuracy: 0.7998\n",
            "Epoch 16/30\n",
            "71/71 - 0s - loss: 0.4164 - accuracy: 0.7958\n",
            "Epoch 17/30\n",
            "71/71 - 0s - loss: 0.4152 - accuracy: 0.7992\n",
            "Epoch 18/30\n",
            "71/71 - 0s - loss: 0.4159 - accuracy: 0.7995\n",
            "Epoch 19/30\n",
            "71/71 - 0s - loss: 0.4129 - accuracy: 0.8029\n",
            "Epoch 20/30\n",
            "71/71 - 0s - loss: 0.4136 - accuracy: 0.7961\n",
            "Epoch 21/30\n",
            "71/71 - 0s - loss: 0.4140 - accuracy: 0.8020\n",
            "Epoch 22/30\n",
            "71/71 - 0s - loss: 0.4142 - accuracy: 0.8001\n",
            "Epoch 23/30\n",
            "71/71 - 0s - loss: 0.4143 - accuracy: 0.7949\n",
            "Epoch 24/30\n",
            "71/71 - 0s - loss: 0.4125 - accuracy: 0.7984\n",
            "Epoch 25/30\n",
            "71/71 - 0s - loss: 0.4126 - accuracy: 0.8018\n",
            "Epoch 26/30\n",
            "71/71 - 0s - loss: 0.4140 - accuracy: 0.8023\n",
            "Epoch 27/30\n",
            "71/71 - 0s - loss: 0.4132 - accuracy: 0.8012\n",
            "Epoch 28/30\n",
            "71/71 - 0s - loss: 0.4115 - accuracy: 0.8020\n",
            "Epoch 29/30\n",
            "71/71 - 0s - loss: 0.4119 - accuracy: 0.8055\n",
            "Epoch 30/30\n",
            "71/71 - 0s - loss: 0.4109 - accuracy: 0.8026\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=30, nodes=128, total=   3.9s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=30, nodes=128 .........\n",
            "Epoch 1/30\n",
            "71/71 - 1s - loss: 0.5926 - accuracy: 0.6985\n",
            "Epoch 2/30\n",
            "71/71 - 0s - loss: 0.4776 - accuracy: 0.7580\n",
            "Epoch 3/30\n",
            "71/71 - 0s - loss: 0.4370 - accuracy: 0.7924\n",
            "Epoch 4/30\n",
            "71/71 - 0s - loss: 0.4290 - accuracy: 0.7924\n",
            "Epoch 5/30\n",
            "71/71 - 0s - loss: 0.4257 - accuracy: 0.7978\n",
            "Epoch 6/30\n",
            "71/71 - 0s - loss: 0.4230 - accuracy: 0.7995\n",
            "Epoch 7/30\n",
            "71/71 - 0s - loss: 0.4188 - accuracy: 0.8015\n",
            "Epoch 8/30\n",
            "71/71 - 0s - loss: 0.4172 - accuracy: 0.8072\n",
            "Epoch 9/30\n",
            "71/71 - 0s - loss: 0.4163 - accuracy: 0.8032\n",
            "Epoch 10/30\n",
            "71/71 - 0s - loss: 0.4169 - accuracy: 0.8020\n",
            "Epoch 11/30\n",
            "71/71 - 0s - loss: 0.4221 - accuracy: 0.7929\n",
            "Epoch 12/30\n",
            "71/71 - 0s - loss: 0.4168 - accuracy: 0.8020\n",
            "Epoch 13/30\n",
            "71/71 - 0s - loss: 0.4173 - accuracy: 0.8006\n",
            "Epoch 14/30\n",
            "71/71 - 0s - loss: 0.4174 - accuracy: 0.8003\n",
            "Epoch 15/30\n",
            "71/71 - 0s - loss: 0.4145 - accuracy: 0.8035\n",
            "Epoch 16/30\n",
            "71/71 - 0s - loss: 0.4160 - accuracy: 0.8055\n",
            "Epoch 17/30\n",
            "71/71 - 0s - loss: 0.4167 - accuracy: 0.8009\n",
            "Epoch 18/30\n",
            "71/71 - 0s - loss: 0.4145 - accuracy: 0.8052\n",
            "Epoch 19/30\n",
            "71/71 - 0s - loss: 0.4136 - accuracy: 0.8023\n",
            "Epoch 20/30\n",
            "71/71 - 0s - loss: 0.4136 - accuracy: 0.7992\n",
            "Epoch 21/30\n",
            "71/71 - 0s - loss: 0.4145 - accuracy: 0.8032\n",
            "Epoch 22/30\n",
            "71/71 - 0s - loss: 0.4127 - accuracy: 0.8038\n",
            "Epoch 23/30\n",
            "71/71 - 0s - loss: 0.4162 - accuracy: 0.8006\n",
            "Epoch 24/30\n",
            "71/71 - 0s - loss: 0.4138 - accuracy: 0.8046\n",
            "Epoch 25/30\n",
            "71/71 - 0s - loss: 0.4177 - accuracy: 0.8049\n",
            "Epoch 26/30\n",
            "71/71 - 0s - loss: 0.4121 - accuracy: 0.8043\n",
            "Epoch 27/30\n",
            "71/71 - 0s - loss: 0.4129 - accuracy: 0.8040\n",
            "Epoch 28/30\n",
            "71/71 - 0s - loss: 0.4134 - accuracy: 0.8006\n",
            "Epoch 29/30\n",
            "71/71 - 0s - loss: 0.4114 - accuracy: 0.8038\n",
            "Epoch 30/30\n",
            "71/71 - 0s - loss: 0.4113 - accuracy: 0.8069\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=30, nodes=128, total=   3.9s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=30, nodes=128 .........\n",
            "Epoch 1/30\n",
            "71/71 - 1s - loss: 0.5428 - accuracy: 0.7298\n",
            "Epoch 2/30\n",
            "71/71 - 0s - loss: 0.4462 - accuracy: 0.7827\n",
            "Epoch 3/30\n",
            "71/71 - 0s - loss: 0.4258 - accuracy: 0.7927\n",
            "Epoch 4/30\n",
            "71/71 - 0s - loss: 0.4229 - accuracy: 0.7941\n",
            "Epoch 5/30\n",
            "71/71 - 0s - loss: 0.4195 - accuracy: 0.7944\n",
            "Epoch 6/30\n",
            "71/71 - 0s - loss: 0.4135 - accuracy: 0.8023\n",
            "Epoch 7/30\n",
            "71/71 - 0s - loss: 0.4121 - accuracy: 0.8066\n",
            "Epoch 8/30\n",
            "71/71 - 0s - loss: 0.4109 - accuracy: 0.8018\n",
            "Epoch 9/30\n",
            "71/71 - 0s - loss: 0.4098 - accuracy: 0.8049\n",
            "Epoch 10/30\n",
            "71/71 - 0s - loss: 0.4107 - accuracy: 0.7998\n",
            "Epoch 11/30\n",
            "71/71 - 0s - loss: 0.4119 - accuracy: 0.7947\n",
            "Epoch 12/30\n",
            "71/71 - 0s - loss: 0.4084 - accuracy: 0.8035\n",
            "Epoch 13/30\n",
            "71/71 - 0s - loss: 0.4069 - accuracy: 0.8086\n",
            "Epoch 14/30\n",
            "71/71 - 0s - loss: 0.4094 - accuracy: 0.7992\n",
            "Epoch 15/30\n",
            "71/71 - 0s - loss: 0.4071 - accuracy: 0.8038\n",
            "Epoch 16/30\n",
            "71/71 - 0s - loss: 0.4083 - accuracy: 0.8012\n",
            "Epoch 17/30\n",
            "71/71 - 0s - loss: 0.4079 - accuracy: 0.8029\n",
            "Epoch 18/30\n",
            "71/71 - 0s - loss: 0.4082 - accuracy: 0.8060\n",
            "Epoch 19/30\n",
            "71/71 - 0s - loss: 0.4069 - accuracy: 0.8035\n",
            "Epoch 20/30\n",
            "71/71 - 0s - loss: 0.4065 - accuracy: 0.8003\n",
            "Epoch 21/30\n",
            "71/71 - 0s - loss: 0.4054 - accuracy: 0.8066\n",
            "Epoch 22/30\n",
            "71/71 - 0s - loss: 0.4044 - accuracy: 0.8029\n",
            "Epoch 23/30\n",
            "71/71 - 0s - loss: 0.4077 - accuracy: 0.8049\n",
            "Epoch 24/30\n",
            "71/71 - 0s - loss: 0.4048 - accuracy: 0.8052\n",
            "Epoch 25/30\n",
            "71/71 - 0s - loss: 0.4085 - accuracy: 0.8038\n",
            "Epoch 26/30\n",
            "71/71 - 0s - loss: 0.4061 - accuracy: 0.8038\n",
            "Epoch 27/30\n",
            "71/71 - 0s - loss: 0.4054 - accuracy: 0.8043\n",
            "Epoch 28/30\n",
            "71/71 - 0s - loss: 0.4051 - accuracy: 0.8057\n",
            "Epoch 29/30\n",
            "71/71 - 0s - loss: 0.4033 - accuracy: 0.8055\n",
            "Epoch 30/30\n",
            "71/71 - 0s - loss: 0.4050 - accuracy: 0.8052\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=30, nodes=128, total=   4.0s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=30, nodes=256 .........\n",
            "Epoch 1/30\n",
            "71/71 - 1s - loss: 0.5498 - accuracy: 0.7304\n",
            "Epoch 2/30\n",
            "71/71 - 0s - loss: 0.4387 - accuracy: 0.7850\n",
            "Epoch 3/30\n",
            "71/71 - 0s - loss: 0.4252 - accuracy: 0.7938\n",
            "Epoch 4/30\n",
            "71/71 - 0s - loss: 0.4243 - accuracy: 0.7947\n",
            "Epoch 5/30\n",
            "71/71 - 0s - loss: 0.4227 - accuracy: 0.7912\n",
            "Epoch 6/30\n",
            "71/71 - 0s - loss: 0.4211 - accuracy: 0.8012\n",
            "Epoch 7/30\n",
            "71/71 - 0s - loss: 0.4201 - accuracy: 0.7981\n",
            "Epoch 8/30\n",
            "71/71 - 0s - loss: 0.4219 - accuracy: 0.7981\n",
            "Epoch 9/30\n",
            "71/71 - 0s - loss: 0.4199 - accuracy: 0.8038\n",
            "Epoch 10/30\n",
            "71/71 - 0s - loss: 0.4186 - accuracy: 0.7975\n",
            "Epoch 11/30\n",
            "71/71 - 0s - loss: 0.4298 - accuracy: 0.7864\n",
            "Epoch 12/30\n",
            "71/71 - 0s - loss: 0.4163 - accuracy: 0.7992\n",
            "Epoch 13/30\n",
            "71/71 - 0s - loss: 0.4155 - accuracy: 0.7989\n",
            "Epoch 14/30\n",
            "71/71 - 0s - loss: 0.4207 - accuracy: 0.7984\n",
            "Epoch 15/30\n",
            "71/71 - 0s - loss: 0.4202 - accuracy: 0.8001\n",
            "Epoch 16/30\n",
            "71/71 - 0s - loss: 0.4165 - accuracy: 0.7952\n",
            "Epoch 17/30\n",
            "71/71 - 0s - loss: 0.4169 - accuracy: 0.7998\n",
            "Epoch 18/30\n",
            "71/71 - 0s - loss: 0.4180 - accuracy: 0.7966\n",
            "Epoch 19/30\n",
            "71/71 - 0s - loss: 0.4128 - accuracy: 0.8035\n",
            "Epoch 20/30\n",
            "71/71 - 0s - loss: 0.4143 - accuracy: 0.7947\n",
            "Epoch 21/30\n",
            "71/71 - 0s - loss: 0.4149 - accuracy: 0.7966\n",
            "Epoch 22/30\n",
            "71/71 - 0s - loss: 0.4153 - accuracy: 0.7969\n",
            "Epoch 23/30\n",
            "71/71 - 0s - loss: 0.4126 - accuracy: 0.7947\n",
            "Epoch 24/30\n",
            "71/71 - 0s - loss: 0.4120 - accuracy: 0.7989\n",
            "Epoch 25/30\n",
            "71/71 - 0s - loss: 0.4119 - accuracy: 0.8015\n",
            "Epoch 26/30\n",
            "71/71 - 0s - loss: 0.4144 - accuracy: 0.8012\n",
            "Epoch 27/30\n",
            "71/71 - 0s - loss: 0.4129 - accuracy: 0.8029\n",
            "Epoch 28/30\n",
            "71/71 - 0s - loss: 0.4107 - accuracy: 0.8009\n",
            "Epoch 29/30\n",
            "71/71 - 0s - loss: 0.4114 - accuracy: 0.8069\n",
            "Epoch 30/30\n",
            "71/71 - 0s - loss: 0.4104 - accuracy: 0.8003\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=30, nodes=256, total=   6.3s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=30, nodes=256 .........\n",
            "Epoch 1/30\n",
            "71/71 - 1s - loss: 0.5302 - accuracy: 0.7437\n",
            "Epoch 2/30\n",
            "71/71 - 0s - loss: 0.4376 - accuracy: 0.7878\n",
            "Epoch 3/30\n",
            "71/71 - 0s - loss: 0.4315 - accuracy: 0.7912\n",
            "Epoch 4/30\n",
            "71/71 - 0s - loss: 0.4242 - accuracy: 0.7984\n",
            "Epoch 5/30\n",
            "71/71 - 0s - loss: 0.4203 - accuracy: 0.7995\n",
            "Epoch 6/30\n",
            "71/71 - 0s - loss: 0.4213 - accuracy: 0.7961\n",
            "Epoch 7/30\n",
            "71/71 - 0s - loss: 0.4223 - accuracy: 0.7921\n",
            "Epoch 8/30\n",
            "71/71 - 0s - loss: 0.4215 - accuracy: 0.7975\n",
            "Epoch 9/30\n",
            "71/71 - 0s - loss: 0.4159 - accuracy: 0.8057\n",
            "Epoch 10/30\n",
            "71/71 - 0s - loss: 0.4182 - accuracy: 0.7998\n",
            "Epoch 11/30\n",
            "71/71 - 0s - loss: 0.4392 - accuracy: 0.7853\n",
            "Epoch 12/30\n",
            "71/71 - 0s - loss: 0.4176 - accuracy: 0.7972\n",
            "Epoch 13/30\n",
            "71/71 - 0s - loss: 0.4164 - accuracy: 0.8006\n",
            "Epoch 14/30\n",
            "71/71 - 0s - loss: 0.4172 - accuracy: 0.7995\n",
            "Epoch 15/30\n",
            "71/71 - 0s - loss: 0.4160 - accuracy: 0.8023\n",
            "Epoch 16/30\n",
            "71/71 - 0s - loss: 0.4164 - accuracy: 0.8015\n",
            "Epoch 17/30\n",
            "71/71 - 0s - loss: 0.4162 - accuracy: 0.7989\n",
            "Epoch 18/30\n",
            "71/71 - 0s - loss: 0.4175 - accuracy: 0.8029\n",
            "Epoch 19/30\n",
            "71/71 - 0s - loss: 0.4151 - accuracy: 0.8052\n",
            "Epoch 20/30\n",
            "71/71 - 0s - loss: 0.4145 - accuracy: 0.8006\n",
            "Epoch 21/30\n",
            "71/71 - 0s - loss: 0.4185 - accuracy: 0.7978\n",
            "Epoch 22/30\n",
            "71/71 - 0s - loss: 0.4126 - accuracy: 0.8049\n",
            "Epoch 23/30\n",
            "71/71 - 0s - loss: 0.4145 - accuracy: 0.8012\n",
            "Epoch 24/30\n",
            "71/71 - 0s - loss: 0.4146 - accuracy: 0.8049\n",
            "Epoch 25/30\n",
            "71/71 - 0s - loss: 0.4197 - accuracy: 0.8003\n",
            "Epoch 26/30\n",
            "71/71 - 0s - loss: 0.4122 - accuracy: 0.8043\n",
            "Epoch 27/30\n",
            "71/71 - 0s - loss: 0.4134 - accuracy: 0.8057\n",
            "Epoch 28/30\n",
            "71/71 - 0s - loss: 0.4137 - accuracy: 0.7995\n",
            "Epoch 29/30\n",
            "71/71 - 0s - loss: 0.4118 - accuracy: 0.8043\n",
            "Epoch 30/30\n",
            "71/71 - 0s - loss: 0.4118 - accuracy: 0.8040\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=30, nodes=256, total=   6.4s\n",
            "[CV] activation=sigmoid, batch_size=50, epochs=30, nodes=256 .........\n",
            "Epoch 1/30\n",
            "71/71 - 1s - loss: 0.5088 - accuracy: 0.7554\n",
            "Epoch 2/30\n",
            "71/71 - 0s - loss: 0.4356 - accuracy: 0.7873\n",
            "Epoch 3/30\n",
            "71/71 - 0s - loss: 0.4266 - accuracy: 0.7910\n",
            "Epoch 4/30\n",
            "71/71 - 0s - loss: 0.4245 - accuracy: 0.7929\n",
            "Epoch 5/30\n",
            "71/71 - 0s - loss: 0.4160 - accuracy: 0.7935\n",
            "Epoch 6/30\n",
            "71/71 - 0s - loss: 0.4158 - accuracy: 0.8026\n",
            "Epoch 7/30\n",
            "71/71 - 0s - loss: 0.4108 - accuracy: 0.8015\n",
            "Epoch 8/30\n",
            "71/71 - 0s - loss: 0.4119 - accuracy: 0.8032\n",
            "Epoch 9/30\n",
            "71/71 - 0s - loss: 0.4092 - accuracy: 0.8038\n",
            "Epoch 10/30\n",
            "71/71 - 0s - loss: 0.4143 - accuracy: 0.7995\n",
            "Epoch 11/30\n",
            "71/71 - 0s - loss: 0.4193 - accuracy: 0.7961\n",
            "Epoch 12/30\n",
            "71/71 - 0s - loss: 0.4115 - accuracy: 0.8032\n",
            "Epoch 13/30\n",
            "71/71 - 0s - loss: 0.4076 - accuracy: 0.8055\n",
            "Epoch 14/30\n",
            "71/71 - 0s - loss: 0.4095 - accuracy: 0.8043\n",
            "Epoch 15/30\n",
            "71/71 - 0s - loss: 0.4094 - accuracy: 0.8023\n",
            "Epoch 16/30\n",
            "71/71 - 0s - loss: 0.4101 - accuracy: 0.7998\n",
            "Epoch 17/30\n",
            "71/71 - 0s - loss: 0.4081 - accuracy: 0.8020\n",
            "Epoch 18/30\n",
            "71/71 - 0s - loss: 0.4073 - accuracy: 0.8075\n",
            "Epoch 19/30\n",
            "71/71 - 0s - loss: 0.4084 - accuracy: 0.8026\n",
            "Epoch 20/30\n",
            "71/71 - 0s - loss: 0.4059 - accuracy: 0.8012\n",
            "Epoch 21/30\n",
            "71/71 - 0s - loss: 0.4056 - accuracy: 0.8049\n",
            "Epoch 22/30\n",
            "71/71 - 0s - loss: 0.4046 - accuracy: 0.8018\n",
            "Epoch 23/30\n",
            "71/71 - 0s - loss: 0.4102 - accuracy: 0.8055\n",
            "Epoch 24/30\n",
            "71/71 - 0s - loss: 0.4046 - accuracy: 0.8063\n",
            "Epoch 25/30\n",
            "71/71 - 0s - loss: 0.4094 - accuracy: 0.8029\n",
            "Epoch 26/30\n",
            "71/71 - 0s - loss: 0.4059 - accuracy: 0.8026\n",
            "Epoch 27/30\n",
            "71/71 - 0s - loss: 0.4060 - accuracy: 0.8018\n",
            "Epoch 28/30\n",
            "71/71 - 0s - loss: 0.4050 - accuracy: 0.8055\n",
            "Epoch 29/30\n",
            "71/71 - 0s - loss: 0.4032 - accuracy: 0.8049\n",
            "Epoch 30/30\n",
            "71/71 - 0s - loss: 0.4052 - accuracy: 0.8023\n",
            "[CV]  activation=sigmoid, batch_size=50, epochs=30, nodes=256, total=   6.7s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=10, nodes=64 .........\n",
            "Epoch 1/10\n",
            "36/36 - 1s - loss: 0.5597 - accuracy: 0.7338\n",
            "Epoch 2/10\n",
            "36/36 - 0s - loss: 0.5095 - accuracy: 0.7378\n",
            "Epoch 3/10\n",
            "36/36 - 0s - loss: 0.4599 - accuracy: 0.7742\n",
            "Epoch 4/10\n",
            "36/36 - 0s - loss: 0.4376 - accuracy: 0.7833\n",
            "Epoch 5/10\n",
            "36/36 - 0s - loss: 0.4275 - accuracy: 0.7944\n",
            "Epoch 6/10\n",
            "36/36 - 0s - loss: 0.4257 - accuracy: 0.7938\n",
            "Epoch 7/10\n",
            "36/36 - 0s - loss: 0.4221 - accuracy: 0.7938\n",
            "Epoch 8/10\n",
            "36/36 - 0s - loss: 0.4202 - accuracy: 0.7947\n",
            "Epoch 9/10\n",
            "36/36 - 0s - loss: 0.4191 - accuracy: 0.7989\n",
            "Epoch 10/10\n",
            "36/36 - 0s - loss: 0.4192 - accuracy: 0.7964\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=10, nodes=64, total=   1.3s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=10, nodes=64 .........\n",
            "Epoch 1/10\n",
            "36/36 - 1s - loss: 0.5992 - accuracy: 0.6792\n",
            "Epoch 2/10\n",
            "36/36 - 0s - loss: 0.5358 - accuracy: 0.7381\n",
            "Epoch 3/10\n",
            "36/36 - 0s - loss: 0.5019 - accuracy: 0.7395\n",
            "Epoch 4/10\n",
            "36/36 - 0s - loss: 0.4687 - accuracy: 0.7574\n",
            "Epoch 5/10\n",
            "36/36 - 0s - loss: 0.4471 - accuracy: 0.7836\n",
            "Epoch 6/10\n",
            "36/36 - 0s - loss: 0.4365 - accuracy: 0.7912\n",
            "Epoch 7/10\n",
            "36/36 - 0s - loss: 0.4297 - accuracy: 0.7927\n",
            "Epoch 8/10\n",
            "36/36 - 0s - loss: 0.4260 - accuracy: 0.7995\n",
            "Epoch 9/10\n",
            "36/36 - 0s - loss: 0.4266 - accuracy: 0.7938\n",
            "Epoch 10/10\n",
            "36/36 - 0s - loss: 0.4231 - accuracy: 0.7964\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=10, nodes=64, total=   1.3s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=10, nodes=64 .........\n",
            "Epoch 1/10\n",
            "36/36 - 1s - loss: 0.6696 - accuracy: 0.5995\n",
            "Epoch 2/10\n",
            "36/36 - 0s - loss: 0.5414 - accuracy: 0.7307\n",
            "Epoch 3/10\n",
            "36/36 - 0s - loss: 0.5095 - accuracy: 0.7321\n",
            "Epoch 4/10\n",
            "36/36 - 0s - loss: 0.4805 - accuracy: 0.7463\n",
            "Epoch 5/10\n",
            "36/36 - 0s - loss: 0.4557 - accuracy: 0.7819\n",
            "Epoch 6/10\n",
            "36/36 - 0s - loss: 0.4404 - accuracy: 0.7895\n",
            "Epoch 7/10\n",
            "36/36 - 0s - loss: 0.4328 - accuracy: 0.7935\n",
            "Epoch 8/10\n",
            "36/36 - 0s - loss: 0.4269 - accuracy: 0.7958\n",
            "Epoch 9/10\n",
            "36/36 - 0s - loss: 0.4231 - accuracy: 0.7975\n",
            "Epoch 10/10\n",
            "36/36 - 0s - loss: 0.4201 - accuracy: 0.7984\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=10, nodes=64, total=   1.3s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=10, nodes=128 ........\n",
            "Epoch 1/10\n",
            "36/36 - 1s - loss: 0.6081 - accuracy: 0.6849\n",
            "Epoch 2/10\n",
            "36/36 - 0s - loss: 0.5169 - accuracy: 0.7338\n",
            "Epoch 3/10\n",
            "36/36 - 0s - loss: 0.4707 - accuracy: 0.7659\n",
            "Epoch 4/10\n",
            "36/36 - 0s - loss: 0.4436 - accuracy: 0.7799\n",
            "Epoch 5/10\n",
            "36/36 - 0s - loss: 0.4310 - accuracy: 0.7898\n",
            "Epoch 6/10\n",
            "36/36 - 0s - loss: 0.4281 - accuracy: 0.7915\n",
            "Epoch 7/10\n",
            "36/36 - 0s - loss: 0.4242 - accuracy: 0.7935\n",
            "Epoch 8/10\n",
            "36/36 - 0s - loss: 0.4214 - accuracy: 0.7958\n",
            "Epoch 9/10\n",
            "36/36 - 0s - loss: 0.4202 - accuracy: 0.7975\n",
            "Epoch 10/10\n",
            "36/36 - 0s - loss: 0.4216 - accuracy: 0.7995\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=10, nodes=128, total=   1.4s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=10, nodes=128 ........\n",
            "Epoch 1/10\n",
            "36/36 - 1s - loss: 0.5934 - accuracy: 0.7096\n",
            "Epoch 2/10\n",
            "36/36 - 0s - loss: 0.5170 - accuracy: 0.7383\n",
            "Epoch 3/10\n",
            "36/36 - 0s - loss: 0.4650 - accuracy: 0.7696\n",
            "Epoch 4/10\n",
            "36/36 - 0s - loss: 0.4412 - accuracy: 0.7890\n",
            "Epoch 5/10\n",
            "36/36 - 0s - loss: 0.4311 - accuracy: 0.7912\n",
            "Epoch 6/10\n",
            "36/36 - 0s - loss: 0.4297 - accuracy: 0.7941\n",
            "Epoch 7/10\n",
            "36/36 - 0s - loss: 0.4235 - accuracy: 0.7986\n",
            "Epoch 8/10\n",
            "36/36 - 0s - loss: 0.4207 - accuracy: 0.8026\n",
            "Epoch 9/10\n",
            "36/36 - 0s - loss: 0.4213 - accuracy: 0.7978\n",
            "Epoch 10/10\n",
            "36/36 - 0s - loss: 0.4203 - accuracy: 0.8023\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=10, nodes=128, total=   1.4s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=10, nodes=128 ........\n",
            "Epoch 1/10\n",
            "36/36 - 1s - loss: 0.5938 - accuracy: 0.6982\n",
            "Epoch 2/10\n",
            "36/36 - 0s - loss: 0.5138 - accuracy: 0.7349\n",
            "Epoch 3/10\n",
            "36/36 - 0s - loss: 0.4599 - accuracy: 0.7719\n",
            "Epoch 4/10\n",
            "36/36 - 0s - loss: 0.4366 - accuracy: 0.7861\n",
            "Epoch 5/10\n",
            "36/36 - 0s - loss: 0.4283 - accuracy: 0.7961\n",
            "Epoch 6/10\n",
            "36/36 - 0s - loss: 0.4231 - accuracy: 0.8006\n",
            "Epoch 7/10\n",
            "36/36 - 0s - loss: 0.4213 - accuracy: 0.7998\n",
            "Epoch 8/10\n",
            "36/36 - 0s - loss: 0.4182 - accuracy: 0.7958\n",
            "Epoch 9/10\n",
            "36/36 - 0s - loss: 0.4162 - accuracy: 0.7998\n",
            "Epoch 10/10\n",
            "36/36 - 0s - loss: 0.4130 - accuracy: 0.8020\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=10, nodes=128, total=   1.4s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=10, nodes=256 ........\n",
            "Epoch 1/10\n",
            "36/36 - 1s - loss: 0.5768 - accuracy: 0.7184\n",
            "Epoch 2/10\n",
            "36/36 - 0s - loss: 0.4829 - accuracy: 0.7591\n",
            "Epoch 3/10\n",
            "36/36 - 0s - loss: 0.4356 - accuracy: 0.7884\n",
            "Epoch 4/10\n",
            "36/36 - 0s - loss: 0.4350 - accuracy: 0.7901\n",
            "Epoch 5/10\n",
            "36/36 - 0s - loss: 0.4235 - accuracy: 0.7941\n",
            "Epoch 6/10\n",
            "36/36 - 0s - loss: 0.4203 - accuracy: 0.7984\n",
            "Epoch 7/10\n",
            "36/36 - 0s - loss: 0.4206 - accuracy: 0.7958\n",
            "Epoch 8/10\n",
            "36/36 - 0s - loss: 0.4195 - accuracy: 0.7964\n",
            "Epoch 9/10\n",
            "36/36 - 0s - loss: 0.4178 - accuracy: 0.7992\n",
            "Epoch 10/10\n",
            "36/36 - 0s - loss: 0.4214 - accuracy: 0.7952\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=10, nodes=256, total=   2.1s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=10, nodes=256 ........\n",
            "Epoch 1/10\n",
            "36/36 - 1s - loss: 0.5854 - accuracy: 0.7233\n",
            "Epoch 2/10\n",
            "36/36 - 0s - loss: 0.4864 - accuracy: 0.7528\n",
            "Epoch 3/10\n",
            "36/36 - 0s - loss: 0.4416 - accuracy: 0.7887\n",
            "Epoch 4/10\n",
            "36/36 - 0s - loss: 0.4346 - accuracy: 0.7910\n",
            "Epoch 5/10\n",
            "36/36 - 0s - loss: 0.4290 - accuracy: 0.7944\n",
            "Epoch 6/10\n",
            "36/36 - 0s - loss: 0.4286 - accuracy: 0.7910\n",
            "Epoch 7/10\n",
            "36/36 - 0s - loss: 0.4211 - accuracy: 0.8029\n",
            "Epoch 8/10\n",
            "36/36 - 0s - loss: 0.4186 - accuracy: 0.8063\n",
            "Epoch 9/10\n",
            "36/36 - 0s - loss: 0.4202 - accuracy: 0.8003\n",
            "Epoch 10/10\n",
            "36/36 - 0s - loss: 0.4180 - accuracy: 0.8001\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=10, nodes=256, total=   2.2s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=10, nodes=256 ........\n",
            "Epoch 1/10\n",
            "36/36 - 1s - loss: 0.5761 - accuracy: 0.7176\n",
            "Epoch 2/10\n",
            "36/36 - 0s - loss: 0.4740 - accuracy: 0.7597\n",
            "Epoch 3/10\n",
            "36/36 - 0s - loss: 0.4328 - accuracy: 0.7912\n",
            "Epoch 4/10\n",
            "36/36 - 0s - loss: 0.4259 - accuracy: 0.7975\n",
            "Epoch 5/10\n",
            "36/36 - 0s - loss: 0.4240 - accuracy: 0.7927\n",
            "Epoch 6/10\n",
            "36/36 - 0s - loss: 0.4165 - accuracy: 0.8029\n",
            "Epoch 7/10\n",
            "36/36 - 0s - loss: 0.4182 - accuracy: 0.8055\n",
            "Epoch 8/10\n",
            "36/36 - 0s - loss: 0.4155 - accuracy: 0.8029\n",
            "Epoch 9/10\n",
            "36/36 - 0s - loss: 0.4140 - accuracy: 0.8035\n",
            "Epoch 10/10\n",
            "36/36 - 0s - loss: 0.4150 - accuracy: 0.7972\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=10, nodes=256, total=   2.1s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=20, nodes=64 .........\n",
            "Epoch 1/20\n",
            "36/36 - 1s - loss: 0.5696 - accuracy: 0.7338\n",
            "Epoch 2/20\n",
            "36/36 - 0s - loss: 0.5294 - accuracy: 0.7338\n",
            "Epoch 3/20\n",
            "36/36 - 0s - loss: 0.4785 - accuracy: 0.7608\n",
            "Epoch 4/20\n",
            "36/36 - 0s - loss: 0.4462 - accuracy: 0.7819\n",
            "Epoch 5/20\n",
            "36/36 - 0s - loss: 0.4317 - accuracy: 0.7912\n",
            "Epoch 6/20\n",
            "36/36 - 0s - loss: 0.4283 - accuracy: 0.7918\n",
            "Epoch 7/20\n",
            "36/36 - 0s - loss: 0.4239 - accuracy: 0.7947\n",
            "Epoch 8/20\n",
            "36/36 - 0s - loss: 0.4217 - accuracy: 0.7958\n",
            "Epoch 9/20\n",
            "36/36 - 0s - loss: 0.4204 - accuracy: 0.7989\n",
            "Epoch 10/20\n",
            "36/36 - 0s - loss: 0.4198 - accuracy: 0.7958\n",
            "Epoch 11/20\n",
            "36/36 - 0s - loss: 0.4193 - accuracy: 0.8001\n",
            "Epoch 12/20\n",
            "36/36 - 0s - loss: 0.4176 - accuracy: 0.7975\n",
            "Epoch 13/20\n",
            "36/36 - 0s - loss: 0.4166 - accuracy: 0.7992\n",
            "Epoch 14/20\n",
            "36/36 - 0s - loss: 0.4173 - accuracy: 0.8015\n",
            "Epoch 15/20\n",
            "36/36 - 0s - loss: 0.4154 - accuracy: 0.8023\n",
            "Epoch 16/20\n",
            "36/36 - 0s - loss: 0.4151 - accuracy: 0.8060\n",
            "Epoch 17/20\n",
            "36/36 - 0s - loss: 0.4147 - accuracy: 0.8049\n",
            "Epoch 18/20\n",
            "36/36 - 0s - loss: 0.4149 - accuracy: 0.8018\n",
            "Epoch 19/20\n",
            "36/36 - 0s - loss: 0.4138 - accuracy: 0.8052\n",
            "Epoch 20/20\n",
            "36/36 - 0s - loss: 0.4139 - accuracy: 0.8032\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=20, nodes=64, total=   2.3s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=20, nodes=64 .........\n",
            "Epoch 1/20\n",
            "36/36 - 1s - loss: 0.6011 - accuracy: 0.6812\n",
            "Epoch 2/20\n",
            "36/36 - 0s - loss: 0.5387 - accuracy: 0.7381\n",
            "Epoch 3/20\n",
            "36/36 - 0s - loss: 0.5061 - accuracy: 0.7386\n",
            "Epoch 4/20\n",
            "36/36 - 0s - loss: 0.4720 - accuracy: 0.7514\n",
            "Epoch 5/20\n",
            "36/36 - 0s - loss: 0.4484 - accuracy: 0.7838\n",
            "Epoch 6/20\n",
            "36/36 - 0s - loss: 0.4368 - accuracy: 0.7941\n",
            "Epoch 7/20\n",
            "36/36 - 0s - loss: 0.4296 - accuracy: 0.7947\n",
            "Epoch 8/20\n",
            "36/36 - 0s - loss: 0.4259 - accuracy: 0.8003\n",
            "Epoch 9/20\n",
            "36/36 - 0s - loss: 0.4265 - accuracy: 0.7949\n",
            "Epoch 10/20\n",
            "36/36 - 0s - loss: 0.4232 - accuracy: 0.7978\n",
            "Epoch 11/20\n",
            "36/36 - 0s - loss: 0.4213 - accuracy: 0.8023\n",
            "Epoch 12/20\n",
            "36/36 - 0s - loss: 0.4202 - accuracy: 0.8035\n",
            "Epoch 13/20\n",
            "36/36 - 0s - loss: 0.4191 - accuracy: 0.8012\n",
            "Epoch 14/20\n",
            "36/36 - 0s - loss: 0.4179 - accuracy: 0.8038\n",
            "Epoch 15/20\n",
            "36/36 - 0s - loss: 0.4175 - accuracy: 0.8040\n",
            "Epoch 16/20\n",
            "36/36 - 0s - loss: 0.4166 - accuracy: 0.8049\n",
            "Epoch 17/20\n",
            "36/36 - 0s - loss: 0.4164 - accuracy: 0.8069\n",
            "Epoch 18/20\n",
            "36/36 - 0s - loss: 0.4152 - accuracy: 0.8049\n",
            "Epoch 19/20\n",
            "36/36 - 0s - loss: 0.4151 - accuracy: 0.8069\n",
            "Epoch 20/20\n",
            "36/36 - 0s - loss: 0.4149 - accuracy: 0.8035\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=20, nodes=64, total=   1.9s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=20, nodes=64 .........\n",
            "Epoch 1/20\n",
            "36/36 - 1s - loss: 0.6273 - accuracy: 0.6465\n",
            "Epoch 2/20\n",
            "36/36 - 0s - loss: 0.5379 - accuracy: 0.7307\n",
            "Epoch 3/20\n",
            "36/36 - 0s - loss: 0.5042 - accuracy: 0.7341\n",
            "Epoch 4/20\n",
            "36/36 - 0s - loss: 0.4735 - accuracy: 0.7497\n",
            "Epoch 5/20\n",
            "36/36 - 0s - loss: 0.4498 - accuracy: 0.7861\n",
            "Epoch 6/20\n",
            "36/36 - 0s - loss: 0.4369 - accuracy: 0.7904\n",
            "Epoch 7/20\n",
            "36/36 - 0s - loss: 0.4315 - accuracy: 0.7924\n",
            "Epoch 8/20\n",
            "36/36 - 0s - loss: 0.4262 - accuracy: 0.7984\n",
            "Epoch 9/20\n",
            "36/36 - 0s - loss: 0.4227 - accuracy: 0.8018\n",
            "Epoch 10/20\n",
            "36/36 - 0s - loss: 0.4196 - accuracy: 0.8012\n",
            "Epoch 11/20\n",
            "36/36 - 0s - loss: 0.4185 - accuracy: 0.8003\n",
            "Epoch 12/20\n",
            "36/36 - 0s - loss: 0.4154 - accuracy: 0.8023\n",
            "Epoch 13/20\n",
            "36/36 - 0s - loss: 0.4138 - accuracy: 0.8029\n",
            "Epoch 14/20\n",
            "36/36 - 0s - loss: 0.4138 - accuracy: 0.8035\n",
            "Epoch 15/20\n",
            "36/36 - 0s - loss: 0.4135 - accuracy: 0.8001\n",
            "Epoch 16/20\n",
            "36/36 - 0s - loss: 0.4100 - accuracy: 0.8023\n",
            "Epoch 17/20\n",
            "36/36 - 0s - loss: 0.4097 - accuracy: 0.8032\n",
            "Epoch 18/20\n",
            "36/36 - 0s - loss: 0.4097 - accuracy: 0.8012\n",
            "Epoch 19/20\n",
            "36/36 - 0s - loss: 0.4087 - accuracy: 0.8049\n",
            "Epoch 20/20\n",
            "36/36 - 0s - loss: 0.4088 - accuracy: 0.8049\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=20, nodes=64, total=   2.0s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=20, nodes=128 ........\n",
            "Epoch 1/20\n",
            "36/36 - 1s - loss: 0.5601 - accuracy: 0.7338\n",
            "Epoch 2/20\n",
            "36/36 - 0s - loss: 0.4947 - accuracy: 0.7486\n",
            "Epoch 3/20\n",
            "36/36 - 0s - loss: 0.4409 - accuracy: 0.7847\n",
            "Epoch 4/20\n",
            "36/36 - 0s - loss: 0.4313 - accuracy: 0.7912\n",
            "Epoch 5/20\n",
            "36/36 - 0s - loss: 0.4235 - accuracy: 0.7949\n",
            "Epoch 6/20\n",
            "36/36 - 0s - loss: 0.4222 - accuracy: 0.7984\n",
            "Epoch 7/20\n",
            "36/36 - 0s - loss: 0.4193 - accuracy: 0.7978\n",
            "Epoch 8/20\n",
            "36/36 - 0s - loss: 0.4182 - accuracy: 0.7941\n",
            "Epoch 9/20\n",
            "36/36 - 0s - loss: 0.4168 - accuracy: 0.7998\n",
            "Epoch 10/20\n",
            "36/36 - 0s - loss: 0.4205 - accuracy: 0.7938\n",
            "Epoch 11/20\n",
            "36/36 - 0s - loss: 0.4171 - accuracy: 0.7966\n",
            "Epoch 12/20\n",
            "36/36 - 0s - loss: 0.4147 - accuracy: 0.8035\n",
            "Epoch 13/20\n",
            "36/36 - 0s - loss: 0.4155 - accuracy: 0.8029\n",
            "Epoch 14/20\n",
            "36/36 - 0s - loss: 0.4182 - accuracy: 0.7947\n",
            "Epoch 15/20\n",
            "36/36 - 0s - loss: 0.4147 - accuracy: 0.7998\n",
            "Epoch 16/20\n",
            "36/36 - 0s - loss: 0.4143 - accuracy: 0.8020\n",
            "Epoch 17/20\n",
            "36/36 - 0s - loss: 0.4162 - accuracy: 0.7984\n",
            "Epoch 18/20\n",
            "36/36 - 0s - loss: 0.4166 - accuracy: 0.7949\n",
            "Epoch 19/20\n",
            "36/36 - 0s - loss: 0.4131 - accuracy: 0.8038\n",
            "Epoch 20/20\n",
            "36/36 - 0s - loss: 0.4146 - accuracy: 0.8035\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=20, nodes=128, total=   2.1s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=20, nodes=128 ........\n",
            "Epoch 1/20\n",
            "36/36 - 1s - loss: 0.5930 - accuracy: 0.6997\n",
            "Epoch 2/20\n",
            "36/36 - 0s - loss: 0.5117 - accuracy: 0.7389\n",
            "Epoch 3/20\n",
            "36/36 - 0s - loss: 0.4634 - accuracy: 0.7688\n",
            "Epoch 4/20\n",
            "36/36 - 0s - loss: 0.4402 - accuracy: 0.7904\n",
            "Epoch 5/20\n",
            "36/36 - 0s - loss: 0.4302 - accuracy: 0.7929\n",
            "Epoch 6/20\n",
            "36/36 - 0s - loss: 0.4286 - accuracy: 0.7947\n",
            "Epoch 7/20\n",
            "36/36 - 0s - loss: 0.4226 - accuracy: 0.8012\n",
            "Epoch 8/20\n",
            "36/36 - 0s - loss: 0.4199 - accuracy: 0.8046\n",
            "Epoch 9/20\n",
            "36/36 - 0s - loss: 0.4205 - accuracy: 0.7992\n",
            "Epoch 10/20\n",
            "36/36 - 0s - loss: 0.4198 - accuracy: 0.8023\n",
            "Epoch 11/20\n",
            "36/36 - 0s - loss: 0.4203 - accuracy: 0.8029\n",
            "Epoch 12/20\n",
            "36/36 - 0s - loss: 0.4170 - accuracy: 0.8001\n",
            "Epoch 13/20\n",
            "36/36 - 0s - loss: 0.4166 - accuracy: 0.8032\n",
            "Epoch 14/20\n",
            "36/36 - 0s - loss: 0.4155 - accuracy: 0.8035\n",
            "Epoch 15/20\n",
            "36/36 - 0s - loss: 0.4160 - accuracy: 0.8001\n",
            "Epoch 16/20\n",
            "36/36 - 0s - loss: 0.4152 - accuracy: 0.8043\n",
            "Epoch 17/20\n",
            "36/36 - 0s - loss: 0.4171 - accuracy: 0.8026\n",
            "Epoch 18/20\n",
            "36/36 - 0s - loss: 0.4147 - accuracy: 0.7986\n",
            "Epoch 19/20\n",
            "36/36 - 0s - loss: 0.4134 - accuracy: 0.8049\n",
            "Epoch 20/20\n",
            "36/36 - 0s - loss: 0.4136 - accuracy: 0.8040\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=20, nodes=128, total=   2.1s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=20, nodes=128 ........\n",
            "Epoch 1/20\n",
            "36/36 - 1s - loss: 0.5645 - accuracy: 0.7307\n",
            "Epoch 2/20\n",
            "36/36 - 0s - loss: 0.4912 - accuracy: 0.7446\n",
            "Epoch 3/20\n",
            "36/36 - 0s - loss: 0.4393 - accuracy: 0.7912\n",
            "Epoch 4/20\n",
            "36/36 - 0s - loss: 0.4273 - accuracy: 0.7944\n",
            "Epoch 5/20\n",
            "36/36 - 0s - loss: 0.4218 - accuracy: 0.7966\n",
            "Epoch 6/20\n",
            "36/36 - 0s - loss: 0.4182 - accuracy: 0.8018\n",
            "Epoch 7/20\n",
            "36/36 - 0s - loss: 0.4160 - accuracy: 0.8023\n",
            "Epoch 8/20\n",
            "36/36 - 0s - loss: 0.4137 - accuracy: 0.8003\n",
            "Epoch 9/20\n",
            "36/36 - 0s - loss: 0.4144 - accuracy: 0.8026\n",
            "Epoch 10/20\n",
            "36/36 - 0s - loss: 0.4103 - accuracy: 0.8049\n",
            "Epoch 11/20\n",
            "36/36 - 0s - loss: 0.4137 - accuracy: 0.7981\n",
            "Epoch 12/20\n",
            "36/36 - 0s - loss: 0.4080 - accuracy: 0.8052\n",
            "Epoch 13/20\n",
            "36/36 - 0s - loss: 0.4072 - accuracy: 0.8083\n",
            "Epoch 14/20\n",
            "36/36 - 0s - loss: 0.4076 - accuracy: 0.8086\n",
            "Epoch 15/20\n",
            "36/36 - 0s - loss: 0.4071 - accuracy: 0.8046\n",
            "Epoch 16/20\n",
            "36/36 - 0s - loss: 0.4078 - accuracy: 0.8046\n",
            "Epoch 17/20\n",
            "36/36 - 0s - loss: 0.4065 - accuracy: 0.8035\n",
            "Epoch 18/20\n",
            "36/36 - 0s - loss: 0.4096 - accuracy: 0.8023\n",
            "Epoch 19/20\n",
            "36/36 - 0s - loss: 0.4060 - accuracy: 0.8057\n",
            "Epoch 20/20\n",
            "36/36 - 0s - loss: 0.4072 - accuracy: 0.8001\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=20, nodes=128, total=   2.1s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=20, nodes=256 ........\n",
            "Epoch 1/20\n",
            "36/36 - 1s - loss: 0.5806 - accuracy: 0.7184\n",
            "Epoch 2/20\n",
            "36/36 - 0s - loss: 0.4859 - accuracy: 0.7582\n",
            "Epoch 3/20\n",
            "36/36 - 0s - loss: 0.4348 - accuracy: 0.7887\n",
            "Epoch 4/20\n",
            "36/36 - 0s - loss: 0.4340 - accuracy: 0.7898\n",
            "Epoch 5/20\n",
            "36/36 - 0s - loss: 0.4228 - accuracy: 0.7921\n",
            "Epoch 6/20\n",
            "36/36 - 0s - loss: 0.4199 - accuracy: 0.8006\n",
            "Epoch 7/20\n",
            "36/36 - 0s - loss: 0.4202 - accuracy: 0.7969\n",
            "Epoch 8/20\n",
            "36/36 - 0s - loss: 0.4191 - accuracy: 0.7949\n",
            "Epoch 9/20\n",
            "36/36 - 0s - loss: 0.4176 - accuracy: 0.7986\n",
            "Epoch 10/20\n",
            "36/36 - 0s - loss: 0.4211 - accuracy: 0.7958\n",
            "Epoch 11/20\n",
            "36/36 - 0s - loss: 0.4227 - accuracy: 0.7895\n",
            "Epoch 12/20\n",
            "36/36 - 0s - loss: 0.4164 - accuracy: 0.8020\n",
            "Epoch 13/20\n",
            "36/36 - 0s - loss: 0.4184 - accuracy: 0.7947\n",
            "Epoch 14/20\n",
            "36/36 - 0s - loss: 0.4218 - accuracy: 0.7924\n",
            "Epoch 15/20\n",
            "36/36 - 0s - loss: 0.4154 - accuracy: 0.8015\n",
            "Epoch 16/20\n",
            "36/36 - 0s - loss: 0.4164 - accuracy: 0.7944\n",
            "Epoch 17/20\n",
            "36/36 - 0s - loss: 0.4188 - accuracy: 0.7966\n",
            "Epoch 18/20\n",
            "36/36 - 0s - loss: 0.4171 - accuracy: 0.8006\n",
            "Epoch 19/20\n",
            "36/36 - 0s - loss: 0.4136 - accuracy: 0.8038\n",
            "Epoch 20/20\n",
            "36/36 - 0s - loss: 0.4142 - accuracy: 0.7981\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=20, nodes=256, total=   3.4s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=20, nodes=256 ........\n",
            "Epoch 1/20\n",
            "36/36 - 1s - loss: 0.5596 - accuracy: 0.7241\n",
            "Epoch 2/20\n",
            "36/36 - 0s - loss: 0.4753 - accuracy: 0.7662\n",
            "Epoch 3/20\n",
            "36/36 - 0s - loss: 0.4348 - accuracy: 0.7915\n",
            "Epoch 4/20\n",
            "36/36 - 0s - loss: 0.4299 - accuracy: 0.7907\n",
            "Epoch 5/20\n",
            "36/36 - 0s - loss: 0.4312 - accuracy: 0.7935\n",
            "Epoch 6/20\n",
            "36/36 - 0s - loss: 0.4280 - accuracy: 0.7915\n",
            "Epoch 7/20\n",
            "36/36 - 0s - loss: 0.4200 - accuracy: 0.8032\n",
            "Epoch 8/20\n",
            "36/36 - 0s - loss: 0.4174 - accuracy: 0.8057\n",
            "Epoch 9/20\n",
            "36/36 - 0s - loss: 0.4187 - accuracy: 0.8009\n",
            "Epoch 10/20\n",
            "36/36 - 0s - loss: 0.4180 - accuracy: 0.7984\n",
            "Epoch 11/20\n",
            "36/36 - 0s - loss: 0.4238 - accuracy: 0.7941\n",
            "Epoch 12/20\n",
            "36/36 - 0s - loss: 0.4191 - accuracy: 0.8001\n",
            "Epoch 13/20\n",
            "36/36 - 0s - loss: 0.4208 - accuracy: 0.7941\n",
            "Epoch 14/20\n",
            "36/36 - 0s - loss: 0.4231 - accuracy: 0.7955\n",
            "Epoch 15/20\n",
            "36/36 - 0s - loss: 0.4156 - accuracy: 0.8018\n",
            "Epoch 16/20\n",
            "36/36 - 0s - loss: 0.4155 - accuracy: 0.8020\n",
            "Epoch 17/20\n",
            "36/36 - 0s - loss: 0.4201 - accuracy: 0.7992\n",
            "Epoch 18/20\n",
            "36/36 - 0s - loss: 0.4161 - accuracy: 0.8023\n",
            "Epoch 19/20\n",
            "36/36 - 0s - loss: 0.4146 - accuracy: 0.8018\n",
            "Epoch 20/20\n",
            "36/36 - 0s - loss: 0.4138 - accuracy: 0.7998\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=20, nodes=256, total=   3.3s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=20, nodes=256 ........\n",
            "Epoch 1/20\n",
            "36/36 - 1s - loss: 0.5429 - accuracy: 0.7338\n",
            "Epoch 2/20\n",
            "36/36 - 0s - loss: 0.4518 - accuracy: 0.7801\n",
            "Epoch 3/20\n",
            "36/36 - 0s - loss: 0.4282 - accuracy: 0.7921\n",
            "Epoch 4/20\n",
            "36/36 - 0s - loss: 0.4239 - accuracy: 0.7947\n",
            "Epoch 5/20\n",
            "36/36 - 0s - loss: 0.4257 - accuracy: 0.7929\n",
            "Epoch 6/20\n",
            "36/36 - 0s - loss: 0.4149 - accuracy: 0.7989\n",
            "Epoch 7/20\n",
            "36/36 - 0s - loss: 0.4171 - accuracy: 0.8072\n",
            "Epoch 8/20\n",
            "36/36 - 0s - loss: 0.4156 - accuracy: 0.8029\n",
            "Epoch 9/20\n",
            "36/36 - 0s - loss: 0.4131 - accuracy: 0.8055\n",
            "Epoch 10/20\n",
            "36/36 - 0s - loss: 0.4139 - accuracy: 0.7995\n",
            "Epoch 11/20\n",
            "36/36 - 0s - loss: 0.4175 - accuracy: 0.7927\n",
            "Epoch 12/20\n",
            "36/36 - 0s - loss: 0.4102 - accuracy: 0.8029\n",
            "Epoch 13/20\n",
            "36/36 - 0s - loss: 0.4077 - accuracy: 0.8052\n",
            "Epoch 14/20\n",
            "36/36 - 0s - loss: 0.4102 - accuracy: 0.8026\n",
            "Epoch 15/20\n",
            "36/36 - 0s - loss: 0.4080 - accuracy: 0.8035\n",
            "Epoch 16/20\n",
            "36/36 - 0s - loss: 0.4090 - accuracy: 0.8029\n",
            "Epoch 17/20\n",
            "36/36 - 0s - loss: 0.4080 - accuracy: 0.8040\n",
            "Epoch 18/20\n",
            "36/36 - 0s - loss: 0.4148 - accuracy: 0.7978\n",
            "Epoch 19/20\n",
            "36/36 - 0s - loss: 0.4078 - accuracy: 0.8060\n",
            "Epoch 20/20\n",
            "36/36 - 0s - loss: 0.4082 - accuracy: 0.7984\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=20, nodes=256, total=   3.3s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=30, nodes=64 .........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.6223 - accuracy: 0.6499\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.5421 - accuracy: 0.7338\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.5050 - accuracy: 0.7375\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.4729 - accuracy: 0.7605\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.4503 - accuracy: 0.7807\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.4382 - accuracy: 0.7887\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.4306 - accuracy: 0.7895\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.4265 - accuracy: 0.7941\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.4246 - accuracy: 0.7941\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.4223 - accuracy: 0.7952\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.4217 - accuracy: 0.8006\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.4203 - accuracy: 0.7984\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.4189 - accuracy: 0.8012\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.4188 - accuracy: 0.8020\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.4174 - accuracy: 0.8038\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.4169 - accuracy: 0.8038\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.4161 - accuracy: 0.8035\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.4162 - accuracy: 0.8043\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.4153 - accuracy: 0.8060\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.4150 - accuracy: 0.8066\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.4148 - accuracy: 0.8009\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.4150 - accuracy: 0.8023\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.4138 - accuracy: 0.8049\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.4150 - accuracy: 0.8003\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.4138 - accuracy: 0.8043\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.4139 - accuracy: 0.8049\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.4142 - accuracy: 0.8026\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.4132 - accuracy: 0.8092\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.4134 - accuracy: 0.8029\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.4127 - accuracy: 0.8052\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=30, nodes=64, total=   2.9s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=30, nodes=64 .........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.6174 - accuracy: 0.6576\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.5406 - accuracy: 0.7381\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.5058 - accuracy: 0.7383\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.4709 - accuracy: 0.7514\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.4475 - accuracy: 0.7853\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.4355 - accuracy: 0.7947\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.4290 - accuracy: 0.7958\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.4255 - accuracy: 0.8006\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.4263 - accuracy: 0.7935\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.4225 - accuracy: 0.7984\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.4210 - accuracy: 0.8026\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.4198 - accuracy: 0.8052\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.4190 - accuracy: 0.8012\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.4178 - accuracy: 0.8035\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.4172 - accuracy: 0.8043\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.4164 - accuracy: 0.8043\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.4162 - accuracy: 0.8052\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.4150 - accuracy: 0.8055\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.4149 - accuracy: 0.8094\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.4145 - accuracy: 0.8060\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.4149 - accuracy: 0.8046\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.4150 - accuracy: 0.7964\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.4135 - accuracy: 0.8060\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.4139 - accuracy: 0.8057\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.4134 - accuracy: 0.8040\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.4127 - accuracy: 0.8020\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.4141 - accuracy: 0.8060\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.4128 - accuracy: 0.8066\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.4118 - accuracy: 0.8043\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.4127 - accuracy: 0.8026\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=30, nodes=64, total=   2.6s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=30, nodes=64 .........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.5895 - accuracy: 0.7307\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.5420 - accuracy: 0.7307\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.4962 - accuracy: 0.7372\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.4590 - accuracy: 0.7682\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.4375 - accuracy: 0.7921\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.4278 - accuracy: 0.7969\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.4253 - accuracy: 0.7969\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.4209 - accuracy: 0.7975\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.4181 - accuracy: 0.7986\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.4155 - accuracy: 0.8018\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.4154 - accuracy: 0.8009\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.4124 - accuracy: 0.8029\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.4112 - accuracy: 0.8032\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.4116 - accuracy: 0.8049\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.4123 - accuracy: 0.7989\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.4084 - accuracy: 0.8038\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.4083 - accuracy: 0.8040\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.4085 - accuracy: 0.8038\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.4080 - accuracy: 0.8040\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.4082 - accuracy: 0.8057\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.4082 - accuracy: 0.8009\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.4062 - accuracy: 0.8035\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.4066 - accuracy: 0.8057\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.4059 - accuracy: 0.8032\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.4057 - accuracy: 0.8049\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.4056 - accuracy: 0.8038\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.4077 - accuracy: 0.7995\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.4066 - accuracy: 0.8043\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.4052 - accuracy: 0.8052\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.4058 - accuracy: 0.8026\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=30, nodes=64, total=   2.7s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=30, nodes=128 ........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.5690 - accuracy: 0.7213\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.5032 - accuracy: 0.7437\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.4469 - accuracy: 0.7841\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.4333 - accuracy: 0.7895\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.4248 - accuracy: 0.7935\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.4233 - accuracy: 0.7969\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.4202 - accuracy: 0.7947\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.4187 - accuracy: 0.7972\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.4173 - accuracy: 0.7995\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.4208 - accuracy: 0.7949\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.4173 - accuracy: 0.7964\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.4149 - accuracy: 0.8038\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.4156 - accuracy: 0.8029\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.4182 - accuracy: 0.7955\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.4148 - accuracy: 0.8009\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.4144 - accuracy: 0.8023\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.4165 - accuracy: 0.7984\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.4169 - accuracy: 0.7958\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.4131 - accuracy: 0.8043\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.4146 - accuracy: 0.8029\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.4140 - accuracy: 0.8015\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.4141 - accuracy: 0.7998\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.4132 - accuracy: 0.8018\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.4132 - accuracy: 0.7998\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.4158 - accuracy: 0.7981\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.4143 - accuracy: 0.8038\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.4137 - accuracy: 0.8029\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.4134 - accuracy: 0.8006\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.4137 - accuracy: 0.8015\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.4118 - accuracy: 0.8020\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=30, nodes=128, total=   2.9s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=30, nodes=128 ........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.5604 - accuracy: 0.7381\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.4928 - accuracy: 0.7452\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.4434 - accuracy: 0.7884\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.4332 - accuracy: 0.7944\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.4249 - accuracy: 0.7955\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.4258 - accuracy: 0.7921\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.4194 - accuracy: 0.7998\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.4177 - accuracy: 0.8043\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.4193 - accuracy: 0.8026\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.4181 - accuracy: 0.8006\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.4192 - accuracy: 0.8029\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.4161 - accuracy: 0.8006\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.4164 - accuracy: 0.8018\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.4152 - accuracy: 0.8052\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.4155 - accuracy: 0.8006\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.4146 - accuracy: 0.8046\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.4174 - accuracy: 0.8001\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.4149 - accuracy: 0.7992\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.4129 - accuracy: 0.8015\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.4133 - accuracy: 0.8038\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.4130 - accuracy: 0.7989\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.4156 - accuracy: 0.7989\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.4141 - accuracy: 0.8052\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.4130 - accuracy: 0.8052\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.4154 - accuracy: 0.8026\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.4127 - accuracy: 0.8035\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.4149 - accuracy: 0.8009\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.4158 - accuracy: 0.7978\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.4137 - accuracy: 0.8040\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.4130 - accuracy: 0.8035\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=30, nodes=128, total=   2.8s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=30, nodes=128 ........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.5533 - accuracy: 0.7307\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.4747 - accuracy: 0.7614\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.4329 - accuracy: 0.7924\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.4254 - accuracy: 0.7935\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.4206 - accuracy: 0.7984\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.4172 - accuracy: 0.8020\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.4152 - accuracy: 0.8035\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.4134 - accuracy: 0.8009\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.4148 - accuracy: 0.8012\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.4101 - accuracy: 0.8029\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.4136 - accuracy: 0.7984\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.4081 - accuracy: 0.8035\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.4073 - accuracy: 0.8080\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.4076 - accuracy: 0.8063\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.4071 - accuracy: 0.8038\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.4080 - accuracy: 0.8032\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.4067 - accuracy: 0.8043\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.4100 - accuracy: 0.8035\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.4062 - accuracy: 0.8046\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.4074 - accuracy: 0.7989\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.4085 - accuracy: 0.8046\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.4076 - accuracy: 0.8023\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.4064 - accuracy: 0.8057\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.4066 - accuracy: 0.8049\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.4063 - accuracy: 0.8032\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.4064 - accuracy: 0.8006\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.4080 - accuracy: 0.8012\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.4095 - accuracy: 0.8063\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.4098 - accuracy: 0.8018\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.4074 - accuracy: 0.8012\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=30, nodes=128, total=   2.7s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=30, nodes=256 ........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.5672 - accuracy: 0.7338\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.4739 - accuracy: 0.7631\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.4322 - accuracy: 0.7853\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.4334 - accuracy: 0.7901\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.4221 - accuracy: 0.7912\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.4200 - accuracy: 0.7978\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.4207 - accuracy: 0.7947\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.4198 - accuracy: 0.7958\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.4184 - accuracy: 0.7989\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.4219 - accuracy: 0.7955\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.4252 - accuracy: 0.7884\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.4166 - accuracy: 0.8018\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.4193 - accuracy: 0.7935\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.4228 - accuracy: 0.7898\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.4157 - accuracy: 0.7992\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.4168 - accuracy: 0.7924\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.4189 - accuracy: 0.7955\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.4170 - accuracy: 0.7995\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.4138 - accuracy: 0.8029\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.4143 - accuracy: 0.7958\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.4148 - accuracy: 0.8020\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.4178 - accuracy: 0.7969\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.4205 - accuracy: 0.7929\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.4140 - accuracy: 0.8009\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.4159 - accuracy: 0.7958\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.4137 - accuracy: 0.8023\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.4170 - accuracy: 0.7984\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.4147 - accuracy: 0.7989\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.4139 - accuracy: 0.8049\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.4124 - accuracy: 0.8012\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=30, nodes=256, total=   4.6s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=30, nodes=256 ........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.5505 - accuracy: 0.7381\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.4665 - accuracy: 0.7676\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.4328 - accuracy: 0.7907\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.4289 - accuracy: 0.7912\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.4317 - accuracy: 0.7927\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.4276 - accuracy: 0.7924\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.4198 - accuracy: 0.8012\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.4173 - accuracy: 0.8057\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.4187 - accuracy: 0.8009\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.4181 - accuracy: 0.7978\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.4239 - accuracy: 0.7952\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.4189 - accuracy: 0.7992\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.4207 - accuracy: 0.7947\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.4228 - accuracy: 0.7955\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.4158 - accuracy: 0.8015\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.4156 - accuracy: 0.8023\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.4200 - accuracy: 0.8001\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.4163 - accuracy: 0.8003\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.4148 - accuracy: 0.8029\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.4140 - accuracy: 0.7984\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.4152 - accuracy: 0.8018\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.4170 - accuracy: 0.8043\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.4247 - accuracy: 0.7898\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.4139 - accuracy: 0.8026\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.4190 - accuracy: 0.8001\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.4138 - accuracy: 0.8020\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.4184 - accuracy: 0.7947\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.4189 - accuracy: 0.7961\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.4154 - accuracy: 0.8032\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.4123 - accuracy: 0.8046\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=30, nodes=256, total=   4.5s\n",
            "[CV] activation=sigmoid, batch_size=100, epochs=30, nodes=256 ........\n",
            "Epoch 1/30\n",
            "36/36 - 1s - loss: 0.5584 - accuracy: 0.7309\n",
            "Epoch 2/30\n",
            "36/36 - 0s - loss: 0.4608 - accuracy: 0.7696\n",
            "Epoch 3/30\n",
            "36/36 - 0s - loss: 0.4287 - accuracy: 0.7915\n",
            "Epoch 4/30\n",
            "36/36 - 0s - loss: 0.4238 - accuracy: 0.7969\n",
            "Epoch 5/30\n",
            "36/36 - 0s - loss: 0.4245 - accuracy: 0.7921\n",
            "Epoch 6/30\n",
            "36/36 - 0s - loss: 0.4155 - accuracy: 0.8012\n",
            "Epoch 7/30\n",
            "36/36 - 0s - loss: 0.4172 - accuracy: 0.8069\n",
            "Epoch 8/30\n",
            "36/36 - 0s - loss: 0.4154 - accuracy: 0.8020\n",
            "Epoch 9/30\n",
            "36/36 - 0s - loss: 0.4135 - accuracy: 0.8055\n",
            "Epoch 10/30\n",
            "36/36 - 0s - loss: 0.4146 - accuracy: 0.7998\n",
            "Epoch 11/30\n",
            "36/36 - 0s - loss: 0.4181 - accuracy: 0.7907\n",
            "Epoch 12/30\n",
            "36/36 - 0s - loss: 0.4092 - accuracy: 0.8049\n",
            "Epoch 13/30\n",
            "36/36 - 0s - loss: 0.4076 - accuracy: 0.8043\n",
            "Epoch 14/30\n",
            "36/36 - 0s - loss: 0.4098 - accuracy: 0.8038\n",
            "Epoch 15/30\n",
            "36/36 - 0s - loss: 0.4079 - accuracy: 0.8038\n",
            "Epoch 16/30\n",
            "36/36 - 0s - loss: 0.4091 - accuracy: 0.8020\n",
            "Epoch 17/30\n",
            "36/36 - 0s - loss: 0.4081 - accuracy: 0.8043\n",
            "Epoch 18/30\n",
            "36/36 - 0s - loss: 0.4148 - accuracy: 0.7969\n",
            "Epoch 19/30\n",
            "36/36 - 0s - loss: 0.4076 - accuracy: 0.8057\n",
            "Epoch 20/30\n",
            "36/36 - 0s - loss: 0.4084 - accuracy: 0.7989\n",
            "Epoch 21/30\n",
            "36/36 - 0s - loss: 0.4107 - accuracy: 0.8063\n",
            "Epoch 22/30\n",
            "36/36 - 0s - loss: 0.4084 - accuracy: 0.8057\n",
            "Epoch 23/30\n",
            "36/36 - 0s - loss: 0.4090 - accuracy: 0.8026\n",
            "Epoch 24/30\n",
            "36/36 - 0s - loss: 0.4076 - accuracy: 0.8029\n",
            "Epoch 25/30\n",
            "36/36 - 0s - loss: 0.4099 - accuracy: 0.8015\n",
            "Epoch 26/30\n",
            "36/36 - 0s - loss: 0.4107 - accuracy: 0.8055\n",
            "Epoch 27/30\n",
            "36/36 - 0s - loss: 0.4082 - accuracy: 0.8035\n",
            "Epoch 28/30\n",
            "36/36 - 0s - loss: 0.4114 - accuracy: 0.8020\n",
            "Epoch 29/30\n",
            "36/36 - 0s - loss: 0.4083 - accuracy: 0.8052\n",
            "Epoch 30/30\n",
            "36/36 - 0s - loss: 0.4061 - accuracy: 0.8020\n",
            "[CV]  activation=sigmoid, batch_size=100, epochs=30, nodes=256, total=   4.5s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=10, nodes=64 .........\n",
            "Epoch 1/10\n",
            "12/12 - 0s - loss: 0.5753 - accuracy: 0.7338\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.5604 - accuracy: 0.7338\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.5417 - accuracy: 0.7338\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.5218 - accuracy: 0.7338\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.4992 - accuracy: 0.7344\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.4769 - accuracy: 0.7517\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.4579 - accuracy: 0.7776\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.4441 - accuracy: 0.7841\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.4362 - accuracy: 0.7929\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.4314 - accuracy: 0.7912\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=10, nodes=64, total=   1.0s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=10, nodes=64 .........\n",
            "Epoch 1/10\n",
            "12/12 - 1s - loss: 0.5737 - accuracy: 0.7381\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.5526 - accuracy: 0.7381\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.5327 - accuracy: 0.7381\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.5105 - accuracy: 0.7381\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.4886 - accuracy: 0.7381\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.4687 - accuracy: 0.7588\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.4532 - accuracy: 0.7799\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.4433 - accuracy: 0.7847\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.4365 - accuracy: 0.7887\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.4323 - accuracy: 0.7927\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=10, nodes=64, total=   1.4s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=10, nodes=64 .........\n",
            "Epoch 1/10\n",
            "12/12 - 1s - loss: 0.6202 - accuracy: 0.7298\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.5842 - accuracy: 0.7307\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.5708 - accuracy: 0.7307\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.5546 - accuracy: 0.7307\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.5391 - accuracy: 0.7307\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.5216 - accuracy: 0.7307\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.5030 - accuracy: 0.7312\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.4849 - accuracy: 0.7452\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.4680 - accuracy: 0.7648\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.4559 - accuracy: 0.7784\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=10, nodes=64, total=   1.0s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=10, nodes=128 ........\n",
            "Epoch 1/10\n",
            "12/12 - 1s - loss: 0.5729 - accuracy: 0.7338\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.5418 - accuracy: 0.7338\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.5147 - accuracy: 0.7346\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.4845 - accuracy: 0.7432\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.4580 - accuracy: 0.7813\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.4405 - accuracy: 0.7895\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.4325 - accuracy: 0.7910\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.4281 - accuracy: 0.7941\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.4262 - accuracy: 0.7964\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.4237 - accuracy: 0.7958\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=10, nodes=128, total=   1.2s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=10, nodes=128 ........\n",
            "Epoch 1/10\n",
            "12/12 - 1s - loss: 0.6135 - accuracy: 0.6920\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.5678 - accuracy: 0.7381\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.5422 - accuracy: 0.7381\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.5220 - accuracy: 0.7381\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.5007 - accuracy: 0.7381\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.4788 - accuracy: 0.7503\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.4607 - accuracy: 0.7776\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.4487 - accuracy: 0.7858\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.4403 - accuracy: 0.7887\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.4351 - accuracy: 0.7918\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=10, nodes=128, total=   1.2s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=10, nodes=128 ........\n",
            "Epoch 1/10\n",
            "12/12 - 0s - loss: 0.6404 - accuracy: 0.6746\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.5772 - accuracy: 0.7307\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.5566 - accuracy: 0.7307\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.5388 - accuracy: 0.7307\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.5149 - accuracy: 0.7315\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.4914 - accuracy: 0.7432\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.4700 - accuracy: 0.7648\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.4546 - accuracy: 0.7813\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.4439 - accuracy: 0.7870\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.4381 - accuracy: 0.7895\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=10, nodes=128, total=   1.1s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=10, nodes=256 ........\n",
            "Epoch 1/10\n",
            "12/12 - 1s - loss: 0.7100 - accuracy: 0.6601\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.5883 - accuracy: 0.7338\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.5416 - accuracy: 0.7338\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.5097 - accuracy: 0.7381\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.4833 - accuracy: 0.7426\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.4614 - accuracy: 0.7807\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.4454 - accuracy: 0.7838\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.4356 - accuracy: 0.7878\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.4314 - accuracy: 0.7932\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.4282 - accuracy: 0.7932\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=10, nodes=256, total=   1.5s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=10, nodes=256 ........\n",
            "Epoch 1/10\n",
            "12/12 - 1s - loss: 0.6067 - accuracy: 0.6943\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.5531 - accuracy: 0.7381\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.5195 - accuracy: 0.7381\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.4875 - accuracy: 0.7423\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.4609 - accuracy: 0.7745\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.4448 - accuracy: 0.7875\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.4349 - accuracy: 0.7907\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.4312 - accuracy: 0.7952\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.4316 - accuracy: 0.7870\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.4270 - accuracy: 0.7941\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=10, nodes=256, total=   1.5s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=10, nodes=256 ........\n",
            "Epoch 1/10\n",
            "12/12 - 1s - loss: 0.6892 - accuracy: 0.6436\n",
            "Epoch 2/10\n",
            "12/12 - 0s - loss: 0.5765 - accuracy: 0.7307\n",
            "Epoch 3/10\n",
            "12/12 - 0s - loss: 0.5420 - accuracy: 0.7307\n",
            "Epoch 4/10\n",
            "12/12 - 0s - loss: 0.5086 - accuracy: 0.7315\n",
            "Epoch 5/10\n",
            "12/12 - 0s - loss: 0.4818 - accuracy: 0.7449\n",
            "Epoch 6/10\n",
            "12/12 - 0s - loss: 0.4588 - accuracy: 0.7790\n",
            "Epoch 7/10\n",
            "12/12 - 0s - loss: 0.4436 - accuracy: 0.7838\n",
            "Epoch 8/10\n",
            "12/12 - 0s - loss: 0.4349 - accuracy: 0.7921\n",
            "Epoch 9/10\n",
            "12/12 - 0s - loss: 0.4294 - accuracy: 0.7952\n",
            "Epoch 10/10\n",
            "12/12 - 0s - loss: 0.4257 - accuracy: 0.7952\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=10, nodes=256, total=   1.5s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=20, nodes=64 .........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.6713 - accuracy: 0.5703\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.5683 - accuracy: 0.7338\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.5655 - accuracy: 0.7338\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.5487 - accuracy: 0.7338\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.5375 - accuracy: 0.7338\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.5255 - accuracy: 0.7338\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.5124 - accuracy: 0.7338\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.4985 - accuracy: 0.7352\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.4851 - accuracy: 0.7446\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.4722 - accuracy: 0.7654\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.4609 - accuracy: 0.7745\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.4519 - accuracy: 0.7793\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.4447 - accuracy: 0.7847\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.4397 - accuracy: 0.7858\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.4363 - accuracy: 0.7907\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.4331 - accuracy: 0.7918\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.4313 - accuracy: 0.7932\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.4296 - accuracy: 0.7958\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.4279 - accuracy: 0.7966\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.4267 - accuracy: 0.7958\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=20, nodes=64, total=   1.4s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=20, nodes=64 .........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.5769 - accuracy: 0.7381\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.5600 - accuracy: 0.7381\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.5436 - accuracy: 0.7381\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.5253 - accuracy: 0.7381\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.5045 - accuracy: 0.7381\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.4830 - accuracy: 0.7423\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.4642 - accuracy: 0.7696\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.4501 - accuracy: 0.7830\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.4404 - accuracy: 0.7875\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.4343 - accuracy: 0.7921\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.4305 - accuracy: 0.7910\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.4277 - accuracy: 0.7952\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.4256 - accuracy: 0.7944\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.4237 - accuracy: 0.7958\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.4226 - accuracy: 0.7975\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.4203 - accuracy: 0.7964\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.4195 - accuracy: 0.7989\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.4185 - accuracy: 0.7989\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.4176 - accuracy: 0.8015\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.4171 - accuracy: 0.8026\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=20, nodes=64, total=   1.4s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=20, nodes=64 .........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.7350 - accuracy: 0.4579\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.5842 - accuracy: 0.7307\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.5753 - accuracy: 0.7307\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.5586 - accuracy: 0.7307\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.5459 - accuracy: 0.7307\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.5333 - accuracy: 0.7307\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.5201 - accuracy: 0.7307\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.5065 - accuracy: 0.7312\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.4926 - accuracy: 0.7383\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.4804 - accuracy: 0.7503\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.4692 - accuracy: 0.7673\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.4597 - accuracy: 0.7725\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.4521 - accuracy: 0.7844\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.4463 - accuracy: 0.7867\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.4412 - accuracy: 0.7875\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.4374 - accuracy: 0.7907\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.4342 - accuracy: 0.7918\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.4315 - accuracy: 0.7912\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.4291 - accuracy: 0.7932\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.4272 - accuracy: 0.7935\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=20, nodes=64, total=   1.8s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=20, nodes=128 ........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.6656 - accuracy: 0.5757\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.5896 - accuracy: 0.7338\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.5485 - accuracy: 0.7338\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.5347 - accuracy: 0.7338\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.5160 - accuracy: 0.7338\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.4969 - accuracy: 0.7383\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.4782 - accuracy: 0.7511\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.4611 - accuracy: 0.7696\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.4484 - accuracy: 0.7833\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.4393 - accuracy: 0.7847\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.4339 - accuracy: 0.7910\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.4302 - accuracy: 0.7938\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.4277 - accuracy: 0.7929\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.4260 - accuracy: 0.7955\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.4249 - accuracy: 0.7964\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.4233 - accuracy: 0.7984\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.4222 - accuracy: 0.7986\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.4216 - accuracy: 0.7955\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.4205 - accuracy: 0.7975\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.4194 - accuracy: 0.7986\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=20, nodes=128, total=   1.7s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=20, nodes=128 ........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.5919 - accuracy: 0.7381\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.5598 - accuracy: 0.7381\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.5392 - accuracy: 0.7381\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.5167 - accuracy: 0.7381\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.4929 - accuracy: 0.7383\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.4694 - accuracy: 0.7602\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.4517 - accuracy: 0.7833\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.4419 - accuracy: 0.7912\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.4360 - accuracy: 0.7856\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.4313 - accuracy: 0.7944\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.4286 - accuracy: 0.7947\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.4256 - accuracy: 0.7981\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.4250 - accuracy: 0.8009\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.4215 - accuracy: 0.7949\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.4210 - accuracy: 0.8020\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.4199 - accuracy: 0.8009\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.4185 - accuracy: 0.8009\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.4173 - accuracy: 0.8023\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.4170 - accuracy: 0.8057\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.4163 - accuracy: 0.8057\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=20, nodes=128, total=   1.7s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=20, nodes=128 ........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.5609 - accuracy: 0.7307\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.5310 - accuracy: 0.7307\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.4964 - accuracy: 0.7446\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.4712 - accuracy: 0.7591\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.4465 - accuracy: 0.7765\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.4345 - accuracy: 0.7941\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.4300 - accuracy: 0.7921\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.4245 - accuracy: 0.7964\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.4215 - accuracy: 0.7981\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.4186 - accuracy: 0.8009\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.4171 - accuracy: 0.8023\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.4155 - accuracy: 0.8015\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.4131 - accuracy: 0.8060\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.4176 - accuracy: 0.7992\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.4142 - accuracy: 0.7998\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.4105 - accuracy: 0.8029\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.4102 - accuracy: 0.8035\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.4103 - accuracy: 0.8023\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.4079 - accuracy: 0.8040\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.4084 - accuracy: 0.8046\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=20, nodes=128, total=   1.7s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=20, nodes=256 ........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.5780 - accuracy: 0.7338\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.5364 - accuracy: 0.7338\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.4958 - accuracy: 0.7517\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.4591 - accuracy: 0.7662\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.4367 - accuracy: 0.7887\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.4357 - accuracy: 0.7867\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.4274 - accuracy: 0.7941\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.4247 - accuracy: 0.7978\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.4218 - accuracy: 0.7972\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.4218 - accuracy: 0.7938\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.4200 - accuracy: 0.8006\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.4187 - accuracy: 0.7958\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.4177 - accuracy: 0.7966\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.4183 - accuracy: 0.7941\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.4172 - accuracy: 0.7998\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.4150 - accuracy: 0.8001\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.4145 - accuracy: 0.8057\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.4150 - accuracy: 0.7992\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.4137 - accuracy: 0.8075\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.4138 - accuracy: 0.8052\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=20, nodes=256, total=   2.2s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=20, nodes=256 ........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.6397 - accuracy: 0.6943\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.5581 - accuracy: 0.7381\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.5351 - accuracy: 0.7383\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.5027 - accuracy: 0.7381\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.4761 - accuracy: 0.7585\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.4535 - accuracy: 0.7807\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.4421 - accuracy: 0.7895\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.4365 - accuracy: 0.7924\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.4360 - accuracy: 0.7910\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.4287 - accuracy: 0.7958\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.4269 - accuracy: 0.7992\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.4241 - accuracy: 0.7969\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.4229 - accuracy: 0.7998\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.4214 - accuracy: 0.8012\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.4204 - accuracy: 0.8032\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.4198 - accuracy: 0.8003\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.4189 - accuracy: 0.8040\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.4168 - accuracy: 0.8006\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.4174 - accuracy: 0.8063\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.4157 - accuracy: 0.8055\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=20, nodes=256, total=   2.3s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=20, nodes=256 ........\n",
            "Epoch 1/20\n",
            "12/12 - 1s - loss: 0.6282 - accuracy: 0.6880\n",
            "Epoch 2/20\n",
            "12/12 - 0s - loss: 0.5790 - accuracy: 0.7315\n",
            "Epoch 3/20\n",
            "12/12 - 0s - loss: 0.5382 - accuracy: 0.7346\n",
            "Epoch 4/20\n",
            "12/12 - 0s - loss: 0.5033 - accuracy: 0.7375\n",
            "Epoch 5/20\n",
            "12/12 - 0s - loss: 0.4700 - accuracy: 0.7639\n",
            "Epoch 6/20\n",
            "12/12 - 0s - loss: 0.4483 - accuracy: 0.7816\n",
            "Epoch 7/20\n",
            "12/12 - 0s - loss: 0.4389 - accuracy: 0.7850\n",
            "Epoch 8/20\n",
            "12/12 - 0s - loss: 0.4306 - accuracy: 0.7958\n",
            "Epoch 9/20\n",
            "12/12 - 0s - loss: 0.4265 - accuracy: 0.7969\n",
            "Epoch 10/20\n",
            "12/12 - 0s - loss: 0.4231 - accuracy: 0.7969\n",
            "Epoch 11/20\n",
            "12/12 - 0s - loss: 0.4210 - accuracy: 0.7998\n",
            "Epoch 12/20\n",
            "12/12 - 0s - loss: 0.4190 - accuracy: 0.7975\n",
            "Epoch 13/20\n",
            "12/12 - 0s - loss: 0.4160 - accuracy: 0.8038\n",
            "Epoch 14/20\n",
            "12/12 - 0s - loss: 0.4201 - accuracy: 0.7978\n",
            "Epoch 15/20\n",
            "12/12 - 0s - loss: 0.4200 - accuracy: 0.7978\n",
            "Epoch 16/20\n",
            "12/12 - 0s - loss: 0.4121 - accuracy: 0.8006\n",
            "Epoch 17/20\n",
            "12/12 - 0s - loss: 0.4120 - accuracy: 0.8057\n",
            "Epoch 18/20\n",
            "12/12 - 0s - loss: 0.4121 - accuracy: 0.8043\n",
            "Epoch 19/20\n",
            "12/12 - 0s - loss: 0.4115 - accuracy: 0.8015\n",
            "Epoch 20/20\n",
            "12/12 - 0s - loss: 0.4099 - accuracy: 0.8038\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=20, nodes=256, total=   2.4s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=30, nodes=64 .........\n",
            "Epoch 1/30\n",
            "12/12 - 0s - loss: 0.5718 - accuracy: 0.7338\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.5536 - accuracy: 0.7338\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.5336 - accuracy: 0.7338\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.5114 - accuracy: 0.7338\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4872 - accuracy: 0.7375\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.4659 - accuracy: 0.7759\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.4493 - accuracy: 0.7801\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.4386 - accuracy: 0.7861\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.4329 - accuracy: 0.7910\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.4293 - accuracy: 0.7932\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.4271 - accuracy: 0.7935\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.4251 - accuracy: 0.7975\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.4238 - accuracy: 0.7972\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.4224 - accuracy: 0.7966\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.4219 - accuracy: 0.7961\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.4207 - accuracy: 0.7964\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.4198 - accuracy: 0.7969\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.4193 - accuracy: 0.7981\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.4183 - accuracy: 0.7978\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.4173 - accuracy: 0.8009\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.4168 - accuracy: 0.8009\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.4174 - accuracy: 0.7989\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.4170 - accuracy: 0.7984\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.4161 - accuracy: 0.8020\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.4149 - accuracy: 0.8069\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.4147 - accuracy: 0.8009\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.4141 - accuracy: 0.8040\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.4138 - accuracy: 0.8049\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.4135 - accuracy: 0.8060\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.4134 - accuracy: 0.8063\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=30, nodes=64, total=   1.7s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=30, nodes=64 .........\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.5838 - accuracy: 0.7381\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.5650 - accuracy: 0.7381\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.5478 - accuracy: 0.7381\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.5302 - accuracy: 0.7381\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.5102 - accuracy: 0.7381\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.4896 - accuracy: 0.7398\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.4706 - accuracy: 0.7648\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.4557 - accuracy: 0.7804\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.4452 - accuracy: 0.7858\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.4387 - accuracy: 0.7887\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.4346 - accuracy: 0.7904\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.4317 - accuracy: 0.7924\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.4293 - accuracy: 0.7964\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.4273 - accuracy: 0.7964\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.4259 - accuracy: 0.7955\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.4234 - accuracy: 0.7975\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.4223 - accuracy: 0.7986\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.4210 - accuracy: 0.8001\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.4200 - accuracy: 0.8003\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.4192 - accuracy: 0.8006\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.4186 - accuracy: 0.8015\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.4181 - accuracy: 0.8018\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.4170 - accuracy: 0.8026\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.4168 - accuracy: 0.8006\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.4158 - accuracy: 0.8012\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.4152 - accuracy: 0.8046\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.4150 - accuracy: 0.8023\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.4149 - accuracy: 0.8072\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.4140 - accuracy: 0.8035\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.4140 - accuracy: 0.8080\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=30, nodes=64, total=   1.7s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=30, nodes=64 .........\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.6143 - accuracy: 0.7270\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.5746 - accuracy: 0.7307\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.5619 - accuracy: 0.7307\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.5460 - accuracy: 0.7307\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.5304 - accuracy: 0.7307\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.5125 - accuracy: 0.7307\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.4935 - accuracy: 0.7378\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.4756 - accuracy: 0.7520\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.4596 - accuracy: 0.7676\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.4487 - accuracy: 0.7850\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.4405 - accuracy: 0.7867\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.4347 - accuracy: 0.7921\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.4306 - accuracy: 0.7944\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.4280 - accuracy: 0.7941\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.4251 - accuracy: 0.7972\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.4226 - accuracy: 0.8015\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.4211 - accuracy: 0.7969\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.4195 - accuracy: 0.8006\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.4177 - accuracy: 0.7992\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.4169 - accuracy: 0.8006\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.4157 - accuracy: 0.8018\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.4147 - accuracy: 0.8001\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.4135 - accuracy: 0.8012\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.4127 - accuracy: 0.8032\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.4121 - accuracy: 0.7998\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.4112 - accuracy: 0.8023\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.4112 - accuracy: 0.8043\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.4103 - accuracy: 0.8020\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.4099 - accuracy: 0.8032\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.4091 - accuracy: 0.8009\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=30, nodes=64, total=   2.2s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=30, nodes=128 ........\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.6002 - accuracy: 0.6937\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.5633 - accuracy: 0.7338\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.5346 - accuracy: 0.7338\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.5114 - accuracy: 0.7338\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4884 - accuracy: 0.7395\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.4660 - accuracy: 0.7708\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.4488 - accuracy: 0.7830\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.4376 - accuracy: 0.7867\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.4319 - accuracy: 0.7904\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.4282 - accuracy: 0.7910\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.4260 - accuracy: 0.7949\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.4239 - accuracy: 0.7964\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.4226 - accuracy: 0.7969\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.4210 - accuracy: 0.7972\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.4205 - accuracy: 0.7986\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.4198 - accuracy: 0.8006\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.4187 - accuracy: 0.8012\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.4187 - accuracy: 0.8018\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.4176 - accuracy: 0.7972\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.4165 - accuracy: 0.8003\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.4157 - accuracy: 0.8023\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.4166 - accuracy: 0.7984\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.4176 - accuracy: 0.7995\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.4174 - accuracy: 0.8012\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.4156 - accuracy: 0.8052\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.4138 - accuracy: 0.8069\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.4134 - accuracy: 0.8086\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.4132 - accuracy: 0.8063\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.4132 - accuracy: 0.8077\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.4133 - accuracy: 0.8077\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=30, nodes=128, total=   2.1s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=30, nodes=128 ........\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.5852 - accuracy: 0.7381\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.5552 - accuracy: 0.7381\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.5338 - accuracy: 0.7381\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.5060 - accuracy: 0.7381\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4786 - accuracy: 0.7537\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.4573 - accuracy: 0.7728\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.4434 - accuracy: 0.7878\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.4371 - accuracy: 0.7927\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.4339 - accuracy: 0.7895\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.4289 - accuracy: 0.7966\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.4265 - accuracy: 0.7984\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.4236 - accuracy: 0.7984\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.4233 - accuracy: 0.7989\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.4203 - accuracy: 0.7972\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.4196 - accuracy: 0.8032\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.4188 - accuracy: 0.7989\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.4177 - accuracy: 0.8006\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.4165 - accuracy: 0.8026\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.4161 - accuracy: 0.8046\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.4156 - accuracy: 0.8052\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.4174 - accuracy: 0.8072\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.4170 - accuracy: 0.8006\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.4154 - accuracy: 0.8029\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.4161 - accuracy: 0.7986\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.4152 - accuracy: 0.8055\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.4129 - accuracy: 0.8038\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.4130 - accuracy: 0.8046\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.4134 - accuracy: 0.8038\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.4129 - accuracy: 0.8057\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.4123 - accuracy: 0.8029\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=30, nodes=128, total=   2.2s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=30, nodes=128 ........\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.5745 - accuracy: 0.7307\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.5498 - accuracy: 0.7307\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.5177 - accuracy: 0.7329\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.4904 - accuracy: 0.7452\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4600 - accuracy: 0.7728\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.4424 - accuracy: 0.7881\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.4348 - accuracy: 0.7861\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.4283 - accuracy: 0.7958\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.4248 - accuracy: 0.7961\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.4217 - accuracy: 0.7969\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.4200 - accuracy: 0.7995\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.4181 - accuracy: 0.7984\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.4158 - accuracy: 0.8026\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.4190 - accuracy: 0.7978\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.4149 - accuracy: 0.7995\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.4123 - accuracy: 0.7995\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.4114 - accuracy: 0.8046\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.4111 - accuracy: 0.8043\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.4090 - accuracy: 0.8049\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.4093 - accuracy: 0.8029\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.4086 - accuracy: 0.8023\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.4089 - accuracy: 0.8046\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.4087 - accuracy: 0.8040\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.4073 - accuracy: 0.8049\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.4075 - accuracy: 0.8023\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.4070 - accuracy: 0.8055\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.4080 - accuracy: 0.8063\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.4075 - accuracy: 0.8035\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.4060 - accuracy: 0.8023\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.4053 - accuracy: 0.8029\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=30, nodes=128, total=   2.2s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=30, nodes=256 ........\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.5929 - accuracy: 0.7321\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.5428 - accuracy: 0.7338\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.5075 - accuracy: 0.7378\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.4732 - accuracy: 0.7531\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4495 - accuracy: 0.7838\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.4391 - accuracy: 0.7890\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.4296 - accuracy: 0.7952\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.4274 - accuracy: 0.7955\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.4239 - accuracy: 0.7975\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.4233 - accuracy: 0.7961\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.4206 - accuracy: 0.7986\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.4195 - accuracy: 0.7969\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.4186 - accuracy: 0.7981\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.4177 - accuracy: 0.7992\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.4174 - accuracy: 0.8012\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.4161 - accuracy: 0.8009\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.4148 - accuracy: 0.8032\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.4156 - accuracy: 0.8001\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.4140 - accuracy: 0.8066\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.4140 - accuracy: 0.8055\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.4142 - accuracy: 0.7995\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.4144 - accuracy: 0.8001\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.4139 - accuracy: 0.8009\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.4142 - accuracy: 0.7975\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.4124 - accuracy: 0.8026\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.4130 - accuracy: 0.8026\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.4132 - accuracy: 0.8043\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.4138 - accuracy: 0.8055\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.4124 - accuracy: 0.8026\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.4136 - accuracy: 0.7998\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=30, nodes=256, total=   3.1s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=30, nodes=256 ........\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.7098 - accuracy: 0.6567\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.5808 - accuracy: 0.7381\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.5397 - accuracy: 0.7381\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.5116 - accuracy: 0.7383\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4882 - accuracy: 0.7418\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.4666 - accuracy: 0.7708\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.4509 - accuracy: 0.7847\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.4423 - accuracy: 0.7912\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.4378 - accuracy: 0.7878\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.4327 - accuracy: 0.7952\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.4300 - accuracy: 0.7975\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.4267 - accuracy: 0.7975\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.4261 - accuracy: 0.7981\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.4228 - accuracy: 0.7964\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.4217 - accuracy: 0.8018\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.4207 - accuracy: 0.8018\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.4196 - accuracy: 0.8023\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.4181 - accuracy: 0.8032\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.4176 - accuracy: 0.8066\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.4167 - accuracy: 0.8052\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.4191 - accuracy: 0.8092\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.4191 - accuracy: 0.7978\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.4160 - accuracy: 0.8043\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.4177 - accuracy: 0.8038\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.4166 - accuracy: 0.8012\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.4140 - accuracy: 0.8052\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.4134 - accuracy: 0.8057\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.4143 - accuracy: 0.8023\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.4133 - accuracy: 0.8026\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.4143 - accuracy: 0.8043\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=30, nodes=256, total=   3.0s\n",
            "[CV] activation=sigmoid, batch_size=300, epochs=30, nodes=256 ........\n",
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.5967 - accuracy: 0.7307\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.5585 - accuracy: 0.7307\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.5166 - accuracy: 0.7361\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.4849 - accuracy: 0.7554\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.4557 - accuracy: 0.7750\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.4400 - accuracy: 0.7907\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.4342 - accuracy: 0.7887\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.4283 - accuracy: 0.7924\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.4244 - accuracy: 0.7964\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.4207 - accuracy: 0.7989\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.4197 - accuracy: 0.7989\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.4171 - accuracy: 0.8012\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.4147 - accuracy: 0.8032\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.4179 - accuracy: 0.7978\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.4230 - accuracy: 0.7938\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.4115 - accuracy: 0.8072\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.4097 - accuracy: 0.8046\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.4101 - accuracy: 0.8029\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.4113 - accuracy: 0.8035\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.4111 - accuracy: 0.8043\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.4094 - accuracy: 0.8003\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.4077 - accuracy: 0.8026\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.4087 - accuracy: 0.8066\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.4064 - accuracy: 0.8043\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.4062 - accuracy: 0.8040\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.4070 - accuracy: 0.8023\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.4093 - accuracy: 0.7961\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.4076 - accuracy: 0.8032\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.4062 - accuracy: 0.8049\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.4075 - accuracy: 0.8029\n",
            "[CV]  activation=sigmoid, batch_size=300, epochs=30, nodes=256, total=   3.0s\n",
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed:  6.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "106/106 - 1s - loss: 0.5633 - accuracy: 0.7137\n",
            "Epoch 2/30\n",
            "106/106 - 0s - loss: 0.4602 - accuracy: 0.7700\n",
            "Epoch 3/30\n",
            "106/106 - 0s - loss: 0.4293 - accuracy: 0.7967\n",
            "Epoch 4/30\n",
            "106/106 - 0s - loss: 0.4230 - accuracy: 0.7969\n",
            "Epoch 5/30\n",
            "106/106 - 0s - loss: 0.4190 - accuracy: 0.8000\n",
            "Epoch 6/30\n",
            "106/106 - 0s - loss: 0.4172 - accuracy: 0.8051\n",
            "Epoch 7/30\n",
            "106/106 - 0s - loss: 0.4148 - accuracy: 0.8013\n",
            "Epoch 8/30\n",
            "106/106 - 0s - loss: 0.4160 - accuracy: 0.8028\n",
            "Epoch 9/30\n",
            "106/106 - 0s - loss: 0.4138 - accuracy: 0.8058\n",
            "Epoch 10/30\n",
            "106/106 - 0s - loss: 0.4126 - accuracy: 0.8045\n",
            "Epoch 11/30\n",
            "106/106 - 0s - loss: 0.4140 - accuracy: 0.8038\n",
            "Epoch 12/30\n",
            "106/106 - 0s - loss: 0.4122 - accuracy: 0.8053\n",
            "Epoch 13/30\n",
            "106/106 - 0s - loss: 0.4127 - accuracy: 0.8041\n",
            "Epoch 14/30\n",
            "106/106 - 0s - loss: 0.4120 - accuracy: 0.8039\n",
            "Epoch 15/30\n",
            "106/106 - 0s - loss: 0.4115 - accuracy: 0.8022\n",
            "Epoch 16/30\n",
            "106/106 - 0s - loss: 0.4117 - accuracy: 0.8034\n",
            "Epoch 17/30\n",
            "106/106 - 0s - loss: 0.4111 - accuracy: 0.8049\n",
            "Epoch 18/30\n",
            "106/106 - 0s - loss: 0.4108 - accuracy: 0.8039\n",
            "Epoch 19/30\n",
            "106/106 - 0s - loss: 0.4110 - accuracy: 0.8055\n",
            "Epoch 20/30\n",
            "106/106 - 0s - loss: 0.4109 - accuracy: 0.8053\n",
            "Epoch 21/30\n",
            "106/106 - 0s - loss: 0.4098 - accuracy: 0.8053\n",
            "Epoch 22/30\n",
            "106/106 - 0s - loss: 0.4107 - accuracy: 0.8030\n",
            "Epoch 23/30\n",
            "106/106 - 0s - loss: 0.4097 - accuracy: 0.8058\n",
            "Epoch 24/30\n",
            "106/106 - 0s - loss: 0.4096 - accuracy: 0.8055\n",
            "Epoch 25/30\n",
            "106/106 - 0s - loss: 0.4110 - accuracy: 0.8034\n",
            "Epoch 26/30\n",
            "106/106 - 0s - loss: 0.4091 - accuracy: 0.8072\n",
            "Epoch 27/30\n",
            "106/106 - 0s - loss: 0.4097 - accuracy: 0.8041\n",
            "Epoch 28/30\n",
            "106/106 - 0s - loss: 0.4087 - accuracy: 0.8045\n",
            "Epoch 29/30\n",
            "106/106 - 0s - loss: 0.4080 - accuracy: 0.8039\n",
            "Epoch 30/30\n",
            "106/106 - 0s - loss: 0.4083 - accuracy: 0.8053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlDxZm42e95m",
        "outputId": "16f7102e-3e08-4dd2-83bc-2a5c4f5a6dc1"
      },
      "source": [
        "# 최적의 결과값을 낸 파라미터를 출력합니다\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.806598424911499 using {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 30, 'nodes': 64}\n",
            "Means: 0.7974971334139506, Stdev: 0.007936460821706568 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 10, 'nodes': 64}\n",
            "Means: 0.7935153444608053, Stdev: 0.004826685189366592 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 10, 'nodes': 128}\n",
            "Means: 0.7921880880991617, Stdev: 0.0072001668697371235 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 10, 'nodes': 256}\n",
            "Means: 0.7935153643290201, Stdev: 0.003968231834885048 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 20, 'nodes': 64}\n",
            "Means: 0.7825180093447367, Stdev: 0.004966173464021692 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 20, 'nodes': 128}\n",
            "Means: 0.7755024631818136, Stdev: 0.0161847048404196 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 20, 'nodes': 256}\n",
            "Means: 0.7897231777509054, Stdev: 0.006339881198630848 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 30, 'nodes': 64}\n",
            "Means: 0.7722791234652201, Stdev: 0.012679749918908786 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 30, 'nodes': 128}\n",
            "Means: 0.7627986272176107, Stdev: 0.009427225861615821 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 30, 'nodes': 256}\n",
            "Means: 0.7982556025187174, Stdev: 0.005178793815853476 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 10, 'nodes': 64}\n",
            "Means: 0.7940841913223267, Stdev: 0.0018577649583669952 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 10, 'nodes': 128}\n",
            "Means: 0.7887751261393229, Stdev: 0.0037252432675041955 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 10, 'nodes': 256}\n",
            "Means: 0.7957906723022461, Stdev: 0.0013933358855224129 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 20, 'nodes': 64}\n",
            "Means: 0.7893439332644144, Stdev: 0.007215139148671137 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 20, 'nodes': 128}\n",
            "Means: 0.7804323037465414, Stdev: 0.013436872428661728 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 20, 'nodes': 256}\n",
            "Means: 0.7948426405588785, Stdev: 0.002337649201426653 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 30, 'nodes': 64}\n",
            "Means: 0.78763747215271, Stdev: 0.006767760638259018 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 30, 'nodes': 128}\n",
            "Means: 0.77417520682017, Stdev: 0.016893325911045986 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 30, 'nodes': 256}\n",
            "Means: 0.8014789422353109, Stdev: 0.0025859321606428085 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 10, 'nodes': 64}\n",
            "Means: 0.8014789621035258, Stdev: 0.0033491671520976822 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 10, 'nodes': 128}\n",
            "Means: 0.799582858880361, Stdev: 0.0017583729350558457 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 10, 'nodes': 256}\n",
            "Means: 0.7990140517552694, Stdev: 0.002721407078751164 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 20, 'nodes': 64}\n",
            "Means: 0.7957906723022461, Stdev: 0.0028250957707270097 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 20, 'nodes': 128}\n",
            "Means: 0.7916192611058553, Stdev: 0.004582104637391739 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 20, 'nodes': 256}\n",
            "Means: 0.7971179286638895, Stdev: 0.000536304598351623 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 30, 'nodes': 64}\n",
            "Means: 0.7948426206906637, Stdev: 0.0066714318916141204 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 30, 'nodes': 128}\n",
            "Means: 0.7847933173179626, Stdev: 0.010388809007626466 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 30, 'nodes': 256}\n",
            "Means: 0.8018581867218018, Stdev: 0.004188599065343348 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 10, 'nodes': 64}\n",
            "Means: 0.8028062184651693, Stdev: 0.0023833391883564163 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 10, 'nodes': 128}\n",
            "Means: 0.788395901521047, Stdev: 0.010921899497160688 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 10, 'nodes': 256}\n",
            "Means: 0.8018581867218018, Stdev: 0.003516728730436511 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 20, 'nodes': 64}\n",
            "Means: 0.8060295780499777, Stdev: 0.001674597073829323 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 20, 'nodes': 128}\n",
            "Means: 0.8035646677017212, Stdev: 0.003423488757101933 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 20, 'nodes': 256}\n",
            "Means: 0.806598424911499, Stdev: 0.0027866717710448258 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 30, 'nodes': 64}\n",
            "Means: 0.8065984050432841, Stdev: 0.002457601234343974 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 30, 'nodes': 128}\n",
            "Means: 0.8062191804250082, Stdev: 0.0032950603139239336 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 30, 'nodes': 256}\n",
            "Means: 0.8026166160901388, Stdev: 0.0021283822713404434 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 10, 'nodes': 64}\n",
            "Means: 0.7963594992955526, Stdev: 0.0012288190115991298 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 10, 'nodes': 128}\n",
            "Means: 0.8039438724517822, Stdev: 0.0028378040884592106 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 10, 'nodes': 256}\n",
            "Means: 0.8039438724517822, Stdev: 0.0014929760128087226 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 20, 'nodes': 64}\n",
            "Means: 0.8029958208401998, Stdev: 0.000536304598351623 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 20, 'nodes': 128}\n",
            "Means: 0.806219200293223, Stdev: 0.0014929861057952356 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 20, 'nodes': 256}\n",
            "Means: 0.8020477692286173, Stdev: 0.004022214242889653 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 30, 'nodes': 64}\n",
            "Means: 0.806219200293223, Stdev: 0.0021948799729043064 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 30, 'nodes': 128}\n",
            "Means: 0.8050815264383951, Stdev: 0.0020942986333580575 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 30, 'nodes': 256}\n",
            "Means: 0.7899127801259359, Stdev: 0.004834114185006723 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 10, 'nodes': 64}\n",
            "Means: 0.7889647285143534, Stdev: 0.003627447216988329 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 10, 'nodes': 128}\n",
            "Means: 0.7944634159406027, Stdev: 0.003262165013387848 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 10, 'nodes': 256}\n",
            "Means: 0.7963594992955526, Stdev: 0.007299360708382722 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 20, 'nodes': 64}\n",
            "Means: 0.8031854430834452, Stdev: 0.0023222183647484073 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 20, 'nodes': 128}\n",
            "Means: 0.806219200293223, Stdev: 0.0034859377424370378 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 20, 'nodes': 256}\n",
            "Means: 0.8020477890968323, Stdev: 0.0020244831322918156 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 30, 'nodes': 64}\n",
            "Means: 0.8031854430834452, Stdev: 0.0009288824792897399 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 30, 'nodes': 128}\n",
            "Means: 0.8016685644785563, Stdev: 0.0018770239473821693 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 30, 'nodes': 256}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVpkfckZoM4O"
      },
      "source": [
        "### 문항 7) 최적의 결과를 낸 파라미터와 결과값을 입력하시오.\n",
        "\n",
        "- batch_size :50\n",
        "- epochs :30\n",
        "- nodes :64\n",
        "- activation :sigmoid\n",
        "\n",
        "- 정답은 `[100, 100, 100], activation_name` 형태로 입력하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSvjGExCjvc_"
      },
      "source": [
        "'activation': 'sigmoid', 'batch_size': 100, 'epochs': 30, 'nodes': 128 가 최적으로 나왔다. 정확도는 약 0.80 \n",
        "\n",
        "이젠 Keras Tuner 를 사용한 파라미터 튜닝도 해보겠음!\n",
        "\n",
        "## Keras Tuner 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sICAonafRIG"
      },
      "source": [
        "# 모델 만들기\n",
        "\n",
        "def model_builder(hp):\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  # Dense layer에서 노드 수를 조정(32-512)\n",
        "  hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
        "\n",
        "  model.add(Dense(units = hp_units, activation='relu'))\n",
        "  model.add(Dense(units = hp_units, activation='relu'))\n",
        "\n",
        "  model.add(Dense(1, activation='sigmoid')) # 이진분류니까 노드수 1, 활성함수로는 시그모이드\n",
        "\n",
        "  # Optimizer의 학습률(learning rate)을 조정[0.01, 0.001, 0.0001]합니다. \n",
        "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  # 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성함\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate = hp_learning_rate), \n",
        "                loss=keras.losses.BinaryCrossentropy(from_logits = True), \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pldUkyetfRKa"
      },
      "source": [
        "# 튜너를 인스턴스화하고 하이퍼 튜닝을 수행\n",
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective = 'val_accuracy', \n",
        "                     max_epochs = 30, \n",
        "                     factor = 3,\n",
        "                     directory = 'my_dir',\n",
        "                     project_name = 'intro_to_kt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mTmNvRkfRMe"
      },
      "source": [
        "# callback 정의 : 하이퍼 파라미터 검색을 실행하기 전에 모든 교육 단계가 끝날 때마다 교육 출력을 지우도록 콜백을 정의합니다.\n",
        "\n",
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "  def on_train_end(*args, **kwargs):\n",
        "    IPython.display.clear_output(wait = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENk4-EMkfROz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c186e7f9-6168-4cfc-e688-8e6cba054730"
      },
      "source": [
        "tuner.search(X_train_scaled, y_train, epochs = 30, batch_size=50, validation_data = (X_test_scaled,y_test), callbacks = [ClearTrainingOutput()])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "최적화된 Dense 노드 수 : {best_hps.get('units')} \n",
        "최적화된 Learning Rate : {best_hps.get('learning_rate')} \n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 66 Complete [00h 00m 03s]\n",
            "val_accuracy: 0.796928346157074\n",
            "\n",
            "Best val_accuracy So Far: 0.806598424911499\n",
            "Total elapsed time: 00h 02m 32s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "\n",
            "최적화된 Dense 노드 수 : 480 \n",
            "최적화된 Learning Rate : 0.001 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJzITjRromsc"
      },
      "source": [
        "### 문항 8) Keras 튜너를 활용하여 얻어낸 파라미터를 입력하시오. \n",
        "\n",
        "- 정답은 `[100, 100]` 형태로 입력하시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQtipKllUBAy",
        "outputId": "1b86c590-1e3b-4220-fd75-50023aafed2c"
      },
      "source": [
        "# 찾은 파라미터들로 모델 만들어보기 (Dense 노드 수 : 416, Learning Rate : 0.01, batch_size : 100, epochs : 30)\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "tf.random.set_seed(1442)\n",
        "initializer = tf.keras.initializers.HeNormal()\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(best_hps.get('units'), \n",
        "                activation='relu', kernel_initializer=initializer,          \n",
        "                kernel_regularizer=regularizers.l2(0.01),    # L2 norm regularization\n",
        "                activity_regularizer=regularizers.l1(0.01))) # L1 norm regularization))\n",
        "model.add(Dense(best_hps.get('units'),\n",
        "                activation='relu', kernel_initializer=initializer,            \n",
        "                kernel_regularizer=regularizers.l2(0.01),    # L2 norm regularization\n",
        "                activity_regularizer=regularizers.l1(0.01)))\n",
        "model.add(Dense(1, activation='sigmoid')) # 이진분류니까 노드수 1, 활성함수로는 시그모이드\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate = best_hps.get('learning_rate')), \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "results = model.fit(X_train_scaled, y_train, epochs=2, batch_size=50, validation_data=(X_test_scaled,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "106/106 [==============================] - 2s 9ms/step - loss: 19.2499 - accuracy: 0.7540 - val_loss: 9.6976 - val_accuracy: 0.7958\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 8.2346 - accuracy: 0.8011 - val_loss: 5.1291 - val_accuracy: 0.7986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt6EKBzUWI1E",
        "outputId": "c08dd990-0304-42a5-b12a-10162e3e103d"
      },
      "source": [
        "# 테스트셋 사용해서 결과 보기\n",
        "model.evaluate(X_test_scaled,  y_test, verbose=2) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 - 0s - loss: 5.1291 - accuracy: 0.7986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.129117012023926, 0.7986348271369934]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAK2wZXOm8Tr"
      },
      "source": [
        "# 도전과제\n",
        "\n",
        "- 1) Random Search 하이퍼 매개 변수 튜닝 구현해보세요.\n",
        "- 2) hyperos 또는 hyperopts를 이용해서 Bayesian Optimiation tuning 수행 [(링크)](https://https://github.com/maxpumperla/hyperas)\n",
        "- 3) 기존에 진행했던 강의&프로젝트 데이터셋을 하이퍼 파라미터로 조정해보세요. \n",
        "- Cifar100을 이용한다면 90% 이상 달성목표! [참고자료](https://paperswithcode.com/sota/image-classification-on-cifar-100)\n",
        "- 4) MLP 모델을 forward 와 backward(학습까지)를 처음부터 구현할 수 있는가?\n",
        "- 5) 케라스에서 MLP 모델을 구현하고 교차 검증(CV)을 통해 하이퍼 파라미터를 조정할 수 있는가?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DgncW3VL1N0"
      },
      "source": [
        "## 1) Random Search 하이퍼 매개 변수 튜닝 구현해보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGe2LA1BPloc"
      },
      "source": [
        "### build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyWZXvlFm8Tr"
      },
      "source": [
        "def make_model_rscv(nodes=64, func='relu', rate=0.1, l2=0.01):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(nodes,\n",
        "                  activation='relu',\n",
        "                  input_dim=X_train.shape[1]))\n",
        "  model.add(Dense(256, activation=func))\n",
        "  model.add(Dropout(rate))\n",
        "  model.add(Dense(512, activation='relu',\n",
        "            kernel_regularizer=regularizers.l2(l2)))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer = 'adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hzXfmLZNOLX"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6W0Op_JPpz3"
      },
      "source": [
        "### Randomized Search CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPtNFkICNA44",
        "outputId": "72ce2046-3e5c-4b4e-9b35-c96e61c21c67"
      },
      "source": [
        "tf.random.set_seed(1442)\n",
        "param_grid = {'nodes': [32, 128, 256, 512],\n",
        "              'func':['tanh', 'relu', 'sigmoid', 'softmax'],\n",
        "              'rate':[0, 0.2, 0.5, 0.7],\n",
        "              'l2':[0.001, 0.005, 0.01, 0.05, 0.1]}\n",
        "\n",
        "model_rscv = KerasClassifier(build_fn=make_model_rscv, verbose=0)\n",
        "\n",
        "grid_rscv = RandomizedSearchCV(\n",
        "    estimator=model_rscv,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=20,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    verbose=3,\n",
        "    n_jobs=1,\n",
        "    random_state=12)\n",
        "grid_result_rscv = grid_rscv.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "[CV] rate=0.7, nodes=512, l2=0.005, func=sigmoid .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.7, nodes=512, l2=0.005, func=sigmoid, score=0.735, total=   3.5s\n",
            "[CV] rate=0.7, nodes=512, l2=0.005, func=sigmoid .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.7, nodes=512, l2=0.005, func=sigmoid, score=0.726, total=   0.9s\n",
            "[CV] rate=0.7, nodes=512, l2=0.005, func=sigmoid .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.7, nodes=512, l2=0.005, func=sigmoid, score=0.770, total=   1.1s\n",
            "[CV] rate=0.2, nodes=32, l2=0.001, func=relu .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=32, l2=0.001, func=relu, score=0.755, total=   0.9s\n",
            "[CV] rate=0.2, nodes=32, l2=0.001, func=relu .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=32, l2=0.001, func=relu, score=0.754, total=   1.0s\n",
            "[CV] rate=0.2, nodes=32, l2=0.001, func=relu .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=32, l2=0.001, func=relu, score=0.750, total=   1.0s\n",
            "[CV] rate=0.2, nodes=256, l2=0.05, func=sigmoid ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=256, l2=0.05, func=sigmoid, score=0.735, total=   0.9s\n",
            "[CV] rate=0.2, nodes=256, l2=0.05, func=sigmoid ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=256, l2=0.05, func=sigmoid, score=0.751, total=   0.9s\n",
            "[CV] rate=0.2, nodes=256, l2=0.05, func=sigmoid ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=256, l2=0.05, func=sigmoid, score=0.741, total=   0.9s\n",
            "[CV] rate=0.5, nodes=512, l2=0.001, func=sigmoid .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.5, nodes=512, l2=0.001, func=sigmoid, score=0.759, total=   1.0s\n",
            "[CV] rate=0.5, nodes=512, l2=0.001, func=sigmoid .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.5, nodes=512, l2=0.001, func=sigmoid, score=0.754, total=   1.2s\n",
            "[CV] rate=0.5, nodes=512, l2=0.001, func=sigmoid .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.5, nodes=512, l2=0.001, func=sigmoid, score=0.741, total=   0.9s\n",
            "[CV] rate=0.2, nodes=128, l2=0.1, func=softmax .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=128, l2=0.1, func=softmax, score=0.735, total=   0.9s\n",
            "[CV] rate=0.2, nodes=128, l2=0.1, func=softmax .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=128, l2=0.1, func=softmax, score=0.726, total=   0.9s\n",
            "[CV] rate=0.2, nodes=128, l2=0.1, func=softmax .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=128, l2=0.1, func=softmax, score=0.741, total=   0.9s\n",
            "[CV] rate=0.2, nodes=256, l2=0.001, func=sigmoid .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=256, l2=0.001, func=sigmoid, score=0.765, total=   1.0s\n",
            "[CV] rate=0.2, nodes=256, l2=0.001, func=sigmoid .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=256, l2=0.001, func=sigmoid, score=0.758, total=   0.9s\n",
            "[CV] rate=0.2, nodes=256, l2=0.001, func=sigmoid .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=256, l2=0.001, func=sigmoid, score=0.769, total=   0.9s\n",
            "[CV] rate=0.5, nodes=128, l2=0.05, func=sigmoid ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.5, nodes=128, l2=0.05, func=sigmoid, score=0.762, total=   1.3s\n",
            "[CV] rate=0.5, nodes=128, l2=0.05, func=sigmoid ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.5, nodes=128, l2=0.05, func=sigmoid, score=0.759, total=   1.0s\n",
            "[CV] rate=0.5, nodes=128, l2=0.05, func=sigmoid ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.5, nodes=128, l2=0.05, func=sigmoid, score=0.765, total=   0.9s\n",
            "[CV] rate=0, nodes=512, l2=0.001, func=tanh ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0, nodes=512, l2=0.001, func=tanh, score=0.760, total=   0.9s\n",
            "[CV] rate=0, nodes=512, l2=0.001, func=tanh ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0, nodes=512, l2=0.001, func=tanh, score=0.726, total=   0.9s\n",
            "[CV] rate=0, nodes=512, l2=0.001, func=tanh ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0, nodes=512, l2=0.001, func=tanh, score=0.762, total=   0.9s\n",
            "[CV] rate=0, nodes=512, l2=0.1, func=sigmoid .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0, nodes=512, l2=0.1, func=sigmoid, score=0.735, total=   0.9s\n",
            "[CV] rate=0, nodes=512, l2=0.1, func=sigmoid .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0, nodes=512, l2=0.1, func=sigmoid, score=0.726, total=   1.0s\n",
            "[CV] rate=0, nodes=512, l2=0.1, func=sigmoid .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0, nodes=512, l2=0.1, func=sigmoid, score=0.741, total=   1.2s\n",
            "[CV] rate=0.7, nodes=256, l2=0.1, func=sigmoid .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.7, nodes=256, l2=0.1, func=sigmoid, score=0.760, total=   0.9s\n",
            "[CV] rate=0.7, nodes=256, l2=0.1, func=sigmoid .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.7, nodes=256, l2=0.1, func=sigmoid, score=0.726, total=   0.9s\n",
            "[CV] rate=0.7, nodes=256, l2=0.1, func=sigmoid .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.7, nodes=256, l2=0.1, func=sigmoid, score=0.741, total=   0.9s\n",
            "[CV] rate=0, nodes=128, l2=0.05, func=tanh ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0, nodes=128, l2=0.05, func=tanh, score=0.759, total=   0.9s\n",
            "[CV] rate=0, nodes=128, l2=0.05, func=tanh ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0, nodes=128, l2=0.05, func=tanh, score=0.751, total=   0.9s\n",
            "[CV] rate=0, nodes=128, l2=0.05, func=tanh ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0, nodes=128, l2=0.05, func=tanh, score=0.766, total=   1.0s\n",
            "[CV] rate=0, nodes=32, l2=0.01, func=sigmoid .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0, nodes=32, l2=0.01, func=sigmoid, score=0.775, total=   1.2s\n",
            "[CV] rate=0, nodes=32, l2=0.01, func=sigmoid .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0, nodes=32, l2=0.01, func=sigmoid, score=0.759, total=   0.9s\n",
            "[CV] rate=0, nodes=32, l2=0.01, func=sigmoid .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0, nodes=32, l2=0.01, func=sigmoid, score=0.777, total=   1.0s\n",
            "[CV] rate=0.5, nodes=128, l2=0.001, func=relu ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.5, nodes=128, l2=0.001, func=relu, score=0.750, total=   0.9s\n",
            "[CV] rate=0.5, nodes=128, l2=0.001, func=relu ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.5, nodes=128, l2=0.001, func=relu, score=0.747, total=   0.9s\n",
            "[CV] rate=0.5, nodes=128, l2=0.001, func=relu ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.5, nodes=128, l2=0.001, func=relu, score=0.259, total=   1.0s\n",
            "[CV] rate=0.2, nodes=128, l2=0.005, func=tanh ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=128, l2=0.005, func=tanh, score=0.735, total=   0.9s\n",
            "[CV] rate=0.2, nodes=128, l2=0.005, func=tanh ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=128, l2=0.005, func=tanh, score=0.750, total=   1.2s\n",
            "[CV] rate=0.2, nodes=128, l2=0.005, func=tanh ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=128, l2=0.005, func=tanh, score=0.773, total=   0.9s\n",
            "[CV] rate=0.7, nodes=512, l2=0.05, func=sigmoid ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.7, nodes=512, l2=0.05, func=sigmoid, score=0.735, total=   1.0s\n",
            "[CV] rate=0.7, nodes=512, l2=0.05, func=sigmoid ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.7, nodes=512, l2=0.05, func=sigmoid, score=0.726, total=   1.0s\n",
            "[CV] rate=0.7, nodes=512, l2=0.05, func=sigmoid ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.7, nodes=512, l2=0.05, func=sigmoid, score=0.741, total=   0.9s\n",
            "[CV] rate=0.2, nodes=32, l2=0.001, func=tanh .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=32, l2=0.001, func=tanh, score=0.764, total=   0.9s\n",
            "[CV] rate=0.2, nodes=32, l2=0.001, func=tanh .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=32, l2=0.001, func=tanh, score=0.726, total=   0.9s\n",
            "[CV] rate=0.2, nodes=32, l2=0.001, func=tanh .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=32, l2=0.001, func=tanh, score=0.767, total=   0.9s\n",
            "[CV] rate=0.2, nodes=256, l2=0.01, func=tanh .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=256, l2=0.01, func=tanh, score=0.761, total=   1.2s\n",
            "[CV] rate=0.2, nodes=256, l2=0.01, func=tanh .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=256, l2=0.01, func=tanh, score=0.726, total=   1.1s\n",
            "[CV] rate=0.2, nodes=256, l2=0.01, func=tanh .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=256, l2=0.01, func=tanh, score=0.763, total=   1.0s\n",
            "[CV] rate=0.2, nodes=512, l2=0.05, func=softmax ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=512, l2=0.05, func=softmax, score=0.735, total=   1.0s\n",
            "[CV] rate=0.2, nodes=512, l2=0.05, func=softmax ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=512, l2=0.05, func=softmax, score=0.726, total=   1.0s\n",
            "[CV] rate=0.2, nodes=512, l2=0.05, func=softmax ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=512, l2=0.05, func=softmax, score=0.741, total=   0.9s\n",
            "[CV] rate=0.2, nodes=32, l2=0.005, func=softmax ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=32, l2=0.005, func=softmax, score=0.765, total=   0.9s\n",
            "[CV] rate=0.2, nodes=32, l2=0.005, func=softmax ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=32, l2=0.005, func=softmax, score=0.768, total=   0.9s\n",
            "[CV] rate=0.2, nodes=32, l2=0.005, func=softmax ......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.2, nodes=32, l2=0.005, func=softmax, score=0.765, total=   1.2s\n",
            "[CV] rate=0.7, nodes=32, l2=0.1, func=tanh ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.7, nodes=32, l2=0.1, func=tanh, score=0.759, total=   0.9s\n",
            "[CV] rate=0.7, nodes=32, l2=0.1, func=tanh ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.7, nodes=32, l2=0.1, func=tanh, score=0.751, total=   0.9s\n",
            "[CV] rate=0.7, nodes=32, l2=0.1, func=tanh ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  1.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.7, nodes=32, l2=0.1, func=tanh, score=0.762, total=   1.0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmbKyK3mPthl"
      },
      "source": [
        "### SCORE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hANVaPFeP-59",
        "outputId": "d1be699e-6615-4ebb-c7c9-69b3538ffad3"
      },
      "source": [
        "rs = pd.DataFrame(grid_result_rscv.cv_results_).sort_values(by='rank_test_score').head()\n",
        "nodes=[]\n",
        "func=[]\n",
        "l2=[]\n",
        "rate=[]\n",
        "for ind in rs.index :\n",
        "  nodes.append(rs.params[ind]['nodes'])\n",
        "  func.append(rs.params[ind]['func'])\n",
        "  l2.append(rs.params[ind]['l2'])\n",
        "  rate.append(rs.params[ind]['rate'])\n",
        "rs['nodes']=nodes\n",
        "rs['func']=func\n",
        "rs['l2']=l2\n",
        "rs['rate']=rate\n",
        "rs[['rank_test_score','nodes','func','l2','rate','split0_test_score',\t'split1_test_score',\t'split2_test_score',\t'mean_test_score',\t'std_test_score']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>nodes</th>\n",
              "      <th>func</th>\n",
              "      <th>l2</th>\n",
              "      <th>rate</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.775313</td>\n",
              "      <td>0.758817</td>\n",
              "      <td>0.777019</td>\n",
              "      <td>0.770383</td>\n",
              "      <td>0.008208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>softmax</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.764505</td>\n",
              "      <td>0.767918</td>\n",
              "      <td>0.765074</td>\n",
              "      <td>0.765832</td>\n",
              "      <td>0.001493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>256</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.765074</td>\n",
              "      <td>0.757679</td>\n",
              "      <td>0.769056</td>\n",
              "      <td>0.763936</td>\n",
              "      <td>0.004714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4</td>\n",
              "      <td>128</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.761661</td>\n",
              "      <td>0.758817</td>\n",
              "      <td>0.764505</td>\n",
              "      <td>0.761661</td>\n",
              "      <td>0.002322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5</td>\n",
              "      <td>128</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.050</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.759386</td>\n",
              "      <td>0.750853</td>\n",
              "      <td>0.766212</td>\n",
              "      <td>0.758817</td>\n",
              "      <td>0.006283</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    rank_test_score  nodes  ... mean_test_score  std_test_score\n",
              "11                1     32  ...        0.770383        0.008208\n",
              "18                2     32  ...        0.765832        0.001493\n",
              "5                 3    256  ...        0.763936        0.004714\n",
              "6                 4    128  ...        0.761661        0.002322\n",
              "10                5    128  ...        0.758817        0.006283\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM12yDcSK1xM"
      },
      "source": [
        "## 2) hyperos 또는 hyperopts를 이용해서 Bayesian Optimiation tuning 수행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCQeltU8LqNo"
      },
      "source": [
        "### 베이직 튜토리얼"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk95KYd7K2mS"
      },
      "source": [
        "from hyperopt import tpe, hp, fmin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "gOcO-ySALek0",
        "outputId": "a2ed6036-2df3-4d2b-f2af-b5b2f30b3450"
      },
      "source": [
        "objective = lambda x: (x-3)**2 + 2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.linspace(-10, 10, 100)\n",
        "y = objective(x)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(x, y)\n",
        "plt.show() # 단순 2차함수인 loss function"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qes0HzBJLiU6",
        "outputId": "dc16fb62-02cf-4b1d-d896-982e011e6550"
      },
      "source": [
        "space = hp.uniform('x', -10, 10) # 가중치의 범위를 정해줌\n",
        "best = fmin(\n",
        "    fn=objective, # Objective Function to optimize\n",
        "    space=space, # Hyperparameter's Search Space\n",
        "    algo=tpe.suggest, # Optimization algorithm\n",
        "    max_evals=1000 # Number of optimization attempts\n",
        ")\n",
        "print(best)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:07<00:00, 135.59it/s, best loss: 2.0000055138541843]\n",
            "{'x': 2.997651840255765}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "jGRL3wWIL9JE",
        "outputId": "531cfd59-b55e-4b16-864d-7e55f1ad08ea"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(x, y)\n",
        "plt.scatter(best['x'], objective(best['x']), color='red')\n",
        "plt.show() # 빨간점이 최적해"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81w5ZLoJM4Fa"
      },
      "source": [
        "### Multiple Parameter Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIbSGVQCM7kg"
      },
      "source": [
        "def objective(params):\n",
        "    x, y = params['x'], params['y'] # 파라미터를 정해줌\n",
        "    return np.sin(np.sqrt(x**2 + y**2)) # Lossfunction return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "7P42JJ1qM-5P",
        "outputId": "2b7bb2e8-cee4-4d12-a235-bc203315eed9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "x = np.linspace(-6, 6, 30)\n",
        "y = np.linspace(-6, 6, 30)\n",
        "x, y = np.meshgrid(x, y)\n",
        "\n",
        "z = objective({'x': x, 'y': y})\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.plot_surface(x, y, z, cmap=cm.coolwarm)\n",
        "\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_zlabel('z')\n",
        "\n",
        "plt.show() # loss function을 3D로 표현"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM9HK76pNF1p"
      },
      "source": [
        "space = {\n",
        "    'x': hp.uniform('x', -6, 6),\n",
        "    'y': hp.uniform('y', -6, 6)\n",
        "} #범위 지정"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZgzzYhoNVT-",
        "outputId": "cd9f4593-3138-4916-d763-4aea3ce613e6"
      },
      "source": [
        "from hyperopt import tpe, hp, fmin\n",
        "\n",
        "def f(params):\n",
        "    x1, x2 = params['x1'], params['x2']\n",
        "    if x1 == 'james':\n",
        "        return -1 * x2\n",
        "    if x1 == 'max':\n",
        "        return 2 * x2\n",
        "    if x1 == 'wansoo':\n",
        "        return -3 * x2\n",
        "\n",
        "search_space = {\n",
        "    'x1': hp.choice('x1', ['james', 'max', 'wansoo']),\n",
        "    'x2': hp.uniform('x2', 5, 10)\n",
        "}\n",
        "\n",
        "best = fmin(\n",
        "    fn=f,\n",
        "    space=search_space,\n",
        "    algo=tpe.suggest,\n",
        "    max_evals=100\n",
        ")\n",
        "\n",
        "print(best)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 174.41it/s, best loss: -29.960242031314763]\n",
            "{'x1': 2, 'x2': 9.986747343771588}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYfqoOFJ4bmB"
      },
      "source": [
        "def objective(params):\n",
        "    x, y = params['x'], params['y'] # 파라미터를 정해줌\n",
        "    return np.sin(np.sqrt(x**2 + y**2)) # Lossfunction return\n",
        "space = {\n",
        "    'x': hp.uniform('x', -6, 6),\n",
        "    'y': hp.uniform('y', -6, 6)\n",
        "} #범위 지정\n",
        "best = fmin(\n",
        "    fn=f,\n",
        "    space=search_space,\n",
        "    algo=tpe.suggest,\n",
        "    max_evals=100\n",
        ")\n",
        "\n",
        "print(best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUwN2tMDQIMn"
      },
      "source": [
        "### 어떻게 적용시킬것인가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pv87qWoVIXs"
      },
      "source": [
        "\n",
        "\n",
        "hyperopt에서 제공하는 기능은 베이지안 기법을 이용해서 주어진 함수에대해 최소값을 찾을 수 있는 인자값을 찾아준다.\n",
        "\n",
        "여기서 주어진 함수란 LOSS Function이고, 인자는 weight가 된다. 3번에서 적용시켜보자\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-faOvOpK7EH"
      },
      "source": [
        "## 3) 기존에 진행했던 강의&프로젝트 데이터셋을 하이퍼 파라미터로 조정해보세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rl-HAGO49pX"
      },
      "source": [
        "pip install hyperas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iEe_XEfP4RL"
      },
      "source": [
        "### build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE2uVkVqVWlh"
      },
      "source": [
        "# the usual imports for a vanilla nueral net\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "def create_model(x_train, y_train, x_test, y_test):\n",
        "  model = Sequential()\n",
        "  model.add(Dense({{choice([16, 256, 512, 1024])}}, input_shape=input_shape, activation='relu',name = 'input_layer'))\n",
        "  model.add(Dense(16, activation='relu', name=\"hidden_layer\"))\n",
        "  model.add(Dense(10,activation='softmax',name=\"output_layer\"))\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "  result = model.fit(X_train, y_train, batch_size={{choice([32, 64, 128])}}, epochs =3, validation_split=.15)\n",
        "\n",
        "  validation_acc = np.amax(result.history['val_acc']) \n",
        "  print('Best validation acc of epoch:', validation_acc)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJrYh_zBP6mD"
      },
      "source": [
        "### bayes opt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWTsIR7P9-6I"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ejv0dLD6UDJ"
      },
      "source": [
        "from hyperopt import Trials, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "model = create_model(X_train,y_train,X_test,y_test)\n",
        "\n",
        "best_run, best_model = optim.minimize(model=model,\n",
        "                                      data=data,\n",
        "                                      algo=tpe.suggest,\n",
        "                                      max_evals=5,\n",
        "                                      trials=Trials(),\n",
        "                                      notebook_name='simple_notebook')\n",
        "X_train, Y_train, X_test, Y_test = data()\n",
        "print(\"Evalutation of best performing model:\")\n",
        "print(best_model.evaluate(X_test, Y_test))\n",
        "print(\"Best performing model chosen hyper-parameters:\")\n",
        "print(best_run)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oABPhVSQFOO"
      },
      "source": [
        "CP949, notebook 오류나서 로컬에서 해결"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYyJvyg9L8VV"
      },
      "source": [
        "## 4) MLP 모델을 forward 와 backward(학습까지)를 처음부터 구현할 수 있는가?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQA8OhW3WCaH"
      },
      "source": [
        "from math import sqrt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjm_y8BTQL9K"
      },
      "source": [
        "### build network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjYzDdX2L88s"
      },
      "source": [
        "class MLP:\n",
        "  ## 초기설정\n",
        "  def __init__(self, input_nodes, hidden_nodes, output_nodes, lr):\n",
        "\n",
        "    self.input_nodes = input_nodes # input layer\n",
        "    self.hidden_nodes = hidden_nodes # hidden layer\n",
        "    self.output_nodes = output_nodes # output layer\n",
        "    self.lr = lr # learning rate\n",
        "\n",
        "    # 가중치 랜덤으로 설정\n",
        "    self.w_ih = np.random.normal(0,\n",
        "                                 sqrt(2/(self.input_nodes + self.hidden_nodes)),\n",
        "                                 (self.input_nodes, self.hidden_nodes))\n",
        "    self.w_ho = np.random.normal(0,\n",
        "                                 sqrt(2/(self.hidden_nodes + self.output_nodes)),\n",
        "                                 (self.hidden_nodes, self.output_nodes))\n",
        "    \n",
        "  ## 활성함수\n",
        "  def sigmoid(self, x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "  # def relu(self, x):\n",
        "  #   if x>0:\n",
        "  #     return x\n",
        "  #   else:\n",
        "  #     return 0\n",
        "\n",
        "  # def softmax(x):\n",
        "\t# e = exp(x)\n",
        "\t# return e / e.sum()\n",
        "\n",
        "  ## fit\n",
        "  def fit(self, X_train, y_train):\n",
        "    self.inputs = X_train\n",
        "    self.targets = y_train\n",
        "    return self.forward('train') # 순전파 train으로보냄\n",
        "\n",
        "  ## 순전파\n",
        "  def forward(self, filter):\n",
        "    if filter == 'train':\n",
        "      self.h = np.dot(self.inputs, self.w_ih) # 가중치*input \n",
        "      self.H = self.sigmoid(self.h) # sigmoid(가중치*input)\n",
        "\n",
        "      self.y = np.dot(self.H, self.w_ho) # 가중치*H\n",
        "      self.Y = self.sigmoid(self.y) # sigmoid(가중치*H)\n",
        "\n",
        "      return self.backward() # 역전파로보냄\n",
        "\n",
        "    elif filter == 'pred':\n",
        "      self.h = np.dot(self.inputs, self.w_ih)\n",
        "      self.H = self.sigmoid(self.h)\n",
        "\n",
        "      self.y = np.dot(self.H, self.w_ho)\n",
        "      self.Y = self.sigmoid(self.y)\n",
        "      return self.Y\n",
        "\n",
        "  ## 역전파\n",
        "  def backward(self):\n",
        "    # 직전층(출력층>>은닉층)\n",
        "    self.o_error = -(self.targets-self.Y) # 오차 ()\n",
        "    self.o_delta = self.o_error * (self.Y * (1 - self.Y)) #오차*시그모이드의 미분 (직전층의 미분값)\n",
        "    # 전전층(은닉층>>입력층)\n",
        "    self.h_error = self.o_delta.dot(self.w_ho.T) # delta* 가중치\n",
        "    self.h_delta = self.h_error * (self.y * (1 - self.y)) #오차*시그모이드의 미분 (전전층의 미분값)\n",
        "    # 가중치는 동시에 업데이트(순차적업데이트 X)\n",
        "    self.w_ih = self.w_ih - self.lr*self.inputs.T.dot(self.h_delta) #learning rate를 곱해서 값을 업데이트\n",
        "    self.w_ho = self.w_ho - self.lr*self.H.T.dot(self.o_delta) #learning rate를 곱해서 값을 업데이트\n",
        "\n",
        "  ## predict\n",
        "  def predict(self, X_test):\n",
        "    self.inputs = X_test\n",
        "\n",
        "    y_pred = self.forward('pred')\n",
        "    return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgsVRh6dQQDx"
      },
      "source": [
        "### DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw3nAz9cUbu1"
      },
      "source": [
        "a = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "b = np.array([[10], [20], [30]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8jAtx6Yjmk5"
      },
      "source": [
        "mlp = MLP(2, 3, 1, 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz9Fx6F9QSsA"
      },
      "source": [
        "### train 10 epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcxbC2VblP3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f7bb76-13b5-48be-fb43-b3ae7a3051e8"
      },
      "source": [
        "# 초기 가중치\n",
        "epoch = 10\n",
        "print(f\"학습전 가중치 : \\n\\t{mlp.w_ih.flatten()} \\n\\t{mlp.w_ho.flatten()}\")\n",
        "mlp.fit(a, b)\n",
        "print(f\"epochs {1} : \\n\\t{mlp.w_ih.flatten()} \\n\\t{mlp.w_ho.flatten()}\")\n",
        "for i in range(epoch):\n",
        "  mlp.forward('train')\n",
        "  print(f\"epochs {i+1} : \\n\\t{mlp.w_ih.flatten()} \\n\\t{mlp.w_ho.flatten()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습전 가중치 : \n",
            "\t[ 0.62767208  0.57670703 -0.58969528 -0.27575651  0.08190298 -0.30976296] \n",
            "\t[ 1.05735637  0.75393613 -0.24242345]\n",
            "epochs 1 : \n",
            "\t[ 0.37283193  0.39499611 -0.53126727 -0.58849959 -0.14109497 -0.23805936] \n",
            "\t[ 1.12139311  0.83327323 -0.23645993]\n",
            "epochs 1 : \n",
            "\t[ 0.45706042  0.45758375 -0.54902791 -0.48050863 -0.06085017 -0.26083062] \n",
            "\t[ 1.14706374  0.91850855 -0.22690772]\n",
            "epochs 2 : \n",
            "\t[ 0.37169452  0.38922721 -0.53214116 -0.58332003 -0.14317615 -0.24049287] \n",
            "\t[ 1.18581532  1.00209757 -0.21907592]\n",
            "epochs 3 : \n",
            "\t[ 0.40779006  0.41973049 -0.53880971 -0.5357918  -0.10301144 -0.24927357] \n",
            "\t[ 1.21056636  1.08221189 -0.21004278]\n",
            "epochs 4 : \n",
            "\t[ 0.33486619  0.35453863 -0.52615684 -0.62421507 -0.18205933 -0.23393144] \n",
            "\t[ 1.23973666  1.16109978 -0.20190325]\n",
            "epochs 5 : \n",
            "\t[ 0.38366362  0.40024082 -0.53410398 -0.56167134 -0.12348277 -0.24411729] \n",
            "\t[ 1.25928495  1.23375828 -0.19267201]\n",
            "epochs 6 : \n",
            "\t[ 0.28640941  0.30495802 -0.51922398 -0.681335   -0.24072075 -0.22580862] \n",
            "\t[ 1.28390448  1.30785579 -0.18457016]\n",
            "epochs 7 : \n",
            "\t[ 0.38937414  0.40984356 -0.53402587 -0.55210923 -0.10908427 -0.24438572] \n",
            "\t[ 1.29853645  1.36995293 -0.17480674]\n",
            "epochs 8 : \n",
            "\t[ 0.19169673  0.20129436 -0.50741488 -0.79780086 -0.36828837 -0.21131113] \n",
            "\t[ 1.32238395  1.44000382 -0.16723142]\n",
            "epochs 9 : \n",
            "\t[ 0.35007418  0.37375874 -0.52744362 -0.59764111 -0.15032534 -0.23662375] \n",
            "\t[ 1.33101297  1.47741376 -0.15602301]\n",
            "epochs 10 : \n",
            "\t[ 0.21007266  0.21835818 -0.51103246 -0.77234247 -0.34424245 -0.21614504] \n",
            "\t[ 1.35024403  1.54447602 -0.14802269]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCqJ-LCpQZwA"
      },
      "source": [
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIlISxqXk-yj"
      },
      "source": [
        "c = np.array([[10, 12]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sywyf9FGk4tN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67869a69-95df-4dc9-ab1a-a4bf0eaf46ec"
      },
      "source": [
        "mlp.predict(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.54829747]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKiZWK5xK_w4"
      },
      "source": [
        "## 5) 케라스에서 MLP 모델을 구현하고 교차 검증(CV)을 통해 하이퍼 파라미터를 조정할 수 있는가?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy_pFuvlQcf5"
      },
      "source": [
        "### load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfoM-7kecPix"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.applications import VGG19\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 100\n",
        "\n",
        "# 데이터 불러오기\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "X_train = X_train / 255.0 \n",
        "X_test = X_test / 255.0 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMNtKuWXQe5l"
      },
      "source": [
        "### build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtFxogdBmMIR"
      },
      "source": [
        "def model_builder(hp):\n",
        "  base_model_1 = VGG19(include_top=False, weights='imagenet', input_shape=(32,32,3), classes=y_train.shape[1])\n",
        "\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3])\n",
        "  hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
        "\n",
        "  model= Sequential()\n",
        "  model.add(base_model_1) \n",
        "  model.add(Flatten()) \n",
        "\n",
        "  #Add the Dense layers along with activation and batch normalization\n",
        "  model.add(Dense(1024,activation=('relu'),input_dim=512))\n",
        "  model.add(Dense(512,activation=('relu'))) \n",
        "  model.add(Dense(256,activation=('relu'))) \n",
        "  model.add(Dropout(.3)) #Adding a dropout layer that will randomly drop /30% of the weights\n",
        "  model.add(Dense(128,activation=('relu')))\n",
        "  model.add(Dropout(.2))\n",
        "  model.add(Dense(hp_units,activation=('relu')))\n",
        "  model.add(Dense(num_classes,activation=('softmax'))) #This is the classification layer\n",
        "  sgd=SGD(lr=hp_learning_rate,momentum=.9,nesterov=False)\n",
        "  adam=Adam(lr=hp_learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "  model.compile(optimizer=sgd,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEiDw2DMRArV"
      },
      "source": [
        "### 5fold CV + Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JChKxEzYsE8U"
      },
      "source": [
        "import kerastuner\n",
        "import numpy as np\n",
        "from sklearn import model_selection\n",
        "class CVTuner(kerastuner.engine.tuner.Tuner):\n",
        "  def run_trial(self, trial, x, y, batch_size=32, epochs=1):\n",
        "    cv = model_selection.KFold(5)\n",
        "    val_losses = []\n",
        "    for train_indices, test_indices in cv.split(x):\n",
        "      x_train, x_test = x[train_indices], x[test_indices]\n",
        "      y_train, y_test = y[train_indices], y[test_indices]\n",
        "      model = self.hypermodel.build(trial.hyperparameters)\n",
        "      model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
        "      val_losses.append(model.evaluate(x_test, y_test))\n",
        "    self.oracle.update_trial(trial.trial_id, {'val_loss': np.mean(val_losses)})\n",
        "    self.save_model(trial.trial_id, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0NRDlbDpdTY"
      },
      "source": [
        "tuner = CVTuner(\n",
        "  hypermodel=my_build_model,\n",
        "  oracle=kerastuner.oracles.BayesianOptimization(\n",
        "    objective='val_loss',\n",
        "    max_trials=40))\n",
        "tuner.search(X_train, y_train, batch_size=64, epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmMd-Xah0m2R"
      },
      "source": [
        "# RAM이 터져서 여기까지만하고, 어떻게하는지 알았다는 것에 의의를 두고 마치겠습니다."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}